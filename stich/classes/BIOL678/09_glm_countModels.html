<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<!DOCTYPE html>
<head>
<!-- Favicon for various operating systems -->
<link rel="apple-touch-icon" sizes="180x180" href="./favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="./favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="./favicon/favicon-16x16.png">
<!-- <link rel="manifest" href="./favicon/site.webmanifest"> -->
<link rel="mask-icon" href="./favicon/safari-pinned-tab.svg" color="#603cba">
<link rel="shortcut icon" href="./favicon/favicon.ico">
<meta name="msapplication-TileColor" content="#603cba">
<meta name="msapplication-config" content="./favicon/browserconfig.xml">
<meta name="theme-color" content="#382121">
</head>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="..\..\styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">danStich</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../../index.html">Home</a>
</li>
<li>
  <a href="../../teaching.html">Teaching</a>
</li>
<li>
  <a href="../../research.html">Research</a>
</li>
<li>
  <a href="../../cv.html">Curriculum vitae</a>
</li>
<li>
  <a href="../../contact.html">Contact</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Course websites
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="index.html">BIOL 678</a>
    </li>
    <li>
      <a href="../BIOL217/index.html">BIOL 217</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<p><br></p>
<div id="glm-count-models" class="section level1">
<h1>GLM: count models</h1>
<p><br></p>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p><br></p>
<p>This week we continue our exploration of generalized linear models and their implementation and interpretation in R. We will continue to investigate the flexible formulation of GLM for use with count models. By the end of this week, you should have a reasonable understanding of why we might use different kinds of count models, how to use them, and what the results mean. We will dive back into the world of residual diagnostics again this week to look at a few different tools that we have at our disposal for GLM</p>
<p><br></p>
</div>
<div id="poisson-regression" class="section level2">
<h2>Poisson regression</h2>
<p><br></p>
<p>Poisson regression is useful for situations in which we have a response that is a count. These are discrete data that cannot be considered continuous because it is impossible for them to take on non-integer or non-negative values. Common examples of these types of responses include species count data in ecology, cell counts in biology, and the number of respondents or patients reporting a side-effect or symptom of interest in the health care profession.</p>
<p>For the Poisson family, the link function that we will use is the ‘log’ link function. This function allows us to work with data that are constrained to be non-negative, a desireable property when we are working with count data.</p>
<p>Let’s use a crab data set to demonstrate the GLM with Poisson data, we will walk through this data set for both the Poisson and negative binomial examples, addressing some distributinal assumptions and model fit along the way.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the data. These data also are available through</span>
<span class="co"># the glm2 package in R.</span>
  crabs =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;http://employees.oneonta.edu/stichds/data/crabs.csv&#39;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)
<span class="co"># Have a look-see</span>
  <span class="kw">head</span>(crabs)
  color spine width mass satellites
<span class="dv">1</span>     <span class="dv">2</span>     <span class="dv">3</span>  <span class="fl">28.3</span> <span class="fl">3.05</span>          <span class="dv">8</span>
<span class="dv">2</span>     <span class="dv">3</span>     <span class="dv">3</span>  <span class="fl">26.0</span> <span class="fl">2.60</span>          <span class="dv">4</span>
<span class="dv">3</span>     <span class="dv">3</span>     <span class="dv">3</span>  <span class="fl">25.6</span> <span class="fl">2.15</span>          <span class="dv">0</span>
<span class="dv">4</span>     <span class="dv">4</span>     <span class="dv">2</span>  <span class="fl">21.0</span> <span class="fl">1.85</span>          <span class="dv">0</span>
<span class="dv">5</span>     <span class="dv">2</span>     <span class="dv">3</span>  <span class="fl">29.0</span> <span class="fl">3.00</span>          <span class="dv">1</span>
<span class="dv">6</span>     <span class="dv">1</span>     <span class="dv">2</span>  <span class="fl">25.0</span> <span class="fl">2.30</span>          <span class="dv">3</span>
  <span class="kw">str</span>(crabs)
<span class="st">&#39;data.frame&#39;</span><span class="op">:</span><span class="st">   </span><span class="dv">173</span> obs. of  <span class="dv">5</span> variables<span class="op">:</span>
<span class="st"> </span><span class="er">$</span><span class="st"> </span>color     <span class="op">:</span><span class="st"> </span>int  <span class="dv">2</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">1</span> <span class="dv">4</span> <span class="dv">2</span> <span class="dv">2</span> <span class="dv">2</span> ...
 <span class="op">$</span><span class="st"> </span>spine     <span class="op">:</span><span class="st"> </span>int  <span class="dv">3</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">2</span> <span class="dv">3</span> <span class="dv">3</span> <span class="dv">1</span> <span class="dv">3</span> ...
 <span class="op">$</span><span class="st"> </span>width     <span class="op">:</span><span class="st"> </span>num  <span class="fl">28.3</span> <span class="dv">26</span> <span class="fl">25.6</span> <span class="dv">21</span> <span class="dv">29</span> <span class="dv">25</span> <span class="fl">26.2</span> <span class="fl">24.9</span> <span class="fl">25.7</span> <span class="fl">27.5</span> ...
 <span class="op">$</span><span class="st"> </span>mass      <span class="op">:</span><span class="st"> </span>num  <span class="fl">3.05</span> <span class="fl">2.6</span> <span class="fl">2.15</span> <span class="fl">1.85</span> <span class="dv">3</span> <span class="fl">2.3</span> <span class="fl">1.3</span> <span class="fl">2.1</span> <span class="dv">2</span> <span class="fl">3.15</span> ...
 <span class="op">$</span><span class="st"> </span>satellites<span class="op">:</span><span class="st"> </span>int  <span class="dv">8</span> <span class="dv">4</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">3</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">8</span> <span class="dv">6</span> ...</code></pre></div>
<p><br></p>
<div id="data-explanation" class="section level3">
<h3>Data explanation</h3>
<p><br></p>
<p>These data represent the number of satellite male crabs per female (rows) horseshoe crab in relation to a number of characteristics of the females, including their color, spine condition, carapace width, and mass (g).</p>
<p>The full citation for the paper that this data set is based on: H. J. Brockmann. 1996. Satellite male groups in horseshoe crabs, <em>Limulus polyphemus</em>. Ethology 102:1-21. <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1996.tb01099.x">doi:10.1111/j.1439-0310.1996.tb01099.x</a></p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># We want to convert color to a factor right off the bat</span>
  crabs<span class="op">$</span>color =<span class="st"> </span><span class="kw">as.factor</span>(crabs<span class="op">$</span>color)

<span class="co"># Fit a model</span>
  count.mod =<span class="st"> </span><span class="kw">glm</span>(satellites<span class="op">~</span>width<span class="op">+</span>mass<span class="op">+</span>spine<span class="op">+</span>color, <span class="dt">data=</span>crabs,
                  <span class="dt">family=</span><span class="st">&#39;poisson&#39;</span>(<span class="dt">link=</span>log))

<span class="co"># Right away, we can see that this model is not a very good fit to the data.</span>
  <span class="kw">plot</span>(count.mod)</code></pre></div>
<p><img src="09_glm_countModels_files/figure-html/unnamed-chunk-3-1.png" width="672" /><img src="09_glm_countModels_files/figure-html/unnamed-chunk-3-2.png" width="672" /><img src="09_glm_countModels_files/figure-html/unnamed-chunk-3-3.png" width="672" /><img src="09_glm_countModels_files/figure-html/unnamed-chunk-3-4.png" width="672" /></p>
<p><br></p>
<p>This brings us to the next important point we need to make about GLMS…</p>
<blockquote>
<p>Even though we are relaxing the assumptions of linear models, we still need to check to make sure the models we use are valid with respect to our assumptions.</p>
</blockquote>
<p>This will become considerably more complicated as we begin to move in to distributions other than the binomial and the Poisson, as our standard methods become less and less applicable and in-depth model validation becomes more and more obscure and more involved.</p>
<p>So, what is going on here? Well, we can see from the first plot that the variance changes with the mean. We can also see that there are some evident issues in our Q-Q plot WRT to the observed vs theoretical values. Finally, we can see that we have some serious outliers in the plot of residuals vs leverage. This is strongly indicative of a skewed distribution in this case given the spread of our leverage points. Outside of the Poisson and Binomial (not the negative binomial!) the interpretability of these plots deteriorates quickly, so we will look at a couple of other methods moving forward.</p>
<p>If we had started by doing data exploration we would have, of course, noticed that even though the data represent counts, they are pretty clearly overdispersed and are indicative of a negative binomial distribution.</p>
<p>For now, we won’t bother to take a look at these results because the link function is the same, so we can get the results from the negative binomial regression in the same way.</p>
<p><br></p>
</div>
</div>
<div id="negative-binomial-regression" class="section level2">
<h2>Negative binomial regression</h2>
<p><br></p>
<p>Okay, moving on with life, let’s take a look at the negative binomial regression model.</p>
<p>We will start this time by actually doing some data exploration before our analysis.</p>
<p>First, look at the distribution of the data. Here, it should be pretty obvious to you by now that these are count data for which the mean is not equal to the variance…right?</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(crabs<span class="op">$</span>satellites)</code></pre></div>
<p><img src="09_glm_countModels_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p><br></p>
<p>If you think back to a couple of weeks ago, you’ll remember this is a pretty typical example of the negative binomial distribution</p>
<p>We can take a look at how this shakes out between our groups (color) as well</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boxplot</span>(satellites<span class="op">~</span>color, <span class="dt">data=</span>crabs)</code></pre></div>
<p><img src="09_glm_countModels_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p><br></p>
<p>And, you can see here that even within groups the distributions do not look like they have equal means and variances, so we will fit a GLM that assumes the response is drawn from a negative binomial distribution. We will need to load a package for this (yay!):</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)</code></pre></div>
<p><br></p>
<p>For this example, we will use a function called <code>glm.nb</code>. This function us estimate a GLM for lets us estimate parameters for a GLM that uses the negative binomial error distribution and estimates the “overdispersion parameter” for the negative binomial distribution. You, of course, remember this parameter and know it as <code>theta</code> from our discussions about probability distributions.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?glm.nb</code></pre></div>
<p><br></p>
<p>Let’s start by fitting a model. Note that we do not need to specify the distributional family or the link function because the glm.nb function was created specifically for the case of negative binomial regression</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">neg.mod =<span class="st"> </span><span class="kw">glm.nb</span>(satellites<span class="op">~</span>width<span class="op">+</span>mass<span class="op">+</span>color, <span class="dt">data=</span>crabs)</code></pre></div>
<p><br></p>
<p>OR, we could fit it with the GLM function like this:</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">neg.mod =<span class="st"> </span><span class="kw">glm</span>(satellites<span class="op">~</span>width<span class="op">+</span>mass<span class="op">+</span>color, <span class="dt">data=</span>crabs,
              <span class="dt">family=</span><span class="st">&#39;negative.binomial&#39;</span>(<span class="dt">theta =</span> <span class="dv">1</span>))</code></pre></div>
<p><br></p>
<p>Play around with the two formulations above and see if there’s a difference. <em>Clue</em>: there’s not really. Just two different ways to do the same thing. The functionality in the glm() function only came around recently, that’s all.</p>
<p>Now, let’s take a look at the distribution of the residuals</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res =<span class="st"> </span>neg.mod<span class="op">$</span>residuals
<span class="kw">plot</span>(neg.mod)</code></pre></div>
<p><img src="09_glm_countModels_files/figure-html/unnamed-chunk-10-1.png" width="672" /><img src="09_glm_countModels_files/figure-html/unnamed-chunk-10-2.png" width="672" /><img src="09_glm_countModels_files/figure-html/unnamed-chunk-10-3.png" width="672" /><img src="09_glm_countModels_files/figure-html/unnamed-chunk-10-4.png" width="672" /></p>
<p><br></p>
<p>Our residuals appear to also take on a negative binomial error distribution, but these plots start to become pretty meaningless in the world of GLMs without a few tweaks…</p>
<p>Luckily, there is also a tool for this purpose</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the boot package</span>
  <span class="kw">library</span>(boot)

<span class="co"># Run the diagnostic plots for our model</span>
  <span class="kw">glm.diag.plots</span>(neg.mod)</code></pre></div>
<p><img src="09_glm_countModels_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p><br></p>
<p>Here, we get a pretty clear picture that our model is adequately describing the overdispersion in the count data when we use the negative binomial distribution, but we may have some issues with extreme data points and excess zeroes.</p>
<p><strong>But</strong>, how does this compare to the Poisson model for count data? We can use model selection to compare the Poisson model to the negative binomial model, since the response is the same in both cases.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(count.mod, neg.mod)
          df      AIC
count.mod  <span class="dv">7</span> <span class="fl">919.8796</span>
neg.mod    <span class="dv">7</span> <span class="fl">759.9076</span></code></pre></div>
<p><br></p>
<p>Clearly the negative binomial model is far superior to the Poisson model here. Now, with a good model in hand we could proceed with data visualization, …, etc.</p>
<p>Still, this will not be satisfying to the purists out there as the two models are not “nested” in the sense that one is a subset of the other. There are some philosophical issues with an I-T approach in this situation, in which case a full-on model validation test might be necessary to determine which model posesses the best predictive properties. Thinking back to our conversations last week, this process potentially could include some measure of accuracy and precision (like the root mean squared error) for each model based on cross validation methods or boot strapping.</p>
<p>On with life again, and we can finally look at the model output…</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(neg.mod)

Call<span class="op">:</span>
<span class="kw">glm.nb</span>(<span class="dt">formula =</span> satellites <span class="op">~</span><span class="st"> </span>width <span class="op">+</span><span class="st"> </span>mass <span class="op">+</span><span class="st"> </span>color, <span class="dt">data =</span> crabs, 
    <span class="dt">init.theta =</span> <span class="fl">0.9603230219</span>, <span class="dt">link =</span> log)

Deviance Residuals<span class="op">:</span><span class="st"> </span>
<span class="st">    </span>Min       1Q   Median       3Q      Max  
<span class="op">-</span><span class="fl">1.8666</span>  <span class="op">-</span><span class="fl">1.3628</span>  <span class="op">-</span><span class="fl">0.3071</span>   <span class="fl">0.4325</span>   <span class="fl">2.2884</span>  

Coefficients<span class="op">:</span>
<span class="st">            </span>Estimate Std. Error z value <span class="kw">Pr</span>(<span class="op">&gt;</span><span class="er">|</span>z<span class="op">|</span>)  
(Intercept) <span class="op">-</span><span class="fl">0.74381</span>    <span class="fl">1.87517</span>  <span class="op">-</span><span class="fl">0.397</span>   <span class="fl">0.6916</span>  
width        <span class="fl">0.01753</span>    <span class="fl">0.09690</span>   <span class="fl">0.181</span>   <span class="fl">0.8565</span>  
mass         <span class="fl">0.65366</span>    <span class="fl">0.35033</span>   <span class="fl">1.866</span>   <span class="fl">0.0621</span> .
color2      <span class="op">-</span><span class="fl">0.25523</span>    <span class="fl">0.34845</span>  <span class="op">-</span><span class="fl">0.732</span>   <span class="fl">0.4639</span>  
color3      <span class="op">-</span><span class="fl">0.51990</span>    <span class="fl">0.38015</span>  <span class="op">-</span><span class="fl">1.368</span>   <span class="fl">0.1714</span>  
color4      <span class="op">-</span><span class="fl">0.48209</span>    <span class="fl">0.42875</span>  <span class="op">-</span><span class="fl">1.124</span>   <span class="fl">0.2608</span>  
<span class="op">---</span>
Signif. codes<span class="op">:</span><span class="st">  </span><span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span>

(Dispersion parameter <span class="cf">for</span> Negative <span class="kw">Binomial</span>(<span class="fl">0.9603</span>) family taken to be <span class="dv">1</span>)

    Null deviance<span class="op">:</span><span class="st"> </span><span class="fl">220.09</span>  on <span class="dv">172</span>  degrees of freedom
Residual deviance<span class="op">:</span><span class="st"> </span><span class="fl">196.61</span>  on <span class="dv">167</span>  degrees of freedom
AIC<span class="op">:</span><span class="st"> </span><span class="fl">759.91</span>

Number of Fisher Scoring iterations<span class="op">:</span><span class="st"> </span><span class="dv">1</span>

              Theta<span class="op">:</span><span class="st">  </span><span class="fl">0.960</span> 
          Std. Err.<span class="op">:</span><span class="st">  </span><span class="fl">0.175</span> 

 <span class="dv">2</span> x log<span class="op">-</span>likelihood<span class="op">:</span><span class="st">  </span><span class="op">-</span><span class="fl">745.908</span> </code></pre></div>
<p><br></p>
<p>The interpretation of this output is virtually identical to the output for linear models that we have been working with. Here, we see that no variable is significant with a type-I error rate of 0.05, and that only the mass of females has a significant effect on the number of satellite males when we increase our type-I error rate to 0.10. How does this compare to the original findings? Go take a look…</p>
<p><br></p>
</div>
<div id="zero-inflation" class="section level2">
<h2>Zero inflation</h2>
<p><br></p>
<p>The fits of these two models, in reality suggest the need to get into a whole other realm of error distributions that we probably will not get into during this class: the zero inflated count model. Zero inflation (excess zeroes in count data) can arise by one of two mechanisms: process zeros and observational zeros that arrive as a result of imperfect detection).</p>
<p>One approach to dealing with this is to use a ‘hurdle’ model. The idea is to make two separate models: 1) a logistic regression model to help us determine which factors influence whether or not the phenomenon of interest even occurred (0 or 1), and 2) a count model that will help us determine what factors influence with what frequency this phenomenon occurred given that it did occur.</p>
<p>First, we make a binary indicator variable to represent whether or not the phenomenon occurred using an if-then statement inside a for loop:</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="st"> </span><span class="kw">nrow</span>(crabs)){
  <span class="cf">if</span>(crabs<span class="op">$</span>satellites[i]<span class="op">==</span><span class="dv">0</span>){
   crabs<span class="op">$</span>present[i] =<span class="st"> </span><span class="dv">0</span>
  } <span class="cf">else</span> {
    crabs<span class="op">$</span>present[i] =<span class="dv">1</span>
  }
}</code></pre></div>
<p><br></p>
<p>Now, the first step is to fit a logistic regression model to predict how our response is affected by some combination of explanatory variables</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">step1 =<span class="st"> </span><span class="kw">glm</span>(present<span class="op">~</span>mass, <span class="dt">data=</span>crabs, <span class="dt">family=</span><span class="st">&#39;binomial&#39;</span>)
<span class="kw">summary</span>(step1)

Call<span class="op">:</span>
<span class="kw">glm</span>(<span class="dt">formula =</span> present <span class="op">~</span><span class="st"> </span>mass, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> crabs)

Deviance Residuals<span class="op">:</span><span class="st"> </span>
<span class="st">    </span>Min       1Q   Median       3Q      Max  
<span class="op">-</span><span class="fl">2.1106</span>  <span class="op">-</span><span class="fl">1.0750</span>   <span class="fl">0.5427</span>   <span class="fl">0.9122</span>   <span class="fl">1.6323</span>  

Coefficients<span class="op">:</span>
<span class="st">            </span>Estimate Std. Error z value <span class="kw">Pr</span>(<span class="op">&gt;</span><span class="er">|</span>z<span class="op">|</span>)    
(Intercept)  <span class="op">-</span><span class="fl">3.6933</span>     <span class="fl">0.8799</span>  <span class="op">-</span><span class="fl">4.197</span> <span class="fl">2.70e-05</span> <span class="op">**</span><span class="er">*</span>
mass          <span class="fl">1.8145</span>     <span class="fl">0.3766</span>   <span class="fl">4.818</span> <span class="fl">1.45e-06</span> <span class="op">**</span><span class="er">*</span>
<span class="op">---</span>
Signif. codes<span class="op">:</span><span class="st">  </span><span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span>

(Dispersion parameter <span class="cf">for</span> binomial family taken to be <span class="dv">1</span>)

    Null deviance<span class="op">:</span><span class="st"> </span><span class="fl">225.76</span>  on <span class="dv">172</span>  degrees of freedom
Residual deviance<span class="op">:</span><span class="st"> </span><span class="fl">195.74</span>  on <span class="dv">171</span>  degrees of freedom
AIC<span class="op">:</span><span class="st"> </span><span class="fl">199.74</span>

Number of Fisher Scoring iterations<span class="op">:</span><span class="st"> </span><span class="dv">4</span></code></pre></div>
<p><br></p>
<p>Here we see that mass has a significant effect on whether or not <em>any</em> satellite males are present</p>
<p>Step 2 is to fit the count model to explain the effects of some combination of explanatory variables on the frequency with which the phenomenon occurs given that it ever occurred in the first place. NOTE: This does not have to be the same combination of explanatory variables. In fact, it is always conceivable that different processes influence these two distinct phenomena.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">step2 =<span class="st"> </span><span class="kw">glm.nb</span>(satellites<span class="op">~</span>mass, <span class="dt">data=</span>crabs[crabs<span class="op">$</span>satellites<span class="op">!=</span><span class="dv">0</span>,])
<span class="kw">summary</span>(step2)

Call<span class="op">:</span>
<span class="kw">glm.nb</span>(<span class="dt">formula =</span> satellites <span class="op">~</span><span class="st"> </span>mass, <span class="dt">data =</span> crabs[crabs<span class="op">$</span>satellites <span class="op">!=</span><span class="st"> </span>
<span class="st">    </span><span class="dv">0</span>, ], <span class="dt">init.theta =</span> <span class="fl">7.337959755</span>, <span class="dt">link =</span> log)

Deviance Residuals<span class="op">:</span><span class="st"> </span>
<span class="st">    </span>Min       1Q   Median       3Q      Max  
<span class="op">-</span><span class="fl">1.8112</span>  <span class="op">-</span><span class="fl">0.7938</span>  <span class="op">-</span><span class="fl">0.1828</span>   <span class="fl">0.5061</span>   <span class="fl">2.6936</span>  

Coefficients<span class="op">:</span>
<span class="st">            </span>Estimate Std. Error z value <span class="kw">Pr</span>(<span class="op">&gt;</span><span class="er">|</span>z<span class="op">|</span>)    
(Intercept)  <span class="fl">1.02307</span>    <span class="fl">0.26164</span>   <span class="fl">3.910</span> <span class="fl">9.22e-05</span> <span class="op">**</span><span class="er">*</span>
mass         <span class="fl">0.18675</span>    <span class="fl">0.09668</span>   <span class="fl">1.932</span>   <span class="fl">0.0534</span> .  
<span class="op">---</span>
Signif. codes<span class="op">:</span><span class="st">  </span><span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span>

(Dispersion parameter <span class="cf">for</span> Negative <span class="kw">Binomial</span>(<span class="fl">7.338</span>) family taken to be <span class="dv">1</span>)

    Null deviance<span class="op">:</span><span class="st"> </span><span class="fl">114.67</span>  on <span class="dv">110</span>  degrees of freedom
Residual deviance<span class="op">:</span><span class="st"> </span><span class="fl">111.05</span>  on <span class="dv">109</span>  degrees of freedom
AIC<span class="op">:</span><span class="st"> </span><span class="fl">523.94</span>

Number of Fisher Scoring iterations<span class="op">:</span><span class="st"> </span><span class="dv">1</span>

              Theta<span class="op">:</span><span class="st">  </span><span class="fl">7.34</span> 
          Std. Err.<span class="op">:</span><span class="st">  </span><span class="fl">2.57</span> 

 <span class="dv">2</span> x log<span class="op">-</span>likelihood<span class="op">:</span><span class="st">  </span><span class="op">-</span><span class="fl">517.938</span> </code></pre></div>
<p><br></p>
<p>From these results, we can see that our count models in the previous sections were really just picking up on the large number of zeroes in our data set. We know this because of the differences in the results between the models <code>step1</code> and <code>step2</code>.</p>
<p>Likewise, we can take another look at our model diagnostics for <code>step2</code> to see if our diagnostic plots look more reasonable now</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make diagnostic plots</span>
  <span class="kw">glm.diag.plots</span>(step2)</code></pre></div>
<p><img src="09_glm_countModels_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p><br></p>
<p>Here, we can see that our residual plots indicate a pretty drastic improvement in our assumptions.</p>
<p>Of course, there are a number of built-in functions available from different packages that can be used to do the same thing. Here is one example from the <code>pscl</code> package:</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the pscl package</span>
  <span class="kw">library</span>(pscl)

<span class="co"># Fit a zero-inflated regression model</span>
  neg.mod2 =<span class="st"> </span><span class="kw">zeroinfl</span>(satellites<span class="op">~</span>width<span class="op">+</span>mass<span class="op">+</span>color, <span class="dt">data=</span>crabs,
                      <span class="dt">dist=</span><span class="st">&#39;negbin&#39;</span>)</code></pre></div>
<p><br></p>
<p>The output here is essentially the same as that from above. The advantage to this approach is that the routine is packaged in a single call, so the output is likewise collected into a single object.</p>
<p><br></p>
</div>
</div>

<!DOCTYPE html>

<br>

<hr>

<p style="color:gray">This work is licensed under a <a href="https://creativecommons.org/licenses/by/4.0/legalcode">Creative Commons Attribution 4.0 International License.</a></p>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
