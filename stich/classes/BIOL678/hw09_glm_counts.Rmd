```{r child="_styles.Rmd"}
```

<br>
 
# GLM: count models

<br>
  
```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# Load the R2jags library
  library(R2jags)
```

## Introduction

<br>
 
This week in class, we introduced GLM formulations of count models using either Poisson or negative binomial error distributions. Along with these ideas, we discussed concepts relating to transformations for exploratory variables and some basic model diagnostics for the GLM in these situations. During lab this week, we will continue to expand on these ideas, and we will reinforce concepts related to model selection and validation that we have talked about in other sections.

For our purposes this week, we will continue to delve further into count models that use Poisson and negative binomial error distributions. We will make predictions from these models, talk about standardized effects, and continue to learn more about writing methods and results for these approaches. We will work with the same models we formulated under the frequentist mode of interest earlier this week, but now we will cast these analyses in a Bayesian framework.

<br>
 
## The data

<br>
 
We are going to continue working with the crabs data this week in lab. In case you need a refresher on those data, here it is:

These data represent the number of satellite male crabs per female (rows) horseshoe crab in relation to a number of characteristics of the females, including their color, spine condition, carapace width, and mass (g).

The full citation for the paper that this data set is based on:
H. J. Brockmann. 1996. Satellite male groups in horseshoe crabs, *Limulus polyphemus*. Ethology 102:1-21. doi:10.1111/j.1439-0310.1996.tb01099.x

Read in the data, and recall that we want to be working with `color`, and `spine` as categorical variables since these are both classification schemes and not actually numeric data.

<br>
 
```{r}
# Read in the data
  crabs = read.csv('http://employees.oneonta.edu/stichds/data/crabs.csv', header = TRUE)

# Take a look at the first few rows of the dataframe
  head(crabs, 10)
```

<br>
 
Did you make sure that the variables `color` and `spine` were stored as either factors or character variables? If not, go ahead and change their data type now.

<br>
 
```{r, echo=FALSE, results='hide'}
# Change color and spine to factors
  crabs$color = as.factor(crabs$color)
  crabs$spine = as.factor(crabs$spine)
```

<br>
 
Don't forget to make sure you did it correctly:

<br>
 
```{r}
# Have a look at the data structure
  str(crabs)
```

<br>
 
## A worked example

<br>
 
Let's get started! Our first challenge here is to fit a count model describing the variability in satellite males as some function of female characteristics. Let's start by building a model that uses only `color` as an explanatory variable. We can liken this to doing and ANOVA to test the effects of `color` on `satellites`. So, if you are following along in your text book, we are somewhere between the models presented in chapters 13 and those presented in chapter 15.

We can formulate this model in a pretty straightforward way by using the same conventions that we have used during the past couple of weeks for Bayesian models written in the BUGS language. Here, we will estimate separate intercepts for each of the color variants in the data set:

If we wanted to write out the likelihood and the model by hand, it might look something like what follows. We are assuming that the i^th^ response (number of satellites) within each j^th^ level of the variable `color` is drawn from a Poisson distribution with a mean and variance of $\lambda$. We start by writing the likelihood for the i^th^ value of $N$ with respect to the i^th^ value of $\lambda$: 

$$N_i = Poisson(\lambda_{i})$$

We can then specify the linear predictor on the link scale (log in this case, because we are modeling count data) to specify the model. In this case, we don't specify any betas because we are estimating group-specific intercepts.

$$log(\lambda_{i}) = \alpha_{i_j}$$

This approach accomplishes the same thing as dummy coding color and writing $log(\lambda_i) = \beta_0 + \beta_1 \cdot x_1 + \beta_2 \cdot x_2 + \beta_3 \cdot x_3$, but the former easier to write out in notation and in the BUGS language. It also makes it easier to communicate means. If we want relative effect sizes, we can just calculate them by doing simple algebra with the posteriors.

And, finally, we assume that the i^th^ value of is drawn from a normal distribution on the link scale, dependent upon the color (j) of the female crab in the i^th^ observation. We specify the prior on alpha for each j^th^ color as a diffuse, normal distribution with a mean ($\mu$) of zero and a variance ($\sigma^2$) of 100 (in BUGS language $\tau = 0.01$).

$$\alpha_{j} = Normal(0, 0.01)$$

> Specify* the model for JAGS

Here, we add in a few calculations so we can assess model fit (see Chapter 13.5-13.5.1 in Kery [2010] for explanations). Essentially, what we are going to do here is calculate the predicted and fitted residuals so we can make (1) a residual plot and (2) a predicted vs fitted plot of sorts.

Note that we put this code inside the same loop as the likelihood because it is also looping over each observation in the data. This decision has nothing to do with statistics and everything to do with programming. A sinlge, loop containing multiple tasks in JAGS is evaluated faster than multiple smaller loops containing only a single task. We could just as easily write the code for fit assessment in a separate loop that iterates over operations. It would just be a little slower to run.

<br>
 
```{r}
modelstring="                 
  model {                       

    # Likelihood and residuals
      for(i in 1:nobs){  
        # Likelihood
          N[i] ~ dpois(lambda[i])
          log(lambda[i]) <- alpha[color[i]] + beta[color[i]]*mass[i]
          
        # Calculations for assessing model fit
          # Pearson residuals (aka standardized residuals)
            pResid[i] <- N[i] - lambda[i]/sqrt(lambda[i])

          # Make a new set of observations 
          # that conform perfectly to the posterior distribution
            N.new[i] ~ dpois(lambda[i])

          # Pearson residuals for the data that conform perfectly
            pResidN[i] <- N.new[i] - lambda[i]/sqrt(lambda[i])

          # Calculate squared residuals for model fit and predictive fit
            D[i] <- pow(pResid[i], 2)
            Dnew[i] <- pow(pResidN[i], 2)
      }

    # Priors
      for(j in 1:ncolors){
        alpha[j] ~ dnorm(0, 0.01)
        beta[j] ~ dnorm(0, 0.01) 
      }

    # Discrepency measures
      fitted <- sum(D[])
      predicted <- sum(Dnew[])
  }                             
    
"

writeLines(modelstring,con="crabsModel.txt")

```

<br>
 
Model *specification* is the declaration of the mathematical formula that we use to relate our expalanatory variables to the response.

> Create a list to hold the data for the model

```{r}
# Package the data in a list
  crabs.data = list(
    nobs = nrow(crabs),
    N = crabs$satellites,
    color = crabs$color,
    ncolors = length(unique(crabs$color)),
    mass=crabs$mass
  )
```

> Tell JAGS which parameters we wish to monitor

```{r}
# Parameters monitored
  parameters <- c('alpha', 'beta', 'pResid', 'fitted', 'predicted')
```

> Define a function that creates a list of initial values for each parameter

```{r}
# Initial values
  inits <- function(){list(
    alpha=rnorm(length(unique(crabs$color)),0,1),
    beta=rnorm(length(unique(crabs$color)),0,1)    
    )}
```

> Define objects to hold MCMC settings for model calibration

```{r}
# MCMC settings
  ni <- 7500       # Number of draws from posterior (for each chain)
  nt <- 3          # Thinning rate
  nb <- 2500       # Number of draws to discard as burn-in
  nc <- 3          # Number of chains
```  

> Fit (calibrate) the model using JAGS

*Calibration* is fitting the model to actual data

```{r, results='hide', warning=FALSE, message=FALSE}
# Call jags and run the model
  crabs.model <- jags(crabs.data, inits=inits, parameters, "crabsModel.txt",
    n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb,
    working.directory = getwd())
```

> Print the model summary

```{r, eval=FALSE}
# Print a summary of the model
  print(crabs.model, digits = 2) 
```  

> Making sense of the results

Unfortunately, storing the residuals also means that we get the print out of the estimates in the model summary...But, we can summarize the model nicely by just printing out the components we really care about. Here, I select only the columns for mean, sd, 95% CRI, Rhat, and n.eff (columns 1-3, and 7-9 in the summary table) for our $\alpha$ parameters and the deviance estimate (rows 1-5 of the summary table). 

<br>
 
```{r}
# Get the relevant information from the model summary
  modSummary = crabs.model$BUGSoutput$summary[1:9, c(1:3, 7:9)]

# Print the model summary
  print(modSummary, digits=2)
```

<br>
 
And, if we need it, we can also get the DIC like this:

<br>
 
```{r}
# Print out DIC value
  crabs.model$BUGSoutput$DIC
```

> Model diagnostics

At a quick glance, the summary table seems to indicate that our chains converged nicely and it looks like we got a good number of samples from our posteriors. I'm not making traceplots 178 parameters, but knock yourself out by all means.

Now that we have our wits back about us, let's actually take a look at some residual plots!

Make a plot of the residuals.

<br>
 
```{r}
plot(crabs.model$BUGSoutput$mean$pResid, las=1, ylab='Pearson residuals', xlab = 'Observation', pch=21, bg='gray87')
abline(h=0, col='red', lty=2, lwd=1)
```

<br>
 
Uh, oh...this isn't looking good! As you can see, most of our residuals are above the zero line here, and even though we are not working with a normally distributed response, the residuals should still have a mean of zero and an approximately normal distribution because we are using a link function that *should* make them normal.

We can keep plowing through this and take a look at our discrepancy measure to see whether or not the model provides an adequate fit:

<br>
 
```{r}
plot(crabs.model$BUGSoutput$sims.list$fitted,
     crabs.model$BUGSoutput$sims.list$predicted,
     xlab='Discrepancy measure for observed',
     ylab='Discrepancy measure for predicted')
abline(0,1,lwd=2,col='black')
```

<br>
 
Also not looking great (see Ch. 13.5.1 for explanation). We can find out pretty quickly, but the key here is that we are looking for a [Bayesian p-] value of about 0.50 (see Ch. 8.4.2 in Kery [2010]).

<br>
 
```{r}
mean(crabs.model$BUGSoutput$sims.list$fitted>
     crabs.model$BUGSoutput$sims.list$predicted)
```

<br>
 
Crap. We are in big trouble here.

Okay, well it's actually not that bad...We just need to look at the assumptions that we've made (and that we would have known were erroneous if we'd done our exploratory analysis!). The fact is, our data are over-dispersed (the variance is bigger than the mean), so these data are not actually Poisson. 

<br>
 
## Accounting for overdispersion

<br>
 
We basically have two options here. We could go full-on negative binomial, or we could just address the overdispersion directly by adding a parameter to the model! Let's do the latter. Basically, the only change here is that we are going to add a parameter, called $\epsilon$ to our model so we can incorporate the overdispersion directly.

<br>
 
```{r}
modelstring="                 
  model {                       
    # Likelihood
      for(i in 1:nobs){          
        N[i] ~ dpois(lambda[i])   
        log(lambda[i]) <- alpha[color[i]] + beta[color[i]]*mass[i] + eps[i]
        eps[i] ~ dnorm(0, tau)


        # Calculations for assessing model fit
          pResid[i] <- N[i] - lambda[i]/sqrt(lambda[i])
          N.new[i] ~ dpois(lambda[i])
          pResidN[i] <- N.new[i] - lambda[i]/sqrt(lambda[i])
          D[i] <- pow(pResid[i], 2)
          Dnew[i] <- pow(pResidN[i], 2)
      }                         

    # Priors
        sigma ~ dunif(0, 10)
        tau <- 1/(sigma * sigma)

      for(i in 1:ncolors){
        alpha[i] ~ dnorm(0,0.001) 
        beta[i] ~ dnorm(0,0.001)  

      }

    # Sums of squared residuals
      fitted <- sum(D[])
      predicted <- sum(Dnew[])
  }                             
"                               
writeLines(modelstring,con="crabsMod2.txt")

# Package the data in a list
  crabs.data = list(
    nobs = nrow(crabs),
    N = crabs$satellites,
    color = crabs$color,
    ncolors = length(unique(crabs$color)),
    mass=crabs$mass
  )

# Parameters monitored
  parameters <- c('alpha', 'beta', 'eps', 'pResid', 'fitted', 'predicted')

# Initial values
  inits <- function(){list(
    alpha=rnorm(length(unique(crabs$color)),0,1),
    beta=rnorm(length(unique(crabs$color)),0,1),
    sigma=runif(1,0,10)
    )}

# MCMC settings
  ni <- 7500      # Number of draws from posterior (for each chain)
  nt <- 3          # Thinning rate
  nb <- 2500       # Number of draws to discard as burn-in
  nc <- 3          # Number of chains

# Call jags and run the model
  crabs.model2 <- jags(crabs.data, inits=inits, parameters, "crabsMod2.txt",
    n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb,
    working.directory = getwd())

# Print an abbreviated summary of the model
# Get the relevant information from the model summary
  modSummary = crabs.model2$BUGSoutput$summary[c(1:9), c(1:3, 7:9)]

# Print the model summary
  print(modSummary, digits=2) 
```

<br>
 
We can see that our values of our parameter estimates have changed a bit here, but how does that translate to model fit?

Go ahead and calculate the Bayesian p-value again. It looks like it is a little closer to 0.50, but maybe not good enough to pass the straight-face test...

<br>
 
```{r, echo=FALSE}
mean(crabs.model2$BUGSoutput$sims.list$fitted>
     crabs.model2$BUGSoutput$sims.list$predicted)
```     
 
<br>
     
So, why is this? It's because we don't just have a little overdispersion...we have quite a bit. Let's have a look at our predictions versus observed number of satellites for each color. From these plots, we can see that our measure of central tendancy is still ballpark, it's just that our variance is still grossly under-estimated.

<br>
 
```{r}
par(mfrow=c(2,2))
for(i in 1:4){
plot(density(crabs$satellites[crabs$color==i]), xlim=c(0, 20), yaxt='n',
     bty='l', main='', xlab = 'Number of satellites')
par(new=TRUE)
plot(density(exp(crabs.model2$BUGSoutput$sims.list$alpha[,i] +
         crabs.model2$BUGSoutput$sims.list$beta[,i]*mean(crabs$satellites[crabs$color==i]))),
     xlim=c(0, 20), main='', xlab='', ylab='', col='red', yaxt='n',
     bty='l')
}
```

<br>
 
## Shifting gears

<br>
 
This example is probably a good case for switching over to the negative binomial distribution. The code to demonstrate this is below. This is the formulation you will work with for the rest of lab.

<br>
 
```{r}
modelstring="                 
  model {                       
    # Likelihood
      for(i in 1:nobs){    
        N[i] ~ dnegbin(p[i], r[color[i]]) 
        logit(p[i]) <- alpha[color[i]] + beta[color[i]]*mass[i]
      }

    # Priors
      for(i in 1:ncolors){
        alpha[i] ~ dnorm(0,0.0001) 
        beta[i] ~ dnorm(0,0.0001)
        r[i] ~ dgamma(0.0001, 0.0001)T(0,3)
      }
  }                             
"                               
writeLines(modelstring,con="crabsMod3.txt")

# Package the data in a list
  crabs.data = list(
    nobs = nrow(crabs),
    N = crabs$satellites,
    color = crabs$color,
    ncolors = length(unique(crabs$color)),
    mass=crabs$mass
  )

# Parameters monitored
  parameters <- c('alpha', 'beta', 'r')

# Initial values
  inits <- function(){list(
    alpha=rnorm(length(unique(crabs$color)),0,1),
    beta=rnorm(length(unique(crabs$color)),0,1),
    r=runif(length(unique(crabs$color)),0,1)
    )}

# MCMC settings
  ni <- 4500       # Number of draws from posterior (for each chain)
  nt <- 10         # Thinning rate
  nb <- 500        # Number of draws to discard as burn-in
  nc <- 3          # Number of chains

# Call jags and run the model
  crabs.model3 <- jags(crabs.data, inits=inits, parameters, "crabsMod3.txt",
    n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb,
    working.directory = getwd())

# Print the model summary
  print(crabs.model3, digits=2) 
```

<br>
 
If we want to see how the estimates from this model compare to the observed data, we can plot the posterior densities for r over the top of histograms for each color. All in all this is looking pretty darn good.

<br>
 
```{r}  
par(mfrow=c(2,2))  
for(i in 1:length(unique(crabs$color))){  
hist(crabs$satellites[crabs$color==i], xlim=c(0, 20), yaxt='n',
     bty='l', main='', xlab = 'Number of satellites', col='gray87')  
par(new=TRUE)
plot(density(exp(crabs.model3$BUGSoutput$sims.list$r[ ,i])),
     xlim=c(0, 20), main='', xlab='', ylab='', col='red', yaxt='n', bty='l')
}
```

<br>
 
## Your mission

<br>
 
Just as in the past couple of weeks, your assignment for this lab is to write a *brief* methods section and a *brief* results section for the exercises you have been working on. **You may use either the maximum likelihood estimation procedure** covered in lecture this week, **or the Bayesian approach** detailed in the lab exercise. Just make sure you pick one or the other and stick to it in your analysis and your writing.

In addition to these tasks, I would like you to **add one additional explanatory variable** to the model. I would like you to add `width` as a continuous covariate. 

Then, so we can compare the relative effect sizes of `width` and `mass`, I want you to standardize the covariates prior to including them in the model.

Remember that this is the same as calculating a whole bunch of z-scores. You can achieve this in R like this (for example):
```{r, eval=FALSE}
# Standardize mass variable:
  crabs$smass = as.vector(scale(crabs$mass))
```

<br>

For your results, you can present covariates on the standardized scale, and back-transform based on our discussions earlier this week to show effects on the real scale of the variable.

<br>
 
```{r, eval=FALSE, echo=FALSE}
# My code for the answer key to lab 09

# Front-end needs -------------------------------------------------------------
  library(R2jags)

# Data manipulation -----------------------------------------------------------
# Read in the data
  crabs = read.csv('crabs.csv', header = TRUE)
# Have a look-see
  head(crabs)
  str(crabs)

# Model specification --------------------------------------------------------
modelstring="                 
  model {                       
    # Likelihood
      for(i in 1:nobs){          
        y[i] ~ dpois(lambda[i])   
        log(lambda[i]) <- alpha[color[i]] + beta[1]*mass[i]
      }                         

    # Priors
      beta ~ dnorm(0,0.0001)

      for(i in 1:ncolors){
        alpha[i] ~ dnorm(0,0.0001)
      }
  }                             
"                               
writeLines(modelstring,con="crabsMod.txt")

# Model settings and calibration ---------------------------------------------
# Package the data in a list
  crabs.data = list(
    nobs = nrow(crabs),
    y = crabs$satellites,
    mass = crabs$mass,
    color = crabs$color,
    ncolors = length(unique(crabs$color))
  )

# Parameters monitored
  parameters <- c('alpha','beta')


# Initial values
  inits <- function(){list(
    alpha=rnorm(length(unique(crabs$color)),0,1),
    beta=rnorm(1,0,1)
    )}

# MCMC settings
  ni <- 7500      # Number of draws from posterior (for each chain)
  nt <- 3          # Thinning rate
  nb <- 2500       # Number of draws to discard as burn-in
  nc <- 3          # Number of chains

# Call jags and run the model
  crabs.model <- jags(crabs.data, inits=inits, parameters, "crabsMod.txt",
    n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb,
    working.directory = getwd())

# Print a summary of the model
  print(crabs.model, digits = 3)  
```  

<br>
   
<br>
   