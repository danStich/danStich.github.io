<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />
<!DOCTYPE html>
<head>
<!-- Favicon for various operating systems -->
<link rel="apple-touch-icon" sizes="180x180" href="./favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="./favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="./favicon/favicon-16x16.png">
<!-- <link rel="manifest" href="./favicon/site.webmanifest"> -->
<link rel="mask-icon" href="./favicon/safari-pinned-tab.svg" color="#603cba">
<link rel="shortcut icon" href="./favicon/favicon.ico">
<meta name="msapplication-TileColor" content="#603cba">
<meta name="msapplication-config" content="./favicon/browserconfig.xml">
<meta name="theme-color" content="#382121">
</head>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="..\..\styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">BIOL 678</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Teaching
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../../teaching.html">Teaching home</a>
    </li>
    <li>
      <a href="../../classes/BIOL217/index.html">BIOL 217</a>
    </li>
    <li>
      <a href="../../classes/BIOL678/index.html">BIOL 678</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../research.html">Research</a>
</li>
<li>
  <a href="../../studentProjects.html">Current Students</a>
</li>
<li>
  <a href="../../publications.html">Publications</a>
</li>
<li>
  <a href="../../cv.html">CV</a>
</li>
<li>
  <a href="../../contact.html">Contact</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/danStich">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<h1 id="multi">
Model selection
</h1>
<p><img src="../../images/glass.jpg"></p>
<h2 id="multi">
Introduction
</h2>
<p>As we have learned in the past couple weeks, we often encounter situations for which there are mulitiple, competing hypotheses about what factors, or combinations of factors, best explain the observed patterns in our response of interest. This uncertainty can arise for one of two primary reasons:</p>
<p><strong>1. Complexity of the study system</strong></p>
<p>Biological systems are complex, and often we are interested in which factor, or set of factors, best predict the patterns we observe in the natural world. In carefully designed experiments, we might be interested in evaluating competing hypotheses about mechanistic drivers of biological phenomena. In complex observational studies, we might simply wish to know what factor or subset of possible factors best predicts the patterns we observe, with the understanding that these findings cannot necessarily be used to infer causality (or ‘mechanism’).</p>
<p><strong>2. Collinearity</strong></p>
<p>Oh, snap! What did he just say? <strong>Collinearity</strong> is the idea that certain explanatory variables are related to one another. I know, I know; last week I told you that the <em>independence of observations</em> was one of the fundamental assumptions that we make about linear models. That is, all observations are sampled independently from one another. This is a nice ideal, and in certain experimental designs that are “orthogonal”, we can ensure that variables are not collinear. But, in the real world, this is almost never the case.</p>
<p>Model selection offers a means for us to weigh the information redundancy and effects of collinearity against the information that is gained as a result of including explanatory variables that are related to one another. In real-world cases, our best model will almost always fall somewhere between a model that contains all of the variables we want to include, and a model that contains only one of those variables.</p>
<div id="methods-for-model-selection" class="section level2">
<h2>Methods for model selection</h2>
<p>Here, we discuss approaches for applying our model-selection tool of choice. As always, I know it is hard to believe, but there is some controversy as to which method of model selection is best for a given situation. Generally speaking, there are 3 major classes of methods for model selection: step-wise selection, all possible subsets, and <em>a priori</em> subsets.</p>
<div id="stepwise-selection--a-limited-treatment" class="section level3">
<h3>Stepwise selection- a limited treatment</h3>
<p>The basic idea behind stepwise selection is that we wish to create and test models in a variable-by-variable manner until only relevant variables are left in the model. The relevance of each variable is evaluated in turn relative to some pre-determined criterion.</p>
<p>While convenient, this approach has some well-known pitfalls. For example, it is easy to miss out on important relationships that are not considered because of the automated inclusion or exclusion of ‘significant’ explanatory variables and the order in which they are entered or dropped. This tool also does not include interaction terms that might be of biological interest by default.</p>
<div id="forward-selection" class="section level4">
<h4>Forward selection</h4>
<p>We start by making a “null” model with none of our variables (a model of the mean) and a full model with all of our explanatory variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">null=<span class="kw">lm</span>(Fertility<span class="op">~</span><span class="dv">1</span>, <span class="dt">data=</span>swiss) <span class="co"># 1 means include no x&#39;s</span>
full=<span class="kw">lm</span>(Fertility<span class="op">~</span>., <span class="dt">data=</span>swiss) <span class="co"># Dot means include all x&#39;s</span></code></pre></div>
<p>Now we perform the forward selection.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">step</span>(null, <span class="dt">scope=</span><span class="kw">list</span>(<span class="dt">lower=</span>null, <span class="dt">upper=</span>full), <span class="dt">direction =</span><span class="st">&#39;forward&#39;</span>)
Start<span class="op">:</span><span class="st">  </span>AIC=<span class="fl">238.35</span>
Fertility <span class="op">~</span><span class="st"> </span><span class="dv">1</span>

                   Df Sum of Sq    RSS    AIC
<span class="op">+</span><span class="st"> </span>Education         <span class="dv">1</span>    <span class="fl">3162.7</span> <span class="fl">4015.2</span> <span class="fl">213.04</span>
<span class="op">+</span><span class="st"> </span>Examination       <span class="dv">1</span>    <span class="fl">2994.4</span> <span class="fl">4183.6</span> <span class="fl">214.97</span>
<span class="op">+</span><span class="st"> </span>Catholic          <span class="dv">1</span>    <span class="fl">1543.3</span> <span class="fl">5634.7</span> <span class="fl">228.97</span>
<span class="op">+</span><span class="st"> </span>Infant.Mortality  <span class="dv">1</span>    <span class="fl">1245.5</span> <span class="fl">5932.4</span> <span class="fl">231.39</span>
<span class="op">+</span><span class="st"> </span>Agriculture       <span class="dv">1</span>     <span class="fl">894.8</span> <span class="fl">6283.1</span> <span class="fl">234.09</span>
<span class="op">&lt;</span>none<span class="op">&gt;</span><span class="st">                          </span><span class="fl">7178.0</span> <span class="fl">238.34</span>

Step<span class="op">:</span><span class="st">  </span>AIC=<span class="fl">213.04</span>
Fertility <span class="op">~</span><span class="st"> </span>Education

                   Df Sum of Sq    RSS    AIC
<span class="op">+</span><span class="st"> </span>Catholic          <span class="dv">1</span>    <span class="fl">961.07</span> <span class="fl">3054.2</span> <span class="fl">202.18</span>
<span class="op">+</span><span class="st"> </span>Infant.Mortality  <span class="dv">1</span>    <span class="fl">891.25</span> <span class="fl">3124.0</span> <span class="fl">203.25</span>
<span class="op">+</span><span class="st"> </span>Examination       <span class="dv">1</span>    <span class="fl">465.63</span> <span class="fl">3549.6</span> <span class="fl">209.25</span>
<span class="op">&lt;</span>none<span class="op">&gt;</span><span class="st">                          </span><span class="fl">4015.2</span> <span class="fl">213.04</span>
<span class="op">+</span><span class="st"> </span>Agriculture       <span class="dv">1</span>     <span class="fl">61.97</span> <span class="fl">3953.3</span> <span class="fl">214.31</span>

Step<span class="op">:</span><span class="st">  </span>AIC=<span class="fl">202.18</span>
Fertility <span class="op">~</span><span class="st"> </span>Education <span class="op">+</span><span class="st"> </span>Catholic

                   Df Sum of Sq    RSS    AIC
<span class="op">+</span><span class="st"> </span>Infant.Mortality  <span class="dv">1</span>    <span class="fl">631.92</span> <span class="fl">2422.2</span> <span class="fl">193.29</span>
<span class="op">+</span><span class="st"> </span>Agriculture       <span class="dv">1</span>    <span class="fl">486.28</span> <span class="fl">2567.9</span> <span class="fl">196.03</span>
<span class="op">&lt;</span>none<span class="op">&gt;</span><span class="st">                          </span><span class="fl">3054.2</span> <span class="fl">202.18</span>
<span class="op">+</span><span class="st"> </span>Examination       <span class="dv">1</span>      <span class="fl">2.46</span> <span class="fl">3051.7</span> <span class="fl">204.15</span>

Step<span class="op">:</span><span class="st">  </span>AIC=<span class="fl">193.29</span>
Fertility <span class="op">~</span><span class="st"> </span>Education <span class="op">+</span><span class="st"> </span>Catholic <span class="op">+</span><span class="st"> </span>Infant.Mortality

              Df Sum of Sq    RSS    AIC
<span class="op">+</span><span class="st"> </span>Agriculture  <span class="dv">1</span>   <span class="fl">264.176</span> <span class="fl">2158.1</span> <span class="fl">189.86</span>
<span class="op">&lt;</span>none<span class="op">&gt;</span><span class="st">                     </span><span class="fl">2422.2</span> <span class="fl">193.29</span>
<span class="op">+</span><span class="st"> </span>Examination  <span class="dv">1</span>     <span class="fl">9.486</span> <span class="fl">2412.8</span> <span class="fl">195.10</span>

Step<span class="op">:</span><span class="st">  </span>AIC=<span class="fl">189.86</span>
Fertility <span class="op">~</span><span class="st"> </span>Education <span class="op">+</span><span class="st"> </span>Catholic <span class="op">+</span><span class="st"> </span>Infant.Mortality <span class="op">+</span><span class="st"> </span>Agriculture

              Df Sum of Sq    RSS    AIC
<span class="op">&lt;</span>none<span class="op">&gt;</span><span class="st">                     </span><span class="fl">2158.1</span> <span class="fl">189.86</span>
<span class="op">+</span><span class="st"> </span>Examination  <span class="dv">1</span>    <span class="fl">53.027</span> <span class="fl">2105.0</span> <span class="fl">190.69</span>

Call<span class="op">:</span>
<span class="kw">lm</span>(<span class="dt">formula =</span> Fertility <span class="op">~</span><span class="st"> </span>Education <span class="op">+</span><span class="st"> </span>Catholic <span class="op">+</span><span class="st"> </span>Infant.Mortality <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>Agriculture, <span class="dt">data =</span> swiss)

Coefficients<span class="op">:</span>
<span class="st">     </span>(Intercept)         Education          Catholic  Infant.Mortality       Agriculture  
         <span class="fl">62.1013</span>           <span class="op">-</span><span class="fl">0.9803</span>            <span class="fl">0.1247</span>            <span class="fl">1.0784</span>           <span class="op">-</span><span class="fl">0.1546</span>  </code></pre></div>
<p>Here, we see that the best model is that which includes the additive effects of <code>Education</code>, <code>Catholic</code>, <code>Infant.Mortality</code>, and <code>Agriculture</code>.</p>
</div>
<div id="backward-selection" class="section level4">
<h4>Backward selection</h4>
<p>We can do backward selection using just the full model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="kw">step</span>(full, <span class="dt">data=</span>swiss, <span class="dt">direction =</span> <span class="st">&#39;backward&#39;</span>)
Start<span class="op">:</span><span class="st">  </span>AIC=<span class="fl">190.69</span>
Fertility <span class="op">~</span><span class="st"> </span>Agriculture <span class="op">+</span><span class="st"> </span>Examination <span class="op">+</span><span class="st"> </span>Education <span class="op">+</span><span class="st"> </span>Catholic <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>Infant.Mortality

                   Df Sum of Sq    RSS    AIC
<span class="op">-</span><span class="st"> </span>Examination       <span class="dv">1</span>     <span class="fl">53.03</span> <span class="fl">2158.1</span> <span class="fl">189.86</span>
<span class="op">&lt;</span>none<span class="op">&gt;</span><span class="st">                          </span><span class="fl">2105.0</span> <span class="fl">190.69</span>
<span class="op">-</span><span class="st"> </span>Agriculture       <span class="dv">1</span>    <span class="fl">307.72</span> <span class="fl">2412.8</span> <span class="fl">195.10</span>
<span class="op">-</span><span class="st"> </span>Infant.Mortality  <span class="dv">1</span>    <span class="fl">408.75</span> <span class="fl">2513.8</span> <span class="fl">197.03</span>
<span class="op">-</span><span class="st"> </span>Catholic          <span class="dv">1</span>    <span class="fl">447.71</span> <span class="fl">2552.8</span> <span class="fl">197.75</span>
<span class="op">-</span><span class="st"> </span>Education         <span class="dv">1</span>   <span class="fl">1162.56</span> <span class="fl">3267.6</span> <span class="fl">209.36</span>

Step<span class="op">:</span><span class="st">  </span>AIC=<span class="fl">189.86</span>
Fertility <span class="op">~</span><span class="st"> </span>Agriculture <span class="op">+</span><span class="st"> </span>Education <span class="op">+</span><span class="st"> </span>Catholic <span class="op">+</span><span class="st"> </span>Infant.Mortality

                   Df Sum of Sq    RSS    AIC
<span class="op">&lt;</span>none<span class="op">&gt;</span><span class="st">                          </span><span class="fl">2158.1</span> <span class="fl">189.86</span>
<span class="op">-</span><span class="st"> </span>Agriculture       <span class="dv">1</span>    <span class="fl">264.18</span> <span class="fl">2422.2</span> <span class="fl">193.29</span>
<span class="op">-</span><span class="st"> </span>Infant.Mortality  <span class="dv">1</span>    <span class="fl">409.81</span> <span class="fl">2567.9</span> <span class="fl">196.03</span>
<span class="op">-</span><span class="st"> </span>Catholic          <span class="dv">1</span>    <span class="fl">956.57</span> <span class="fl">3114.6</span> <span class="fl">205.10</span>
<span class="op">-</span><span class="st"> </span>Education         <span class="dv">1</span>   <span class="fl">2249.97</span> <span class="fl">4408.0</span> <span class="fl">221.43</span>

Call<span class="op">:</span>
<span class="kw">lm</span>(<span class="dt">formula =</span> Fertility <span class="op">~</span><span class="st"> </span>Agriculture <span class="op">+</span><span class="st"> </span>Education <span class="op">+</span><span class="st"> </span>Catholic <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>Infant.Mortality, <span class="dt">data =</span> swiss)

Coefficients<span class="op">:</span>
<span class="st">     </span>(Intercept)       Agriculture         Education          Catholic  Infant.Mortality  
         <span class="fl">62.1013</span>           <span class="op">-</span><span class="fl">0.1546</span>           <span class="op">-</span><span class="fl">0.9803</span>            <span class="fl">0.1247</span>            <span class="fl">1.0784</span>  </code></pre></div>
<p>In this case we end up with the same model. Note that this is not always the case.</p>
</div>
</div>
<div id="all-possible-models-all-subsets" class="section level3">
<h3>All possible models (all subsets)</h3>
<p>Just as the name states- compare all possible combinations of variables. This is largely an exploratory approach or is reserved for cases in which we care solely about prediction.</p>
<p>We will not discuss these techniques in this class because 1) they are usually not needed 2) they can lead to laziness in formulation of hypotheses and in a worst case data dredging, and 3) plain and simple: there are just better tools available for these purposes now (e.g. GAMM, CART, and network analysis).</p>
</div>
<div id="a-priori-model-subsets" class="section level3">
<h3><em>A priori</em> model subsets</h3>
<p>Consideration of only those models for which we have <em>a priori</em> reasons for inclusion. These are usually models that are designed to represented competing [biological] hypotheses or to balance those hypotheses within a framework for testing.</p>
<div id="multi-phase-heirarchical-selection" class="section level4">
<h4>Multi-phase (heirarchical) selection</h4>
<p>More later in the course…maybe</p>
<p>Essentially, this means that we impose some kind of hierarchy on the steps we take to test competing hypotheses. For instance, we might first wish to compare hypotheses about some process that we think is of greatest relevance, or some kind of underlying phenomenon that must be accounted for prior to investigating biological questions (e.g., detection probabilities in mark-recapture models). Then, we can use the best model(s) from that set of hypotheses as the basis for testing hypotheses about other processes of interest, taking into account previous findings. This becomes important if we are thinking about collinear effects of different explanatory variables on multiple (usually categorical) outcomes.</p>
</div>
<div id="single-phase-selection" class="section level4">
<h4>Single-phase selection</h4>
<p>We will discuss this in detail below.</p>
</div>
</div>
<div id="tools-for-a-priori-model-selection" class="section level3">
<h3>Tools for <em>a priori</em> model selection</h3>
<p>Here, we will focus on a few common approaches to model selection that can be useful in different situations. Although it is a popular alternative, we will not discuss Mallow’s Cp because it involves ‘all subset’ regression and we don’t want to get into that if we can help it. In truth, there are a limited number of exploratory purposes for which this selection method is useful, and in those cases thoughtful study design and alternative statistical approaches are often superior than throwing spaghetti at the wall and looking to see what sticks.</p>
<p>We <em>will</em> examine:</p>
<ul>
<li><p>Adjusted R<sup>2</sup></p></li>
<li><p>PRESS statistic</p></li>
<li><p>AIC</p></li>
</ul>
<blockquote>
<p>Let’s check some of these tools out!</p>
</blockquote>
<p>Start by fitting some models, we will use the <code>swiss</code> data again this week for the purpose of demonstrating selection tools because it is a noisy data set with lots of complexity.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&#39;swiss&#39;</span>)

<span class="co"># Fit the model that tests the</span>
<span class="co"># effects of education on the fertility index</span>
  mod.Ed =<span class="st"> </span><span class="kw">lm</span>(Fertility<span class="op">~</span>Education, <span class="dt">data=</span>swiss)
  
<span class="co"># Fit another model that tests</span>
<span class="co"># effects of % Catholic on Fertility</span>
  mod.Cath =<span class="st"> </span><span class="kw">lm</span>(Fertility<span class="op">~</span>Catholic, <span class="dt">data=</span>swiss)
  
<span class="co"># Fit a model with additive effects</span>
<span class="co"># of both explanatory variables</span>
  mod.EdCath =<span class="st"> </span><span class="kw">lm</span>(Fertility<span class="op">~</span>Education <span class="op">+</span><span class="st"> </span>Catholic, <span class="dt">data=</span>swiss)
  
<span class="co"># Fit a model with multiplicative</span>
<span class="co"># effects of both explanatory variables</span>
  mod.EdxCath =<span class="st"> </span><span class="kw">lm</span>(Fertility<span class="op">~</span>Education<span class="op">*</span>Catholic, <span class="dt">data=</span>swiss)</code></pre></div>
<p>Now we have four models that represent competing hypotheses:</p>
<p>1.<code>Education</code> alone is the best explanation among those considered for variability in <code>fertility</code>.</p>
<p>2.Percent <code>Catholic</code> alone is the best explanation among those considered for variability in <code>fertility</code>.</p>
<p>3.The additive effects of <code>Education</code> and percent <code>Catholic</code> are the best explanation among those considered for variability in <code>fertility</code>.</p>
<p>4.The interactive effects of <code>Education</code> and percent <code>Catholic</code> are the best explanation among those considered for variability in <code>fertility</code>.</p>
<p>Great, but how can we evaluate which of these hypotheses is best supported by our data?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Let&#39;s start by making all of our models into a list</span>
  mods =<span class="st"> </span><span class="kw">list</span>(mod.Ed, mod.Cath, mod.EdCath, mod.EdxCath)

<span class="co"># We&#39;ll give the list some names, too</span>
  <span class="kw">names</span>(mods) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;Ed&#39;</span>, <span class="st">&#39;Cath&#39;</span>, <span class="st">&#39;EdCath&#39;</span>, <span class="st">&#39;EdxCath&#39;</span>)</code></pre></div>
<div id="adjusted-r2" class="section level4">
<h4>Adjusted R<sup>2</sup></h4>
<p>This offers a relatively simple tool for model selection, and balances the number of parameters in the model with the number of observations in our data.</p>
<p>Just as before, we can look at the summary of our model objects that we have stored in this list.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Education only model, we can take a look, like this</span>
  <span class="kw">summary</span>(mods<span class="op">$</span>Ed)

Call<span class="op">:</span>
<span class="kw">lm</span>(<span class="dt">formula =</span> Fertility <span class="op">~</span><span class="st"> </span>Education, <span class="dt">data =</span> swiss)

Residuals<span class="op">:</span>
<span class="st">    </span>Min      1Q  Median      3Q     Max 
<span class="op">-</span><span class="fl">17.036</span>  <span class="op">-</span><span class="fl">6.711</span>  <span class="op">-</span><span class="fl">1.011</span>   <span class="fl">9.526</span>  <span class="fl">19.689</span> 

Coefficients<span class="op">:</span>
<span class="st">            </span>Estimate Std. Error t value <span class="kw">Pr</span>(<span class="op">&gt;</span><span class="er">|</span>t<span class="op">|</span>)    
(Intercept)  <span class="fl">79.6101</span>     <span class="fl">2.1041</span>  <span class="fl">37.836</span>  <span class="op">&lt;</span><span class="st"> </span><span class="fl">2e-16</span> <span class="op">**</span><span class="er">*</span>
Education    <span class="op">-</span><span class="fl">0.8624</span>     <span class="fl">0.1448</span>  <span class="op">-</span><span class="fl">5.954</span> <span class="fl">3.66e-07</span> <span class="op">**</span><span class="er">*</span>
<span class="op">---</span>
Signif. codes<span class="op">:</span><span class="st">  </span><span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span>

Residual standard error<span class="op">:</span><span class="st"> </span><span class="fl">9.446</span> on <span class="dv">45</span> degrees of freedom
Multiple R<span class="op">-</span>squared<span class="op">:</span><span class="st">  </span><span class="fl">0.4406</span>,    Adjusted R<span class="op">-</span>squared<span class="op">:</span><span class="st">  </span><span class="fl">0.4282</span> 
F<span class="op">-</span>statistic<span class="op">:</span><span class="st"> </span><span class="fl">35.45</span> on <span class="dv">1</span> and <span class="dv">45</span> DF,  p<span class="op">-</span>value<span class="op">:</span><span class="st"> </span><span class="fl">3.659e-07</span>

<span class="co"># REMEMBER: this model is an object stored in R,</span>
<span class="co"># so we can also look at the names of this summary,</span>
<span class="co"># like this</span>
  <span class="kw">names</span>(<span class="kw">summary</span>(mods<span class="op">$</span>Ed))
 [<span class="dv">1</span>] <span class="st">&quot;call&quot;</span>          <span class="st">&quot;terms&quot;</span>         <span class="st">&quot;residuals&quot;</span>     <span class="st">&quot;coefficients&quot;</span>  <span class="st">&quot;aliased&quot;</span>       <span class="st">&quot;sigma&quot;</span>         <span class="st">&quot;df&quot;</span>            <span class="st">&quot;r.squared&quot;</span>     <span class="st">&quot;adj.r.squared&quot;</span> <span class="st">&quot;fstatistic&quot;</span>    <span class="st">&quot;cov.unscaled&quot;</span> </code></pre></div>
<p><em>Whoa</em>, this is some heavy stuff. To recap, we have made a list of models, each of which are stored in R as lists. Each model has lots of elements, one of which is the summary of the model, which has its own elements that are named.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Here, we see that we can extract the adjusted </span>
<span class="co"># R-squared directly from the model summary</span>
  <span class="kw">summary</span>(mods<span class="op">$</span>Ed)<span class="op">$</span>adj.r.squared
[<span class="dv">1</span>] <span class="fl">0.4281849</span>
  <span class="kw">summary</span>(mods<span class="op">$</span>Cath)<span class="op">$</span>adj.r.squared
[<span class="dv">1</span>] <span class="fl">0.1975591</span>
  <span class="kw">summary</span>(mods<span class="op">$</span>EdCath)<span class="op">$</span>adj.r.squared
[<span class="dv">1</span>] <span class="fl">0.5551665</span>
  <span class="kw">summary</span>(mods<span class="op">$</span>EdxCath)<span class="op">$</span>adj.r.squared
[<span class="dv">1</span>] <span class="fl">0.5700628</span></code></pre></div>
<p>When we compare adjusted R<sup>2</sup>, <strong>the model with the highest R<sup>2</sup> is the “best model”</strong>. So, in this case, we would conclude that <code>EdxCath</code> is the best model.</p>
</div>
<div id="press-statistic-predicted-sum-of-squares" class="section level4">
<h4>PRESS statistic (Predicted sum of squares)</h4>
<p>To use the PRESS statistic in R, we need to load a new package. Yay!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#install.packages(&#39;qpcR&#39;)</span>
 <span class="kw">library</span>(qpcR)

<span class="co"># Let&#39;s start with a single example. </span>
<span class="co"># Here, we are given three things in the</span>
<span class="co"># output from the &#39;PRESS&#39; function.</span>
  <span class="kw">PRESS</span>(mods<span class="op">$</span>Ed)
.........<span class="dv">10</span>.........<span class="dv">20</span>.........<span class="dv">30</span>.........<span class="dv">40</span>.......
<span class="op">$</span>stat
[<span class="dv">1</span>] <span class="fl">4323.733</span>

<span class="op">$</span>residuals
 [<span class="dv">1</span>]  <span class="fl">11.1787318</span>  <span class="fl">11.5065064</span>  <span class="fl">17.7278799</span>  <span class="fl">12.5398747</span>  <span class="fl">10.4882280</span>   <span class="fl">2.5911695</span>  <span class="fl">10.4885953</span>  <span class="fl">20.1597326</span>   <span class="fl">9.0526997</span>  <span class="fl">14.8302796</span>  <span class="fl">13.0168641</span>  <span class="op">-</span><span class="fl">5.2753911</span>  <span class="op">-</span><span class="fl">6.8447158</span>  <span class="op">-</span><span class="fl">0.3698141</span> <span class="op">-</span><span class="fl">14.0142691</span>  <span class="op">-</span><span class="fl">9.9871628</span>
[<span class="dv">17</span>]  <span class="op">-</span><span class="fl">1.0354472</span>   <span class="fl">0.2588946</span>  <span class="op">-</span><span class="fl">8.4026213</span>  <span class="op">-</span><span class="fl">6.9021136</span>  <span class="op">-</span><span class="fl">5.6071189</span> <span class="op">-</span><span class="fl">12.4751694</span> <span class="op">-</span><span class="fl">12.9403552</span> <span class="op">-</span><span class="fl">17.5105794</span>  <span class="op">-</span><span class="fl">6.5399771</span>   <span class="fl">1.5243571</span>  <span class="op">-</span><span class="fl">5.2119131</span> <span class="op">-</span><span class="fl">10.7169905</span>  <span class="op">-</span><span class="fl">5.1114868</span>  <span class="op">-</span><span class="fl">7.4861541</span>  <span class="op">-</span><span class="fl">2.4853488</span>  <span class="op">-</span><span class="fl">5.2790448</span>
[<span class="dv">33</span>]  <span class="op">-</span><span class="fl">0.6098953</span>  <span class="op">-</span><span class="fl">4.0456127</span>   <span class="fl">2.4663864</span>  <span class="op">-</span><span class="fl">7.0043837</span>  <span class="fl">15.7477692</span>  <span class="fl">11.1484049</span>   <span class="fl">1.1631787</span>  <span class="op">-</span><span class="fl">4.5203842</span>   <span class="fl">4.3983013</span>  <span class="fl">14.1573518</span>   <span class="fl">4.1296291</span>  <span class="op">-</span><span class="fl">6.1267680</span>   <span class="fl">1.9422167</span> <span class="op">-</span><span class="fl">10.9733208</span> <span class="op">-</span><span class="fl">13.0789076</span>

<span class="op">$</span>P.square
[<span class="dv">1</span>] <span class="fl">0.3976372</span>
  
<span class="co"># What we are really interested in here is the</span>
<span class="co"># first element in this list, the PRESS statistic.</span>
<span class="co"># We can call this statistic out by name</span>
  <span class="kw">PRESS</span>(mods<span class="op">$</span>Ed)<span class="op">$</span>stat
.........<span class="dv">10</span>.........<span class="dv">20</span>.........<span class="dv">30</span>.........<span class="dv">40</span>.......
[<span class="dv">1</span>] <span class="fl">4323.733</span>
  <span class="kw">PRESS</span>(mods<span class="op">$</span>Cath)<span class="op">$</span>stat
.........<span class="dv">10</span>.........<span class="dv">20</span>.........<span class="dv">30</span>.........<span class="dv">40</span>.......
[<span class="dv">1</span>] <span class="fl">6036.623</span>
  <span class="kw">PRESS</span>(mods<span class="op">$</span>EdCath)<span class="op">$</span>stat
.........<span class="dv">10</span>.........<span class="dv">20</span>.........<span class="dv">30</span>.........<span class="dv">40</span>.......
[<span class="dv">1</span>] <span class="fl">3490.614</span>
  <span class="kw">PRESS</span>(mods<span class="op">$</span>EdxCath)<span class="op">$</span>stat
.........<span class="dv">10</span>.........<span class="dv">20</span>.........<span class="dv">30</span>.........<span class="dv">40</span>.......
[<span class="dv">1</span>] <span class="fl">3455.346</span></code></pre></div>
<p><strong>The model with the lowest PRESS statistic is the best model</strong>. The meaning of this statistic is that the model is not “internally” sensitive the the data points. We can draw this interpretation because PRESS is a form of cross validation (which we will discuss later this week).</p>
<p>So, these are nice tools, but they are based almost exclusively on the sums of squares for our regressions, so they don’t take much into account redundancy in the parameters of the regression, and they don’t apply to models that can’t be fit with least squares estimation. This leads to some problems…</p>
<ol style="list-style-type: decimal">
<li><p>Most of the time we are using maximum likelihood estimation for these techniques, and it would be nice to have a tool that takes into account the actual likelihood of the models.</p></li>
<li><p>These tools don’t allow us to determine <em>how much</em> better one model is than another.</p></li>
<li><p>We have no way to communicate the uncertainty in model selection, nor any simple method for incorporating this uncertainty into our model predictions.</p></li>
</ol>
</div>
<div id="information-theoretic-approaches" class="section level4">
<h4>Information theoretic approaches</h4>
<h5 id="multi">
Akaike’s information criterion (AIC)
</h5>
<p>This tool (or the popular alternative, BIC) will be more useful for us during the next several weeks than any of the previous methods because it allows us to draw inference based on the likelihood of the model rather than the sums of squares, which we will learn that GLMs and other generalizations do not have!</p>
<p>Information-theoretic approaches to model selection are based on the trade off in information gained through addition of parameters and the added complexity of the models, with respect to sample size. I will hold off on a detailed explanation because you will learn more about this tool in your readings. So, let’s cut straight to the chase.</p>
<p>Remember that we made a list of <em>a priori</em> models above that we would like to consider.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Get the names of those models</span>
  <span class="kw">names</span>(mods)
[<span class="dv">1</span>] <span class="st">&quot;Ed&quot;</span>      <span class="st">&quot;Cath&quot;</span>    <span class="st">&quot;EdCath&quot;</span>  <span class="st">&quot;EdxCath&quot;</span>

<span class="co"># We can strip the AIC values from each</span>
<span class="co"># of the model objects using a</span>
<span class="co"># function from the apply family:</span>
  <span class="kw">mapply</span>(<span class="dt">FUN =</span> <span class="st">&#39;AIC&#39;</span>, mods)
      Ed     Cath   EdCath  EdxCath 
<span class="fl">348.4223</span> <span class="fl">364.3479</span> <span class="fl">337.5636</span> <span class="fl">336.8823</span> </code></pre></div>
<p>Now we have a named vector holding AIC values for each of our named models. At a glance, we can see that our model with the interaction is the ‘best’ model in the set as indicated by our other statistics, but this time it is only better by less than 1 AIC (<strong>lower AIC is better</strong>). Can we say anything about that?</p>
<p>Funny you should ask. Yes, we can. We have a few general rules of thumb for interpreting the AIC statistic, and we can actually derive a whole set of statistics based on these rankings.</p>
<blockquote>
<p>Open can of worms…</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># First, we need another library</span>
  <span class="co">#install.packages(&#39;AICcmodavg&#39;)</span>
  <span class="kw">library</span>(AICcmodavg)

<span class="co"># Let&#39;s start digging into this stuff</span>
<span class="co"># by making a table that can help us along. </span>
  <span class="kw">aictab</span>(<span class="dt">cand.set =</span> mods, <span class="dt">modnames =</span> <span class="kw">names</span>(mods))

Model selection based on AICc<span class="op">:</span>

<span class="st">        </span>K   AICc Delta_AICc AICcWt Cum.Wt      LL
EdxCath <span class="dv">5</span> <span class="fl">338.35</span>       <span class="fl">0.00</span>   <span class="fl">0.52</span>   <span class="fl">0.52</span> <span class="op">-</span><span class="fl">163.44</span>
EdCath  <span class="dv">4</span> <span class="fl">338.52</span>       <span class="fl">0.17</span>   <span class="fl">0.48</span>   <span class="fl">1.00</span> <span class="op">-</span><span class="fl">164.78</span>
Ed      <span class="dv">3</span> <span class="fl">348.98</span>      <span class="fl">10.63</span>   <span class="fl">0.00</span>   <span class="fl">1.00</span> <span class="op">-</span><span class="fl">171.21</span>
Cath    <span class="dv">3</span> <span class="fl">364.91</span>      <span class="fl">26.56</span>   <span class="fl">0.00</span>   <span class="fl">1.00</span> <span class="op">-</span><span class="fl">179.17</span></code></pre></div>
<p>Lots going on here…What does it all mean?</p>
<p>From left to right</p>
<p>First, notice that the rownames are actually our model names</p>
<p><strong><code>K</code></strong> is the number of parameters in each of the models</p>
<p><strong><code>AICc</code></strong> is the AIC score, but it is corrected for sample size. Generally speaking, this means models with many parameters and small number of observations are penalized for potential instability in the likelihood. In general, using the AIC<sub>c</sub> is almost always a practical approach because it is conservative and the effect of the penalty goes away with sufficiently large sample sizes.</p>
<p><strong><code>Delta_AICc</code></strong> is the difference in AIC<sub>c</sub> between the best model and each of the other models.</p>
<p><strong><code>AICcWt</code></strong> is the probability that a given model is the best model in the candidate set.</p>
<p><strong><code>Cum.Wt</code></strong> is the cumulative weights represented by each of the models from best to last. This can be used to create a 95% confidence set of models.</p>
<p><strong><code>LL</code></strong> is the log likelihood of each model, the very same discussed at the beginning of our discussions about probability distributions!</p>
<div id="interpreting-the-model-selection-table" class="section level5">
<h5>Interpreting the model selection table</h5>
<p><strong>In general</strong>:</p>
<p>A lower AIC is better.</p>
<p>Models with <span class="math inline">\(\Delta\)</span>AIC<sub>c</sub> of less than 2.0 are considered to have similar support as the best model. Models with <span class="math inline">\(\Delta\)</span>AIC<sub>c</sub> from 2 to 4 have some support in the data, but not as much. Models with <span class="math inline">\(\Delta\)</span>AIC<sub>c</sub> &gt; 4 have virtually no support.</p>
<p>The ratio of AIC weights (w<sub>i</sub>)can be used to interpret the improvement between the best model and each subsequent model. In this example, the best model is only <span class="math inline">\(\frac{0.52}{0.48} = 1.08 \times\)</span> better supported than the next best model, but the best two models have all of the support.</p>
<p>Our results suggest that <code>Education</code> and <code>Catholic</code> are the both important in explaining the variation in <code>Fertility</code>, because both are included in any model receiving any support in the candidate set.</p>
<p>Unlike our previous results, we have no clear winner in this case, and we are left wondering whether it is the additive effects or the multiplicative effects of <code>Education</code> and <code>Catholic</code> that are important. But, we still may want to get estimates for our main effects, at least, so we can make some good solid inference on the effect sizes. If only we had a method for dealing with this uncertainty now…Oh wait, we do!</p>
<p>Using model averaging to account for the model uncertainty, we can see that the unconditional confidence interval for <code>Education</code> is negative and does not overlap zero, and the opposite trend is evident in the trend for <code>Catholic</code>. We also find out that the interaction between <code>Education</code> and <code>Catholic</code> is actually not significant, which is probably why the main effects model had equivelent support in the candidate set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">modavg</span>(mods, <span class="dt">parm =</span> <span class="st">&#39;Education&#39;</span>, <span class="dt">modnames =</span> <span class="kw">names</span>(mods),
       <span class="dt">conf.level =</span> .<span class="dv">95</span>, <span class="dt">exclude =</span> <span class="ot">TRUE</span>)

Multimodel inference on <span class="st">&quot;Education&quot;</span> based on AICc

AICc table used to obtain model<span class="op">-</span>averaged estimate<span class="op">:</span>

<span class="st">        </span>K   AICc Delta_AICc AICcWt Estimate   SE
Ed      <span class="dv">3</span> <span class="fl">348.98</span>      <span class="fl">10.63</span>   <span class="fl">0.00</span>    <span class="op">-</span><span class="fl">0.86</span> <span class="fl">0.14</span>
EdCath  <span class="dv">4</span> <span class="fl">338.52</span>       <span class="fl">0.17</span>   <span class="fl">0.48</span>    <span class="op">-</span><span class="fl">0.79</span> <span class="fl">0.13</span>
EdxCath <span class="dv">5</span> <span class="fl">338.35</span>       <span class="fl">0.00</span>   <span class="fl">0.52</span>    <span class="op">-</span><span class="fl">0.43</span> <span class="fl">0.26</span>

Model<span class="op">-</span>averaged estimate<span class="op">:</span><span class="st"> </span><span class="op">-</span><span class="fl">0.6</span> 
Unconditional SE<span class="op">:</span><span class="st"> </span><span class="fl">0.28</span> 
<span class="dv">95</span>% Unconditional confidence interval<span class="op">:</span><span class="st"> </span><span class="op">-</span><span class="fl">1.14</span>, <span class="op">-</span><span class="fl">0.06</span>
<span class="kw">modavg</span>(mods, <span class="dt">parm =</span> <span class="st">&#39;Catholic&#39;</span>, <span class="dt">modnames =</span> <span class="kw">names</span>(mods),
       <span class="dt">conf.level =</span> .<span class="dv">95</span>, <span class="dt">exclude =</span> <span class="ot">TRUE</span>)

Multimodel inference on <span class="st">&quot;Catholic&quot;</span> based on AICc

AICc table used to obtain model<span class="op">-</span>averaged estimate<span class="op">:</span>

<span class="st">        </span>K   AICc Delta_AICc AICcWt Estimate   SE
Cath    <span class="dv">3</span> <span class="fl">364.91</span>      <span class="fl">26.56</span>   <span class="fl">0.00</span>     <span class="fl">0.14</span> <span class="fl">0.04</span>
EdCath  <span class="dv">4</span> <span class="fl">338.52</span>       <span class="fl">0.17</span>   <span class="fl">0.48</span>     <span class="fl">0.11</span> <span class="fl">0.03</span>
EdxCath <span class="dv">5</span> <span class="fl">338.35</span>       <span class="fl">0.00</span>   <span class="fl">0.52</span>     <span class="fl">0.18</span> <span class="fl">0.05</span>

Model<span class="op">-</span>averaged estimate<span class="op">:</span><span class="st"> </span><span class="fl">0.15</span> 
Unconditional SE<span class="op">:</span><span class="st"> </span><span class="fl">0.06</span> 
<span class="dv">95</span>% Unconditional confidence interval<span class="op">:</span><span class="st"> </span><span class="fl">0.04</span>, <span class="fl">0.26</span>
<span class="kw">modavg</span>(mods, <span class="dt">parm =</span> <span class="st">&#39;Education:Catholic&#39;</span>, <span class="dt">modnames =</span> <span class="kw">names</span>(mods),
       <span class="dt">conf.level =</span> .<span class="dv">95</span>, <span class="dt">exclude =</span> <span class="ot">TRUE</span>)

Multimodel inference on <span class="st">&quot;Education:Catholic&quot;</span> based on AICc

AICc table used to obtain model<span class="op">-</span>averaged estimate<span class="op">:</span>

<span class="st">        </span>K   AICc Delta_AICc AICcWt Estimate   SE
EdxCath <span class="dv">5</span> <span class="fl">338.35</span>          <span class="dv">0</span>      <span class="dv">1</span>    <span class="op">-</span><span class="fl">0.01</span> <span class="fl">0.01</span>

Model<span class="op">-</span>averaged estimate<span class="op">:</span><span class="st"> </span><span class="op">-</span><span class="fl">0.01</span> 
Unconditional SE<span class="op">:</span><span class="st"> </span><span class="fl">0.01</span> 
<span class="dv">95</span>% Unconditional confidence interval<span class="op">:</span><span class="st"> </span><span class="op">-</span><span class="fl">0.02</span>, <span class="dv">0</span></code></pre></div>
<p>Isn’t that fantastic? From here we could move on to make predictions based on the model-averaged parameter estimates using what you learned last week. But…what if we weren’t convinced so easily and wanted a reliable means of seeing how well our model actually performs now that we’ve selected one (or more)? More on this below…</p>
<p>The simple fact of the matter is that we have selected a “best” model, but that doesn’t mean our model is necessarily a “good” model.</p>
</div>
</div>
</div>
</div>
<div id="model-validation" class="section level2">
<h2>Model validation</h2>
<p>Once we have selected a best model, or a set of explanatory variables that we want to consider in our analysis, it is important that we validate that model when possible. In truth, comparison of the validity of multiple models can even be a method for model selection in itself, but we are not going to go there this semester because it would require a much richer understanding of programming than we can achieve in a week.</p>
<div id="what-is-model-validation" class="section level3">
<h3>What is model validation?</h3>
<p>Model validation is the use of external data, or subsets of data that we have set aside for use in assessing the predictive ability of our models. That is, we can use new data to test how well our model works for making predictions about the system of interest. Pretty cool, I know!</p>
<p>There are lots of different methods for model validation, each of which uses some of your data for fitting (or <strong>training</strong>) the model and then saves some of the data for predicting new observations based on your model parameters (<strong>testing</strong>). We can do this by hand if we want to, but for the sake of this course, let’s avoid the extraneous programming knowledge required for this and just use some of the built-in functions in readily available R packages.</p>
<p>Very generally speaking, there are a large (near-infinite) number of ways to do model validation based on how you split up your data set and how you choose to evaluate predictions. This <a href="http://machinelearningmastery.com/how-to-estimate-model-accuracy-in-r-using-the-caret-package/">blog</a> gives a nice overview of these methods with the <code>iris</code> data set in R using the <code>caret</code> package.</p>
</div>
<div id="worked-example" class="section level3">
<h3>Worked example</h3>
<p>Let’s work an example for the models we built for the swiss data above. We do this ‘by hand’ to show how this works:</p>
<div id="leave-one-out-cross-validation" class="section level4">
<h4>Leave-one-out cross validation</h4>
<p>First, make a couple of empty vectors to hold our training data and our predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  ed.obs =<span class="st"> </span><span class="kw">c</span>()  <span class="co"># Will hold observation witheld for each iteration</span>
  ed.pred =<span class="st"> </span><span class="kw">c</span>() <span class="co"># Will hold our prediction for each iteration</span></code></pre></div>
<p>Now, drop one data point, fit the model, and predict the missing data point one row at a time until you have done them all.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Repeat this for each row of the data set</span>
<span class="co"># until we have left each out</span>
  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(swiss)){

<span class="co"># Sample the data, leaving out one row</span>
  <span class="co"># These will be our &#39;training data&#39;</span>
    data.train =<span class="st"> </span>swiss[<span class="op">-</span>i, ]
  <span class="co"># These will be the data we use for prediction</span>
    data.pred =<span class="st"> </span>swiss[(<span class="kw">rownames</span>(swiss) <span class="op">%in%</span>
<span class="st">                       </span><span class="kw">rownames</span>(data.train))<span class="op">==</span><span class="ot">FALSE</span>,]

<span class="co"># Fit the model that tests the effects of Education</span>
<span class="co"># on the Fertility</span>
  mod.Ed =<span class="st"> </span><span class="kw">lm</span>(Fertility<span class="op">~</span>Education, <span class="dt">data=</span>swiss)

<span class="co"># Predict Fertility from the fitted model and store</span>
  ed.pred[i] =<span class="st"> </span><span class="kw">predict</span>(mod.Ed, data.pred)
  ed.obs[i] =<span class="st"> </span>data.pred<span class="op">$</span>Fertility
}</code></pre></div>
<p>Now, We can look at a plot to subjectively judge the fit.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set plot margins</span>
  <span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">1</span>,<span class="dv">1</span>))

<span class="co"># Plot the predictions against the observed value</span>
<span class="co"># that we left out, do for each iteration.</span>
  <span class="kw">plot</span>(ed.obs, ed.pred, <span class="dt">pch=</span><span class="dv">21</span>, <span class="dt">bg=</span><span class="st">&#39;black&#39;</span>,
       <span class="dt">col=</span><span class="st">&#39;black&#39;</span>, <span class="dt">yaxt=</span><span class="st">&#39;n&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>, <span class="dt">cex.axis=</span><span class="fl">1.1</span>,
       <span class="dt">cex.lab=</span><span class="fl">1.15</span>, <span class="dt">ylab=</span><span class="st">&#39;Predicted&#39;</span>, <span class="dt">xlab =</span> <span class="st">&#39;Observed&#39;</span>)
  
<span class="co"># Add the rotated y-axis</span>
  <span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">las=</span><span class="dv">2</span>, <span class="dt">cex.axis=</span><span class="fl">1.1</span>)</code></pre></div>
<p><img src="06_modelSelection_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>We could also look at a regression of our predictions on the observed data used for predictions to see how good we are. In this case, not great!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit the model</span>
  pred.line =<span class="st"> </span><span class="kw">lm</span>(ed.obs<span class="op">~</span>ed.pred)
<span class="co"># Summarize the model</span>
  <span class="kw">summary</span>(pred.line)

Call<span class="op">:</span>
<span class="kw">lm</span>(<span class="dt">formula =</span> ed.obs <span class="op">~</span><span class="st"> </span>ed.pred)

Residuals<span class="op">:</span>
<span class="st">    </span>Min      1Q  Median      3Q     Max 
<span class="op">-</span><span class="fl">17.036</span>  <span class="op">-</span><span class="fl">6.711</span>  <span class="op">-</span><span class="fl">1.011</span>   <span class="fl">9.526</span>  <span class="fl">19.689</span> 

Coefficients<span class="op">:</span>
<span class="st">              </span>Estimate Std. Error t value <span class="kw">Pr</span>(<span class="op">&gt;</span><span class="er">|</span>t<span class="op">|</span>)    
(Intercept) <span class="op">-</span><span class="fl">1.658e-14</span>  <span class="fl">1.186e+01</span>   <span class="fl">0.000</span>        <span class="dv">1</span>    
ed.pred      <span class="fl">1.000e+00</span>  <span class="fl">1.680e-01</span>   <span class="fl">5.954</span> <span class="fl">3.66e-07</span> <span class="op">**</span><span class="er">*</span>
<span class="op">---</span>
Signif. codes<span class="op">:</span><span class="st">  </span><span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span>

Residual standard error<span class="op">:</span><span class="st"> </span><span class="fl">9.446</span> on <span class="dv">45</span> degrees of freedom
Multiple R<span class="op">-</span>squared<span class="op">:</span><span class="st">  </span><span class="fl">0.4406</span>,    Adjusted R<span class="op">-</span>squared<span class="op">:</span><span class="st">  </span><span class="fl">0.4282</span> 
F<span class="op">-</span>statistic<span class="op">:</span><span class="st"> </span><span class="fl">35.45</span> on <span class="dv">1</span> and <span class="dv">45</span> DF,  p<span class="op">-</span>value<span class="op">:</span><span class="st"> </span><span class="fl">3.659e-07</span>
<span class="co"># Extract the R-squared for observed vs predicted</span>
  <span class="kw">summary</span>(pred.line)<span class="op">$</span>r.squared
[<span class="dv">1</span>] <span class="fl">0.4406156</span>
          
<span class="co"># Plot predictive line</span>
<span class="co"># Get coefficients</span>
  <span class="kw">summary</span>(pred.line)<span class="op">$</span>coefficients
                 Estimate Std. Error       t value     <span class="kw">Pr</span>(<span class="op">&gt;</span><span class="er">|</span>t<span class="op">|</span>)
(Intercept) <span class="op">-</span><span class="fl">1.658293e-14</span> <span class="fl">11.8617938</span> <span class="op">-</span><span class="fl">1.398012e-15</span> <span class="fl">1.000000e+00</span>
ed.pred      <span class="fl">1.000000e+00</span>  <span class="fl">0.1679651</span>  <span class="fl">5.953619e+00</span> <span class="fl">3.658617e-07</span>
<span class="co"># Use sequence of new data</span>
  pred.pts =<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">seq</span>(<span class="kw">min</span>(ed.obs), <span class="kw">max</span>(ed.obs), <span class="dv">1</span>))
  <span class="kw">names</span>(pred.pts) =<span class="st"> &#39;ed.pred&#39;</span>
<span class="co"># Make predictions using coefficients from regression</span>
  pred=<span class="st"> </span><span class="kw">predict</span>(pred.line, pred.pts, <span class="dt">interval=</span><span class="st">&#39;prediction&#39;</span>)

<span class="co"># Plot the data again (same as above)</span>
  <span class="kw">plot</span>(ed.obs, ed.pred, <span class="dt">pch=</span><span class="dv">21</span>, <span class="dt">bg=</span><span class="st">&#39;black&#39;</span>,
       <span class="dt">col=</span><span class="st">&#39;gray87&#39;</span>, <span class="dt">yaxt=</span><span class="st">&#39;n&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>, <span class="dt">cex.axis=</span><span class="fl">1.1</span>,
       <span class="dt">cex.lab=</span><span class="fl">1.15</span>, <span class="dt">ylab=</span><span class="st">&#39;Predicted&#39;</span>, <span class="dt">xlab =</span> <span class="st">&#39;Observed&#39;</span>)
  <span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">las=</span><span class="dv">2</span>, <span class="dt">cex.axis=</span><span class="fl">1.1</span>)  
  
<span class="co"># Plot the lines</span>
  <span class="kw">lines</span>(pred.pts[,<span class="dv">1</span>], pred[,<span class="dv">1</span>], <span class="dt">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">lwd=</span><span class="dv">3</span>)
  <span class="kw">lines</span>(pred.pts[,<span class="dv">1</span>], pred[,<span class="dv">2</span>], <span class="dt">col =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
  <span class="kw">lines</span>(pred.pts[,<span class="dv">1</span>], pred[,<span class="dv">3</span>], <span class="dt">col =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="06_modelSelection_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>There are lots of other takes on cross-validation, including popular approaches such as k-fold cross-validation, and a number of simulation-based tools: many of which can be implemented in wrappers available through various R packages. I will leave you to explore these in your leisure time. In general, the more data that are set aside, the more robust the validation is, but we usually don’t want to set aside so much of our data that the training model isn’t representative of the data we’ve collected.</p>
</div>
<div id="boot-strapping-method" class="section level4">
<h4>Boot-strapping method</h4>
<p>Boot strapping (or “jack-knifing”) is similar to cross validation in that we leave out some chunk of data and fit a model. The only difference here is that we are randomly selecting the training data each time, rather than working our way through the data systematically. The only difficulty now becomes choosing the appropriate amount of data to leave out for this validation tool…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># First, make an empty vector to</span>
<span class="co"># hold our training and predicting data</span>
  p.Rsquare =<span class="st"> </span><span class="kw">c</span>()

<span class="co"># We will randomly sample our data 10,000 times</span>
  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="fl">1e4</span>){

<span class="co"># Sample the data, taking only 22 </span>
<span class="co"># data points (about half the data).</span>
<span class="co"># These will be our &#39;training data&#39;</span>
  data.train=swiss[<span class="kw">sample</span>(<span class="kw">nrow</span>(swiss), <span class="dv">22</span>, <span class="dt">replace=</span><span class="ot">FALSE</span>) , ]
  
<span class="co"># These will be the data we use for prediction:</span>
  data.pred=swiss[(<span class="kw">rownames</span>(swiss) <span class="op">%in%</span><span class="st"> </span>
<span class="st">                   </span><span class="kw">rownames</span>(data.train))<span class="op">==</span><span class="ot">FALSE</span>,]

<span class="co"># Fit the model that tests the </span>
<span class="co"># effects of education on the fertility index</span>
  mod.Ed =<span class="st"> </span><span class="kw">lm</span>(Fertility<span class="op">~</span>Education, <span class="dt">data=</span>swiss)

<span class="co"># Predict fertility from the fitted</span>
<span class="co"># model and store the result</span>
  ed.pred =<span class="st"> </span><span class="kw">predict</span>(mod.Ed, data.pred)
  ed.obs =<span class="st"> </span>data.pred<span class="op">$</span>Fertility

<span class="co"># Get predictive R-squared</span>
  p.Rsquare[i] =<span class="st"> </span><span class="kw">summary</span>(<span class="kw">lm</span>(ed.pred<span class="op">~</span>ed.obs))<span class="op">$</span>r.squared

}</code></pre></div>
<p>We can now calculate the median predicted R-squared and the 95% CI on this test statistic</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="kw">median</span>(p.Rsquare)
[<span class="dv">1</span>] <span class="fl">0.4542436</span>
  <span class="kw">quantile</span>(p.Rsquare, <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))
     <span class="fl">2.5</span><span class="op">%     97.5%</span><span class="st"> </span>
<span class="fl">0.1080989</span> <span class="fl">0.6225763</span> </code></pre></div>
<p>We can look at the distribution of our r-squared values for regressions that measure the fit between our predictions and our observations</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plot the histogram</span>
  <span class="kw">hist</span>(p.Rsquare, <span class="dt">breaks=</span><span class="dv">100</span>, <span class="dt">yaxt=</span><span class="st">&#39;n&#39;</span>, <span class="dt">xaxt=</span><span class="st">&#39;n&#39;</span>,
       <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">5e2</span>), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,.<span class="dv">75</span>), <span class="dt">col=</span><span class="st">&#39;gray87&#39;</span>,
       <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="st">&#39;Predicted R&#39;</span><span class="op">^</span><span class="st">&#39;2&#39;</span>),
       <span class="dt">main=</span><span class="st">&#39;&#39;</span>, <span class="dt">cex.lab=</span><span class="fl">1.3</span>)

  <span class="co"># Add some axis labels in position them</span>
  <span class="co"># in the correct spot</span>
    <span class="kw">axis</span>(<span class="dv">1</span>, <span class="dt">cex.axis=</span><span class="fl">1.1</span>, <span class="dt">pos=</span><span class="dv">0</span>)
    <span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">las=</span><span class="dv">2</span>, <span class="dt">cex.axis=</span><span class="fl">1.1</span>, <span class="dt">pos=</span><span class="dv">0</span>)
    
  <span class="co"># Add a blue vertical line for the median</span>
  <span class="co"># of our predicted R-squared</span>
    <span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">median</span>(p.Rsquare),
           <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
    <span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">quantile</span>(p.Rsquare, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>)),
           <span class="dt">col=</span><span class="st">&#39;red&#39;</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>)    </code></pre></div>
<p><img src="06_modelSelection_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>This approach is not only useful for cross-validation, but can also be a good tool for assessing a priori statistical power based on some estimates of variance, effect sizes, and variable sample sizes. We recently used the approach to do this for <a href="https://www.sciencedirect.com/science/article/pii/S1470160X19300731?utm_campaign=STMJ_75273_AUTH_SERV_PPUB&utm_medium=email&utm_dgroup=Email1Publishing&utm_acid=252084706&SIS_ID=-1&dgcid=STMJ_75273_AUTH_SERV_PPUB&CMX_ID=&utm_in=DM461565&utm_source=AC_30">community metrics in brook trout streams</a> in NY so we could determine what sampling intensity was needed to detect biologically meaningful responses to acid rain recovery. Such investigations allow us to plan our studies ahead of time and potentially save time and money, in addition to serving as validation tools.</p>
</div>
</div>
</div>

<!DOCTYPE html>

<br>

<hr>

<p style="color:gray; text-align:center">This work is licensed under a <a href="https://creativecommons.org/licenses/by/4.0/legalcode">Creative Commons Attribution 4.0 International License</a>. Data are provided for educational purposes only unless otherwise noted.</p>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
