<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<!DOCTYPE html>
<head>
<!-- Favicon for various operating systems -->
<link rel="apple-touch-icon" sizes="180x180" href="./favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="./favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="./favicon/favicon-16x16.png">
<!-- <link rel="manifest" href="./favicon/site.webmanifest"> -->
<link rel="mask-icon" href="./favicon/safari-pinned-tab.svg" color="#603cba">
<link rel="shortcut icon" href="./favicon/favicon.ico">
<meta name="msapplication-TileColor" content="#603cba">
<meta name="msapplication-config" content="./favicon/browserconfig.xml">
<meta name="theme-color" content="#382121">
</head>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">danStich</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../../index.html">Home</a>
</li>
<li>
  <a href="../../teaching.html">Teaching</a>
</li>
<li>
  <a href="../../research.html">Research</a>
</li>
<li>
  <a href="../../cv.html">Curriculum vitae</a>
</li>
<li>
  <a href="../../courseWebsites.html">Course websites</a>
</li>
<li>
  <a href="../../contact.html">Contact</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<style>
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}

.column {
    float: left;
    padding: 15px;
}

.clearfix::after {
    content: "";
    clear: both;
    display: table;
}

.content {
    width: 75%;
}

</style>
<p><br></p>
<div id="generalized-linear-mixed-models-glmm" class="section level2">
<h2>Generalized linear mixed models (GLMM)</h2>
<p><br></p>
<p>This week in lecture, we introduced the generalized linear mixed model (GLMM). As we have discussed, the GLMM is to the linear mixed model as the GLM is to the general linear model (ANOVA, linear regression, ANCOVA, etc.). That is to say, the GLMM is just an LMM that assumes some error distribution other than normal. This week in lab, we will practice running GLMMs using restricted maximum likelihood estimation (REML) in the <code>lme4</code> package in R, and using Bayesian estimation in JAGS through the <code>R2jags</code> package in R. We will play with a couple of different data sets this week, and give you the choice of which to pursue further.</p>
<p><br></p>
</div>
<div id="choose-your-own-data-adventure" class="section level2 tabset tabset-fade">
<h2>Choose your own data adventure</h2>
<!-- .tabset-fade .tabset-pills} -->
<p><br></p>
<p>This week we will work with two different data examples to demonstrate a couple different applications of GLMM to non-normal data. The binomial and Poisson distributions are commonly used to describe biological and ecological processes due to the nature of the data we collect. Therefore, one of the examples this week will use a Bernouli response (special case of the binomial where <code>N</code> = 1), and the other will use a Poisson (count) response to demonstrate the application of GLMMs in biology and ecology. Please realize that these examples hold true for any response that takes similar forms, and they are easily generalized to include a wide variety of other sampling distributions.</p>
<p><br> For our assignments this week, students can choose to work with either one of these examples, and must only submit a write-up for one of them. You choose, although I encourage you to explore with both of them to investigate similarities and differences in how things work for the models.</p>
<p><br></p>
<div id="walleye-phenology" class="section level3">
<h3><span style="color:black"> Walleye phenology</span></h3>
<p><br></p>
<div id="walleye-in-spring" class="section level4">
<h4><strong>Walleye in spring</strong></h4>
<p><br></p>
<p>It is that magical time of year again. Birds are returning from their winter vacations, and all of the critters are twitterpaited. The salamanders and frogs are making there way to breeding pools in the soaked leaf litter, and even the fish are warming up for the spawn. There’s only one problem: we don’t quite know when those fish are going to get into the streams so we can catch them, clip their fins, put some tags in them, and study their every move (…muwahaha…).</p>
<p><br></p>
<p>For this first example, we will attempt to predict counts of walleye, <em>Sander vitreus</em>, in spawning streams of Otsego Lake based on historical counts and climate data.</p>
<p><br></p>
<div id="walleye-data" class="section level5">
<h5><strong>Walleye data</strong></h5>
<p><br></p>
<p>We begin by reading in the data set:</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the walleye data</span>
  wae =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;http://employees.oneonta.edu/stichds/data/otsegoRunCounts.csv&#39;</span>, <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><br></p>
<p>Have a look at the first ten lines of the data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="kw">head</span>(wae, <span class="dv">10</span>)</code></pre></div>
<pre><code>##         date          site Length..mm. Weight..gm.    Sex Stage
## 1   4/5/2009 Cripple Creek         450          NA   Male  Ripe
## 2   4/5/2009 Cripple Creek         370          NA   Male  Ripe
## 3   4/5/2009 Cripple Creek         501          NA Female  Ripe
## 4   4/5/2009 Cripple Creek         474          NA Female  Hard
## 5   4/9/2009 Cripple Creek         480        1021   Male  Ripe
## 6  4/16/2009 Cripple Creek         540          NA   Male  Ripe
## 7  4/16/2009 Cripple Creek         605          NA Female  Ripe
## 8  4/16/2009 Cripple Creek         553          NA   Male  Ripe
## 9  4/16/2009 Cripple Creek         550          NA   Male Spent
## 10 4/16/2009 Cripple Creek         508          NA   Male  Ripe</code></pre>
<p><br></p>
<p>And check out the data structure</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">str</span>(wae)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1399 obs. of  6 variables:
##  $ date       : chr  &quot;4/5/2009&quot; &quot;4/5/2009&quot; &quot;4/5/2009&quot; &quot;4/5/2009&quot; ...
##  $ site       : chr  &quot;Cripple Creek&quot; &quot;Cripple Creek&quot; &quot;Cripple Creek&quot; &quot;Cripple Creek&quot; ...
##  $ Length..mm.: int  450 370 501 474 480 540 605 553 550 508 ...
##  $ Weight..gm.: int  NA NA NA NA 1021 NA NA NA NA NA ...
##  $ Sex        : chr  &quot;Male&quot; &quot;Male&quot; &quot;Female&quot; &quot;Female&quot; ...
##  $ Stage      : chr  &quot;Ripe&quot; &quot;Ripe&quot; &quot;Ripe&quot; &quot;Hard&quot; ...</code></pre>
<p><br></p>
<p>These data are measurements of the length and mass of individual walleye at various reproductive stages that were captured in spawning tributaries of Otsego Lake during the 2009 and 2013 spawning season.</p>
<p>We will use the data to predict number of walleye we expect to see each day in the spawning tribs during spring 2017 based on historical counts.</p>
<p><br></p>
</div>
<div id="climate-data" class="section level5">
<h5><strong>Climate data</strong></h5>
<p><br></p>
<p>For this example, we are interested in predicting the timing of the walleye run. Generally speaking, phenology of spawning events in fishes and many other animals is driven by circannual rhythms entrained by photoperiod. However, temperature often acts as a trigger for releasing behavior related to spawning…<strong>Translation</strong>: if we want to predict timing of the spawning run, we need to have data for photoperiod and temperature, too!</p>
<p>I collected some of this information ahead of time for you. Temperature, precipitation, and snow depth data were downloaded from the following, surely reliable, <a href="http://www.usclimatedata.com/climate/cooperstown/new-york/united-states/usny0326/2017/3">website</a>.</p>
<p>Read in the data an have a look at the structure</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the climate data</span>
  climate=<span class="kw">read.csv</span>(<span class="st">&#39;http://employees.oneonta.edu/stichds/data/tempdata.csv&#39;</span>, <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)

<span class="co"># Have a look at the data structure</span>
  <span class="kw">str</span>(climate)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    555 obs. of  3 variables:
##  $ date  : chr  &quot;1/1/2009&quot; &quot;1/2/2009&quot; &quot;1/3/2009&quot; &quot;1/4/2009&quot; ...
##  $ high_f: num  19.9 17.1 28 28 33.1 32 35.1 34 30 21.9 ...
##  $ low_f : num  0 3 12.9 12.9 10.9 12 12 27 12.9 0 ...</code></pre>
<p><br></p>
</div>
<div id="data-management" class="section level5">
<h5><strong>Data management</strong></h5>
<p><br></p>
<div id="walleye-counts" class="section level6">
<h6><strong>Walleye counts</strong></h6>
<p><br></p>
<p>Okay, so now we have fish records by date and we have some climate data for those same dates and then some. Now, we need to smash all of those data together so we can use them.</p>
<p>Our first step will be to summarize the walleye data by date. To do this, we will use the <code>plyr</code> package in R.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the package</span>
  <span class="kw">library</span>(plyr)</code></pre></div>
<p><br></p>
<p>Tally up total counts of walleye in each stream on each day.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a column of ones that we can sum</span>
wae<span class="op">$</span>pres =<span class="st"> </span><span class="dv">1</span>

weye =<span class="st"> </span><span class="kw">ddply</span>(wae, <span class="kw">c</span>(<span class="st">&#39;date&#39;</span>, <span class="st">&#39;site&#39;</span>), summarize, <span class="dt">counts =</span> <span class="kw">sum</span>(pres))</code></pre></div>
<p><br></p>
</div>
<div id="climate-data-1" class="section level6">
<h6><strong>Climate data</strong></h6>
<p><br></p>
<p>Next, we will get the climate data in order.</p>
<p>Because temperature fluctuates pretty widely in the spring, we often think of accumulated thermal units (ATU) or degree days as having more of an influence on the reproductive biology of many organisms rather than just absolute temperatures. You can think of degree days as the sum of all temperatures from some starting date until some ending date. In our case, we will add up the degree days from January 1 until date i in our dataframe to get degree days for each observation.</p>
<p>First, we will convert our temperatures to celcius like the rest of the world.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Convert from farenheit to celcius</span>
  climate<span class="op">$</span>high_c =<span class="st"> </span>(climate<span class="op">$</span>high_f<span class="op">-</span><span class="dv">32</span>)<span class="op">*</span><span class="dv">5</span><span class="op">/</span><span class="dv">9</span>
  climate<span class="op">$</span>low_c =<span class="st"> </span>(climate<span class="op">$</span>low_f<span class="op">-</span><span class="dv">32</span>)<span class="op">*</span><span class="dv">5</span><span class="op">/</span><span class="dv">9</span></code></pre></div>
<p><br></p>
<p>Next, we will calculate degree days (in <span class="math inline">\(^{\circ}\)</span>C) using both the high temp and the low temp. We will start by calculating the mean of highs and lows, and then add them up for the time period of interest. Ideally, we would be working with averages, but this will do for now.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate mean based on daily highs and lows</span>
  climate<span class="op">$</span>mean_c =<span class="st"> </span><span class="kw">apply</span>(climate[ , <span class="dv">4</span><span class="op">:</span><span class="dv">5</span>], <span class="dv">1</span>, mean)

<span class="co"># Exclude values less than zero from this calculation</span>
  climate<span class="op">$</span>ddPrep =<span class="st"> </span>climate<span class="op">$</span>mean_c
  
  climate<span class="op">$</span>ddPrep[climate<span class="op">$</span>ddPrep <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>] =<span class="st"> </span><span class="dv">0</span>

<span class="co"># Change date to a date object from factor</span>
  <span class="co"># Load lubridate package</span>
    <span class="kw">library</span>(lubridate)
  <span class="co"># Convert to date</span>
    climate<span class="op">$</span>date =<span class="st"> </span><span class="kw">as.Date</span>(<span class="kw">as.character</span>(climate<span class="op">$</span>date),
                           <span class="dt">format=</span><span class="st">&quot;%m/%d/%Y&quot;</span>)
  <span class="co"># Get ordinal date</span>
    climate<span class="op">$</span>day =<span class="st"> </span><span class="kw">yday</span>(climate<span class="op">$</span>date)
  <span class="co"># Get year</span>
    climate<span class="op">$</span>year =<span class="st"> </span><span class="kw">year</span>(climate<span class="op">$</span>date)
  <span class="co"># Sort climate data by date and year</span>
    climate =<span class="st"> </span>climate[<span class="kw">with</span>(climate, <span class="kw">order</span>(year, day)), ]    
    
<span class="co"># Add up the values to calculate degree days for each year</span>
  <span class="co"># Split the dataframe up into a list with a df for each year</span>
    test =<span class="st"> </span><span class="kw">split</span>(climate<span class="op">$</span>ddPrep, climate<span class="op">$</span>year)
  <span class="co"># Replace NA values of temperature with arithmetic mean of </span>
  <span class="co"># preceding and following elements</span>
    <span class="kw">library</span>(zoo)
    test =<span class="st"> </span><span class="kw">mapply</span>(na.approx, test)
  <span class="co"># Calculate degree days for each year  </span>
    dd =<span class="st"> </span><span class="kw">mapply</span>(cumsum, test)
  <span class="co"># Unlist the result and add it to the climate data  </span>
    climate<span class="op">$</span>dd =<span class="st"> </span><span class="kw">unlist</span>(dd)
    climate<span class="op">$</span>dd2 =<span class="st"> </span>climate<span class="op">$</span>dd<span class="op">^</span><span class="dv">2</span></code></pre></div>
<p><br></p>
<p>We can now add degree days to our fish data. What? Fish data? I forgot we had that!</p>
<p>To wrap up our climate analysis, we will quickly calculate day length at Otsego Lake based on lattitude for each day of our historical records using the <code>geosphere</code> package.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(geosphere)
climate<span class="op">$</span>daylight =<span class="st"> </span><span class="kw">daylength</span>(<span class="dt">lat =</span> <span class="fl">42.76</span>, <span class="dt">doy =</span> climate<span class="op">$</span>day)
climate<span class="op">$</span>daylight2 =<span class="st"> </span>climate<span class="op">$</span>daylight<span class="op">^</span><span class="dv">2</span></code></pre></div>
<p><br></p>
<p>Our final job will be to add all of the climate data to our new dataframe containing walleye counts. This is relatively easy to do in R using the <code>merge</code> function, like so:</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># First, format the date column in the weye df</span>
  weye<span class="op">$</span>date =<span class="st"> </span><span class="kw">as.Date</span>(<span class="kw">as.character</span>(weye<span class="op">$</span>date),
                      <span class="dt">format=</span><span class="st">&quot;%m/%d/%Y&quot;</span>)  

<span class="co"># Merge the two dataframes</span>
  eyes =<span class="st"> </span><span class="kw">merge</span>(weye, climate)

<span class="co"># Finally, we are going to get rid of Leatherstocking </span>
<span class="co"># for now because there are few data points there</span>
  eyes =<span class="st"> </span>eyes[eyes<span class="op">$</span>site<span class="op">!=</span><span class="st">&#39;Leatherstocking Creek&#39;</span>, ]
  
<span class="co"># Check to see how much data we have left</span>
  <span class="kw">nrow</span>(eyes)</code></pre></div>
<pre><code>## [1] 55</code></pre>
<p><br></p>
<p>Wow, that’s rough! We went from several hundred lines of data to just a handful pretty quickly!!</p>
<p><br></p>
</div>
</div>
<div id="modeling-counts" class="section level5">
<h5>Modeling counts</h5>
<p><br></p>
<p>After our data management triathalon, we can finally model walleye counts as a function of some explanatory variables of interest. As has become our practice during the last several lessons, we will do this in both frequentist and Bayesian frameworks.</p>
<p><br></p>
<div id="reml-estimation" class="section level6">
<h6>REML Estimation</h6>
<p><br></p>
<p>We start by estimating a model using REML. Let’s say for the sake of argument that we are simply interested in the lake-wide mean of our counts so that we know when students should, for example, be heading out to tributaries to look for walleyes in streams.</p>
<p>For now, we will model walleye count as a function of photoperiod, with a random effect of site on the intercepts. This model assumes that there is variability in counts of spawning individuals between sites, but that the relationship between photoperiod and count is the same across all sites. In this case, we will specify a quadratic relationship between counts and dates because we expect the number of fish to increase to some point in the run before it decreases. We are not interested</p>
<p>In the <code>lme4</code> package, the model might look something like this:</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the package</span>
  <span class="kw">library</span>(lme4)

<span class="co"># Make the model</span>
  waeMod1 =<span class="st"> </span><span class="kw">glmer</span>(counts<span class="op">~</span>dd <span class="op">+</span><span class="st"> </span>dd2 <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>site), <span class="dt">data=</span>eyes, <span class="dt">family=</span>poisson)
  
<span class="co"># Have a look-see at the results</span>
  <span class="kw">summary</span>(waeMod1)</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: poisson  ( log )
## Formula: counts ~ dd + dd2 + (1 | site)
##    Data: eyes
## 
##      AIC      BIC   logLik deviance df.resid 
##   1195.2   1203.2   -593.6   1187.2       51 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -6.257 -2.652 -0.781  2.096 13.001 
## 
## Random effects:
##  Groups Name        Variance Std.Dev.
##  site   (Intercept) 0.006751 0.08216 
## Number of obs: 55, groups:  site, 3
## 
## Fixed effects:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -5.402e+00  5.369e-01  -10.06   &lt;2e-16 ***
## dd           1.094e-01  6.693e-03   16.35   &lt;2e-16 ***
## dd2         -3.290e-04  2.059e-05  -15.98   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##     (Intr) dd    
## dd  -0.984       
## dd2  0.956 -0.991
## fit warnings:
## Some predictor variables are on very different scales: consider rescaling
## convergence code: 0
## unable to evaluate scaled gradient
## Model failed to converge: degenerate  Hessian with 1 negative eigenvalues</code></pre>
<p><br></p>
<p>Crap! Our model failed to converge. It looks like this is probably because we have variables on really different scales, and because we have a lot of colinearity between them. So, let’s try standardizing our covariates to see what we can do about that:</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Standardize photoperiod</span>
  eyes<span class="op">$</span>sdd =<span class="st"> </span><span class="kw">scale</span>(eyes<span class="op">$</span>dd) 

<span class="co"># Make the model</span>
  waeMod2 =<span class="st"> </span><span class="kw">glmer</span>(counts<span class="op">~</span>sdd <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(sdd<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>site), <span class="dt">data=</span>eyes,
                  <span class="dt">family=</span><span class="kw">negative.binomial</span>(<span class="dt">theta=</span><span class="dv">1000</span>))
  
<span class="co"># Have a look-see at the results</span>
  <span class="kw">summary</span>(waeMod2)</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: Negative Binomial(1000)  ( log )
## Formula: counts ~ sdd + I(sdd^2) + (1 | site)
##    Data: eyes
## 
##      AIC      BIC   logLik deviance df.resid 
##   1172.5   1182.6   -581.3   1162.5       50 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -6.1202 -2.6201 -0.7898  2.0706 12.8880 
## 
## Random effects:
##  Groups Name        Variance Std.Dev.
##  site   (Intercept) 0.006653 0.08157 
## Number of obs: 55, groups:  site, 3
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.67562    0.06149  59.776  &lt; 2e-16 ***
## sdd          0.23311    0.04584   5.085 3.68e-07 ***
## I(sdd^2)    -0.83656    0.05294 -15.802  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##          (Intr) sdd   
## sdd      -0.038       
## I(sdd^2) -0.363 -0.085</code></pre>
<p><br></p>
<p>Okay, looks like we are doing a lot better with this now.</p>
<p>As we look through these results, we can see that we have a significant effect of daylight on spawning behavior. What’s more is that our count of spawning fish appears to increase during the year to a point before it starts to decrease.</p>
<p>Now, if we want, we can make a graph to show these predictions. Here, we make predictions for all years, and then we plot those predictions for a single site (<code>Shadow Brook</code>).</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the merTools package</span>
  <span class="kw">library</span>(merTools)
  
<span class="co"># Make a new dataframe for prediction</span>
  sdd =<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="kw">min</span>(eyes<span class="op">$</span>sdd), <span class="dt">to =</span> <span class="kw">max</span>(eyes<span class="op">$</span>sdd), <span class="dt">by =</span> .<span class="dv">1</span>)
  site =<span class="st"> </span><span class="kw">sort</span>(<span class="kw">rep</span>(<span class="kw">unique</span>(eyes<span class="op">$</span>site), <span class="kw">length</span>(sdd)))
  sdd =<span class="st"> </span><span class="kw">rep</span>(sdd, <span class="kw">length</span>(<span class="kw">unique</span>(eyes<span class="op">$</span>site)))
  newdata =<span class="st"> </span><span class="kw">data.frame</span>(sdd)
  
<span class="co"># Simulate predictions from the relationship stored in the model fit using</span>
<span class="co"># our new data</span>
  PI &lt;-<span class="st"> </span><span class="kw">predictInterval</span>(<span class="dt">merMod =</span> waeMod2, <span class="dt">newdata =</span> newdata, 
                        <span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">n.sims =</span> <span class="dv">1000</span>,
                        <span class="dt">stat =</span> <span class="st">&quot;median&quot;</span>, <span class="dt">type=</span><span class="st">&quot;linear.prediction&quot;</span>,
                        <span class="dt">include.resid.var =</span> <span class="ot">TRUE</span>)
  PI =<span class="st"> </span><span class="kw">apply</span>(PI, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), exp)
  
<span class="co"># Plot the raw data but don&#39;t label the x-axis</span>
<span class="co"># because we will want to add unstandardized labels</span>
<span class="co"># even though our regression used standardized labels</span>
  <span class="kw">plot</span>(eyes<span class="op">$</span>sdd[eyes<span class="op">$</span>site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>],
       eyes<span class="op">$</span>counts[eyes<span class="op">$</span>site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>],
       <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">500</span>), <span class="dt">pch=</span><span class="dv">21</span>,
       <span class="dt">bg=</span><span class="kw">c</span>(<span class="st">&#39;gray87&#39;</span>, <span class="st">&#39;gray60&#39;</span>,<span class="st">&#39;gray40&#39;</span>, <span class="st">&#39;black&#39;</span>)[<span class="kw">as.factor</span>(eyes<span class="op">$</span>year)],
       <span class="dt">cex=</span><span class="fl">1.9</span>, <span class="dt">xlab=</span><span class="st">&#39;Degree days&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Count&#39;</span>,
       <span class="dt">xaxt=</span><span class="st">&#39;n&#39;</span>
       )

<span class="co"># Add lines to the plot</span>
  <span class="kw">lines</span>(newdata<span class="op">$</span>sdd[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>],
        PI[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>,<span class="dv">1</span>], <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>) <span class="co"># Mean</span>
  <span class="kw">lines</span>(newdata<span class="op">$</span>sdd[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>],
        PI[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>,<span class="dv">2</span>], <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;red&#39;</span>) <span class="co"># Lower</span>
  <span class="kw">lines</span>(newdata<span class="op">$</span>sdd[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>],
        PI[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>,<span class="dv">3</span>], <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;red&#39;</span>) <span class="co"># Upper</span></code></pre></div>
<p><img src="hw11_glmm_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p><br></p>
<p>We could also do this using our global parameter estimates and some new data. We see that our mean predictions aren’t terrible, but there is quite a bit of uncertainty here.</p>
<p><br></p>
</div>
</div>
<div id="bayesian-estimation" class="section level5">
<h5><strong>Bayesian estimation</strong></h5>
<p><br></p>
<p>We can fit the same model in the Bayesian framework, too. Here we specify it just as we have during the past couple of weeks.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Write model</span>
modelstring=<span class="st">&quot;</span>
<span class="st">model {</span>

<span class="st"># Likelihood</span>
<span class="st"> for(i in 1:n){</span>
<span class="st">    count[i] ~ dnegbin(p[i], r)     # The random variable</span>
<span class="st">    p[i] &lt;- r/(r+lambda[i])</span>
<span class="st">    log(lambda[i]) &lt;- mu[i]</span>
<span class="st">    mu[i] &lt;- alpha[site[i]] + beta*sdd[i] + beta2*(sdd[i]^2) # Expectation</span>
<span class="st"> }</span>

<span class="st"># Priors</span>
<span class="st"> for (i in 1:ngroups){      </span>
<span class="st">    alpha[i] ~ dnorm(mu.int, tau.int)   # Random intercepts</span>
<span class="st"> }</span>

<span class="st"> mu.int ~ dnorm(0, 0.1)       # Mean hyperparameter for random intercepts</span>
<span class="st"> tau.int &lt;- 1 / (sigma.int * sigma.int)</span>
<span class="st"> sigma.int ~ dunif(0, 100)      # SD hyperparameter for random intercepts</span>

<span class="st"> beta ~ dnorm(0, 0.001)          # Common slope</span>
<span class="st"> taub &lt;- 1 / ( sigmab * sigmab)    # Residual precision</span>
<span class="st"> sigmab ~ dunif(0, 100)          # Residual standard deviation</span>

<span class="st"> beta2 ~ dnorm(0, 0.0001)          # Common slope</span>
<span class="st"> taub2 &lt;- 1 / ( sigmab2 * sigmab2)    # Residual precision</span>
<span class="st"> sigmab2 ~ dunif(0, 100)          # Residual standard deviation</span>

<span class="st"> r ~ dgamma(0.01, 0.001)          # Site-specific overdispersion</span>


<span class="st">}</span>
<span class="st">&quot;</span>
<span class="kw">writeLines</span>(modelstring, <span class="st">&quot;waeModel.txt&quot;</span>)

<span class="co"># Bundle data</span>
  wae.data &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">count=</span>eyes<span class="op">$</span>count,
                   <span class="dt">site =</span> <span class="kw">as.numeric</span>(<span class="kw">as.factor</span>(eyes<span class="op">$</span>site)), 
                   <span class="dt">sdd =</span> <span class="kw">as.vector</span>(eyes<span class="op">$</span>sdd),
                   <span class="dt">ngroups =</span> <span class="kw">length</span>(<span class="kw">unique</span>(eyes<span class="op">$</span>site)),
                   <span class="dt">n =</span> <span class="kw">nrow</span>(eyes)
                   )
  
<span class="co"># Inits function</span>
inits &lt;-<span class="st"> </span><span class="cf">function</span>(){
  <span class="kw">list</span>(
    <span class="dt">alpha =</span> <span class="kw">rnorm</span>(<span class="kw">length</span>(<span class="kw">unique</span>(eyes<span class="op">$</span>site)), <span class="dv">0</span>, <span class="dv">1</span>),
    <span class="dt">r =</span> <span class="kw">rgamma</span>(<span class="kw">length</span>(<span class="kw">unique</span>(eyes<span class="op">$</span>site)), <span class="fl">0.1</span>, <span class="fl">0.01</span>),
    <span class="dt">beta =</span> <span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),
    <span class="dt">beta2 =</span> <span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">10</span>),
    <span class="dt">mu.int =</span> <span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),
    <span class="dt">sigma.int =</span> <span class="kw">rlnorm</span>(<span class="dv">1</span>),
    <span class="dt">sigmab =</span> <span class="kw">rlnorm</span>(<span class="dv">1</span>),
    <span class="dt">sigmab2=</span><span class="kw">rlnorm</span>(<span class="dv">1</span>)
  )}

<span class="co"># Parameters to estimate</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;beta2&quot;</span>,<span class="st">&quot;mu.int&quot;</span>, <span class="st">&quot;sigma.int&quot;</span>, <span class="st">&quot;sigmab&quot;</span>,
                <span class="st">&quot;sigmab2&quot;</span>)

<span class="co"># MCMC settings</span>
ni &lt;-<span class="st"> </span><span class="dv">5000</span>
nb &lt;-<span class="st"> </span><span class="dv">1000</span>
nt &lt;-<span class="st"> </span><span class="dv">10</span>
nc &lt;-<span class="st"> </span><span class="dv">3</span>

<span class="co"># Load the package</span>
  <span class="kw">library</span>(R2jags)

<span class="co"># Run the Gibbs sampler</span>
  out &lt;-<span class="kw">jags</span>(wae.data, <span class="dt">inits=</span><span class="ot">NULL</span>, parameters, <span class="st">&quot;waeModel.txt&quot;</span>, <span class="dt">n.thin=</span>nt, 
  <span class="dt">n.chains=</span>nc, <span class="dt">n.burnin=</span>nb, <span class="dt">n.iter=</span>ni, <span class="dt">progress.bar =</span> <span class="st">&#39;none&#39;</span>)</code></pre></div>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 55
##    Unobserved stochastic nodes: 10
##    Total graph size: 556
## 
## Initializing model</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Print the results  </span>
  <span class="kw">print</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>summary[ , <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dv">7</span><span class="op">:</span><span class="dv">9</span>)], <span class="dt">digits=</span><span class="dv">3</span>)</code></pre></div>
<pre><code>##              mean     sd     2.5%   97.5% Rhat n.eff
## alpha[1]    3.500  0.336   2.7980   4.169 1.00   770
## alpha[2]    3.742  0.243   3.2871   4.267 1.00   460
## alpha[3]    3.663  0.211   3.2636   4.104 1.00  1200
## beta        0.473  0.172   0.1234   0.800 1.00  1200
## beta2      -0.760  0.130  -1.0168  -0.489 1.00   890
## deviance  438.314  3.485 433.7105 446.957 1.00  1200
## mu.int      3.467  0.826   1.1719   4.354 1.04   350
## sigma.int   0.769  1.277   0.0204   4.706 1.01   160
## sigmab     48.754 28.995   2.0478  97.745 1.00  1200
## sigmab2    48.528 28.084   2.9644  97.152 1.00  1200</code></pre>
<p><br></p>
<p>We notice that all parameters converge. Note that if we run this without standardizing our degree day covariate, convergence is not quite as clean. This is likely because of correlations between <code>dd</code> and <code>dd2</code>. Just as we did for the REML model, we could plot predictions for these results…</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a new sequence of standardized degree days  </span>
  sdd =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, .<span class="dv">1</span>)

<span class="co"># Make prediction from the model parameters</span>
  fit =<span class="st"> </span><span class="kw">exp</span>(
    <span class="kw">mean</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>mu.int)<span class="op">+</span>
<span class="st">    </span><span class="kw">mean</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta)<span class="op">*</span>sdd<span class="op">+</span>
<span class="st">    </span><span class="kw">mean</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta2)<span class="op">*</span>(sdd<span class="op">^</span><span class="dv">2</span>))

  lcis =<span class="st"> </span><span class="kw">exp</span>(
    <span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>mu.int, <span class="dt">probs=</span>.<span class="dv">025</span>)<span class="op">+</span>
<span class="st">    </span><span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta, <span class="dt">probs=</span>.<span class="dv">025</span>)<span class="op">*</span>sdd<span class="op">+</span>
<span class="st">    </span><span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta2, <span class="dt">probs=</span>.<span class="dv">025</span>)<span class="op">*</span>(sdd<span class="op">^</span><span class="dv">2</span>))
  
  ucis =<span class="st"> </span><span class="kw">exp</span>(
    <span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>mu.int, <span class="dt">probs=</span>.<span class="dv">975</span>)<span class="op">+</span>
<span class="st">    </span><span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta, <span class="dt">probs=</span>.<span class="dv">975</span>)<span class="op">*</span>sdd<span class="op">+</span>
<span class="st">    </span><span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta2, <span class="dt">probs=</span>.<span class="dv">975</span>)<span class="op">*</span>(sdd<span class="op">^</span><span class="dv">2</span>))
  
<span class="co"># Plot the predictions</span>
  <span class="kw">plot</span>(eyes<span class="op">$</span>sdd, eyes<span class="op">$</span>counts,
       <span class="dt">pch=</span><span class="dv">21</span>, <span class="dt">bg=</span><span class="st">&#39;gray&#39;</span>, <span class="dt">cex=</span><span class="fl">1.2</span>,
       <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">max</span>(eyes<span class="op">$</span>counts)<span class="op">+</span><span class="dv">50</span>),
       <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>),
       <span class="dt">xlab=</span><span class="st">&#39;Degree days (C)&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Count of spawners&#39;</span>,
       <span class="dt">xaxt=</span><span class="st">&#39;n&#39;</span>, <span class="dt">yaxt=</span><span class="st">&#39;n&#39;</span>)
  <span class="kw">lines</span>(sdd, fit, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)
  <span class="kw">lines</span>(sdd, lcis, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;red&#39;</span>)
  <span class="kw">lines</span>(sdd, ucis, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;red&#39;</span>)

<span class="co"># Add a new x-axis </span>
  <span class="kw">axis</span>(<span class="dt">side=</span><span class="dv">1</span>,
         <span class="dt">at=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="fl">0.5</span>),
         <span class="dt">labels=</span> 
           <span class="co">#Get dd on original scale from a sequence</span>
           <span class="co"># of new standardized values</span>
           <span class="kw">round</span>(
             <span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="fl">0.5</span>)<span class="op">*</span><span class="kw">sd</span>(eyes<span class="op">$</span>dd)<span class="op">+</span><span class="kw">mean</span>(eyes<span class="op">$</span>dd)
             )
         )
  
<span class="co"># Add a rotated y-axis</span>
  <span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">las=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="hw11_glmm_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="your-mission" class="section level5">
<h5><strong>Your mission</strong></h5>
<p><br></p>
<p>For this option, I want you to do the following:</p>
<p><br></p>

<ol style="list-style-type: decimal">
<li>Use the degree day data from 2018 that we made (waaaay up top) to predict mean and 95% CI for counts from each of the models above, using any of the methods you have learned in this course. Treat these like sequences that we’ve been passing to the <code>newdata</code> argument in the <code>predict</code> function all semester, or that we have recently been using to make predictions by hand. <strong>Note</strong> that you will not get the back end of the curve because it is early April right now!</li>
</ol>

<ol start="2" style="list-style-type: decimal">
<li>Tell me how many walleye you predicted that the crew caught on Tuesday 10 April 2018. Then, tell me how many you predict they will catch 12 April 2018 (tonight).</li>
</ol>
<p><br></p>
</div>
</div>
</div>
<div id="plant-surveys" class="section level3">
<h3><span style="color:gray"><b> <strong>Plant surveys</strong> </b></span></h3>
<p><br></p>
<div id="big-milfoil-problems" class="section level4">
<h4><strong>Big milfoil problems</strong></h4>
<p><br></p>
<p>For this example, we will look at increases or decreases in Eurasian watermilfoil (<em>Myriophylum spicatum</em>) following herbicide treatment at different doses. We will use a Bernoulli response (1 or 0) to test effects of secchi depth on treatment response across 30 sites.</p>
<p><br></p>
</div>
<div id="data" class="section level4">
<h4><strong>Data</strong></h4>
<p><br></p>
<p>Start by reading in the data:</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the plant data</span>
  plants =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://employees.oneonta.edu/stichds/data/plants.csv&quot;</span>)</code></pre></div>
<p><br></p>
<p>This is a pretty straightforward data set compared to the walleye phenology set (hopefully that is not what led you here). We have 5 paired samples of Eurasian watermilfoil from each of 30 sites before and after treatment with herbicide. Those data have been condensed to indicate whether the species increased or decreased at each site following herbicide application. Here, we will investigate the influence of Secchi depth (an index for water clarity where greater values indicate clearer water) on this response, while accounting for random variation between sites.</p>
<p><br></p>
<div id="estimation-with-reml" class="section level5">
<h5><strong>Estimation with REML</strong></h5>
<p><br></p>
<p>To start with, we will fit the model using REML. Here, we need to remember to specify a site-specific random effect on the intercept and we need to give R the <code>family</code> for our link function.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit the model and store it to an object</span>
  plantMod1=<span class="kw">glmer</span>(increase<span class="op">~</span>secchi<span class="op">+</span>(<span class="dv">1</span><span class="op">|</span>site), <span class="dt">data=</span>plants, <span class="dt">family=</span>binomial)

<span class="co"># Take a look at the results</span>
  <span class="kw">summary</span>(plantMod1)</code></pre></div>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: increase ~ secchi + (1 | site)
##    Data: plants
## 
##      AIC      BIC   logLik deviance df.resid 
##     90.4     99.4    -42.2     84.4      147 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -0.5454 -0.3472 -0.2958 -0.1905  4.6690 
## 
## Random effects:
##  Groups Name        Variance Std.Dev.
##  site   (Intercept) 0        0       
## Number of obs: 150, groups:  site, 30
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)   2.1638     2.3519   0.920   0.3576  
## secchi       -1.3904     0.7411  -1.876   0.0606 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##        (Intr)
## secchi -0.992</code></pre>
<p><br></p>
<p>After a quick look at the results, we see that Secchi depth has a significant, poositive effect on the probability that plant biomass will increase following this herbicide application.</p>
<p>We could make a graph of these results as follows:</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># First, make a function to invert the logit</span>
  invlogit=<span class="cf">function</span>(x){<span class="kw">exp</span>(x)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(x))}

<span class="co"># Now we can make predictions</span>
  newSecchi =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="fl">0.10</span>)
  preds =<span class="st"> </span><span class="op">-</span><span class="fl">4.744</span> <span class="op">+</span><span class="st"> </span><span class="fl">1.980</span><span class="op">*</span>newSecchi
  
  <span class="kw">plot</span>(newSecchi, <span class="kw">invlogit</span>(preds), <span class="dt">type=</span><span class="st">&#39;l&#39;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)</code></pre></div>
<p><img src="hw11_glmm_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="bayesian-estimation-1" class="section level5">
<h5><strong>Bayesian estimation</strong></h5>
<p><br></p>
<p>Now, we will estimate a model using Bayesian methods.</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modelstring=<span class="st">&quot;</span>
<span class="st">      model{</span>

<span class="st">        # Priors</span>
<span class="st">          for(i in 1:ngroups){</span>
<span class="st">            alpha[i] ~ dnorm(mu.int, tau.int) # Random intercepts</span>
<span class="st">          }</span>

<span class="st">          mu.int ~ dnorm(0, 0.001)            # Mean hyperparameter for ran. intercepts</span>
<span class="st">          tau.int &lt;- 1/(sigma.int*sigma.int)  # Precision for random intercepts</span>
<span class="st">          sigma.int ~ dunif(0, 100)           # SD hyperparameter for ran. intercepts</span>

<span class="st">          beta ~ dnorm(0, 0.001)              # Common slope for beta</span>

<span class="st">        # Likelihood</span>
<span class="st">          for(i in 1:N){</span>
<span class="st">            y[i] ~ dbern(mu[i])</span>
<span class="st">            logit(mu[i]) &lt;- alpha[site[i]] + beta*secchi[i]</span>
<span class="st">          }</span>
<span class="st">        }</span>
<span class="st">&quot;</span>
<span class="kw">writeLines</span>(modelstring, <span class="st">&quot;plantModel.txt&quot;</span>)</code></pre></div>
<blockquote>
<p>Make the data</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Package the data in a list for JAGS</span>
    jags.data &lt;-<span class="st"> </span><span class="kw">list</span>(
      <span class="dt">y =</span> plants<span class="op">$</span>increase,
      <span class="dt">site =</span> plants<span class="op">$</span>site,
      <span class="dt">secchi=</span>plants<span class="op">$</span>secchi,
      <span class="dt">ngroups=</span><span class="kw">length</span>(<span class="kw">unique</span>(plants<span class="op">$</span>site)),
      <span class="dt">N =</span> <span class="kw">nrow</span>(plants)
    )</code></pre></div>
<blockquote>
<p>Define parameters for monitoring</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Specify the parameters we want to monitor</span>
    parameters =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;mu.int&quot;</span>, <span class="st">&quot;sigma.int&quot;</span>)</code></pre></div>
<blockquote>
<p>Specify initial values</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a function to declare some initial values.</span>
    inits =<span class="st"> </span><span class="cf">function</span>(){
      <span class="kw">list</span>(
        <span class="dt">alpha =</span> <span class="kw">rnorm</span>(<span class="kw">length</span>(<span class="kw">unique</span>(plants<span class="op">$</span>site)), <span class="dv">0</span>, <span class="dv">2</span>),
        <span class="dt">beta =</span> <span class="kw">rnorm</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>),
        <span class="dt">mu.int =</span> <span class="kw">rnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>),
        <span class="dt">sigma.int =</span> <span class="kw">rlnorm</span>(<span class="dv">1</span>)
      )
    }</code></pre></div>
<blockquote>
<p>Define MCMC settings for Gibbs sampler</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># MCMC settings</span>
  ni &lt;-<span class="st"> </span><span class="dv">15000</span>
  nt &lt;-<span class="st"> </span><span class="dv">3</span>
  nb &lt;-<span class="st"> </span><span class="dv">5000</span>
  nc &lt;-<span class="st"> </span><span class="dv">3</span></code></pre></div>
<blockquote>
<p>Run the model</p>
</blockquote>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 150
##    Unobserved stochastic nodes: 33
##    Total graph size: 584
## 
## Initializing model</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the R2jags package</span>
  <span class="kw">library</span>(R2jags)

<span class="co"># Call JAGS from R and run the model</span>
   plant_glmm &lt;-<span class="st"> </span><span class="kw">jags</span>(jags.data, inits, parameters,
     <span class="st">&quot;plantModel.txt&quot;</span>, <span class="dt">n.chains =</span> nc, <span class="dt">n.thin =</span> nt, <span class="dt">n.iter =</span> ni,
     <span class="dt">n.burnin =</span> nb)</code></pre></div>
<blockquote>
<p>Look at the results</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Print the model</span>
  <span class="kw">print</span>(plant_glmm, <span class="dt">digits=</span><span class="dv">3</span>)</code></pre></div>
<pre><code>## Inference for Bugs model at &quot;plantModel.txt&quot;, fit using jags,
##  3 chains, each with 15000 iterations (first 5000 discarded), n.thin = 3
##  n.sims = 10002 iterations saved
##           mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
## alpha[1]    3.417   2.652 -1.457  1.343  3.450  5.213  8.499 1.496     8
## alpha[2]    3.406   2.638 -1.436  1.326  3.413  5.170  8.510 1.496     8
## alpha[3]    3.083   2.569 -1.646  1.078  3.145  4.849  7.959 1.489     8
## alpha[4]    3.464   2.691 -1.437  1.351  3.473  5.275  8.660 1.488     8
## alpha[5]    3.209   2.633 -1.614  1.151  3.245  5.008  8.293 1.484     8
## alpha[6]    3.483   2.705 -1.453  1.355  3.492  5.309  8.678 1.488     8
## alpha[7]    3.407   2.645 -1.425  1.307  3.439  5.185  8.485 1.487     8
## alpha[8]    3.357   2.611 -1.434  1.286  3.381  5.129  8.371 1.498     8
## alpha[9]    3.189   2.617 -1.589  1.120  3.233  4.983  8.161 1.498     8
## alpha[10]   3.377   2.626 -1.463  1.285  3.399  5.146  8.419 1.498     8
## alpha[11]   3.244   2.652 -1.583  1.152  3.297  5.043  8.334 1.482     8
## alpha[12]   3.255   2.646 -1.557  1.182  3.298  5.092  8.288 1.483     8
## alpha[13]   3.167   2.601 -1.624  1.130  3.253  4.966  8.092 1.493     8
## alpha[14]   3.216   2.630 -1.572  1.154  3.272  5.000  8.278 1.492     8
## alpha[15]   3.185   2.606 -1.595  1.140  3.229  4.968  8.133 1.496     8
## alpha[16]   3.240   2.652 -1.658  1.159  3.286  5.039  8.262 1.485     8
## alpha[17]   3.363   2.620 -1.437  1.303  3.399  5.130  8.446 1.497     8
## alpha[18]   3.128   2.592 -1.636  1.097  3.187  4.890  8.035 1.493     8
## alpha[19]   3.110   2.564 -1.576  1.095  3.155  4.866  7.993 1.488     8
## alpha[20]   3.257   2.649 -1.566  1.175  3.308  5.046  8.356 1.492     8
## alpha[21]   3.228   2.639 -1.602  1.147  3.289  4.985  8.293 1.497     8
## alpha[22]   3.372   2.620 -1.461  1.318  3.391  5.146  8.384 1.501     8
## alpha[23]   3.318   2.587 -1.447  1.275  3.371  5.071  8.241 1.496     8
## alpha[24]   3.200   2.618 -1.601  1.129  3.237  4.978  8.205 1.498     8
## alpha[25]   3.150   2.589 -1.600  1.134  3.220  4.900  8.083 1.491     8
## alpha[26]   3.206   2.517 -1.467  1.221  3.265  4.924  7.988 1.496     8
## alpha[27]   3.375   2.629 -1.452  1.310  3.408  5.142  8.432 1.495     8
## alpha[28]   3.233   2.633 -1.582  1.159  3.281  5.023  8.283 1.483     8
## alpha[29]   3.394   2.637 -1.468  1.318  3.426  5.173  8.436 1.498     8
## alpha[30]   3.240   2.646 -1.597  1.149  3.288  5.033  8.307 1.485     8
## beta       -1.790   0.823 -3.391 -2.345 -1.775 -1.136 -0.307 1.516     7
## mu.int      3.275   2.578 -1.449  1.237  3.340  5.017  8.114 1.517     7
## sigma.int   0.416   0.358  0.012  0.135  0.328  0.606  1.304 1.014   320
## deviance   86.184   2.944 80.425 84.527 85.881 87.865 92.638 1.027   110
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 4.3 and DIC = 90.4
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<p><br></p>
<p>As you can see from the output, we have estimates of probability of increase in plant biomass on the logits scale for each site. If we wanted to see the overall average effect of Secchi depth on treatment effectiveness, we could look at it like this:</p>
<p><br></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newSecchi =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">1</span>)
preds =<span class="st"> </span>plant_glmm<span class="op">$</span>BUGSoutput<span class="op">$</span>mean<span class="op">$</span>mu.int <span class="op">+</span><span class="st"> </span>plant_glmm<span class="op">$</span>BUGSoutput<span class="op">$</span>mean<span class="op">$</span>beta<span class="op">*</span>newSecchi</code></pre></div>
<pre><code>## Warning in plant_glmm$BUGSoutput$mean$beta * newSecchi: Recycling array of length 1 in array-vector arithmetic is deprecated.
##   Use c() or as.vector() instead.</code></pre>
<pre><code>## Warning in plant_glmm$BUGSoutput$mean$mu.int + plant_glmm$BUGSoutput$mean$beta * : Recycling array of length 1 in array-vector arithmetic is deprecated.
##   Use c() or as.vector() instead.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">preds =<span class="st"> </span><span class="kw">invlogit</span>(preds)
<span class="kw">plot</span>(newSecchi, preds, <span class="dt">type=</span><span class="st">&#39;l&#39;</span>, <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">xlab=</span><span class="st">&#39;Secchi depth (m)&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Probability of increase&#39;</span>)</code></pre></div>
<p><img src="hw11_glmm_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p><br></p>
</div>
<div id="your-mission-1" class="section level5">
<h5><strong>Your mission</strong></h5>
<p><br></p>
<p>For this option, I want you to do the following:</p>

<ol style="list-style-type: decimal">
<li>Run the model out to convergence and make sure n.eff is sufficiently large.</li>
</ol>

<ol start="2" style="list-style-type: decimal">
<li>Plot the overall mean posterior predictions for <em>each iteration</em> of the simulation in gray, and show lines for the mean, and 95% CRI, as we did in lab last week (and in the LMM lecture, and in the GLMM lecture).</li>
</ol>
<p><br></p>
<p><br></p>
</div>
</div>
</div>
</div>

<!DOCTYPE html>
<p>Copyright &copy; 2017 Dan Stich. All rights reserved.</p>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
