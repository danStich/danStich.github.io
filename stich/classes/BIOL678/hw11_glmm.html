<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<!DOCTYPE html>
<head>
<!-- Favicon for various operating systems -->
<link rel="apple-touch-icon" sizes="180x180" href="./favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="./favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="./favicon/favicon-16x16.png">
<!-- <link rel="manifest" href="./favicon/site.webmanifest"> -->
<link rel="mask-icon" href="./favicon/safari-pinned-tab.svg" color="#603cba">
<link rel="shortcut icon" href="./favicon/favicon.ico">
<meta name="msapplication-TileColor" content="#603cba">
<meta name="msapplication-config" content="./favicon/browserconfig.xml">
<meta name="theme-color" content="#382121">
</head>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' || rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="..\..\styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">BIOL 678</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Teaching
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../../teaching.html">Teaching home</a>
    </li>
    <li>
      <a href="../../classes/BIOL217/index.html">BIOL 217</a>
    </li>
    <li>
      <a href="../../classes/BIOL678/index.html">BIOL 678</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../research.html">Research</a>
</li>
<li>
  <a href="../../studentProjects.html">Current Students</a>
</li>
<li>
  <a href="../../publications.html">Publications</a>
</li>
<li>
  <a href="../../cv.html">CV</a>
</li>
<li>
  <a href="../../contact.html">Contact</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/danStich">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<h1 id="multi">
Generalized linear mixed models (GLMM)
<h1>
<p><img src="../../images/matrixSmolt.jpg" alt=""></p>
<h2 id="multi">
Introduction
</h2>
<p>This week in lecture, we introduced the generalized linear mixed model (GLMM). As we have discussed, the GLMM is to the linear mixed model as the GLM is to the general linear model (ANOVA, linear regression, ANCOVA, etc.). That is to say, the GLMM is just an LMM that assumes some error distribution other than normal. This week in lab, we will practice running GLMMs using restricted maximum likelihood estimation (REML) in the <code>lme4</code> package in R, and using Bayesian estimation in JAGS through the <code>R2jags</code> package in R. We will play with a couple of different data sets this week, and give you the choice of which to pursue further.</p>
<div id="choose-your-own-data-adventure" class="section level2 tabset tabset-fade">
<h2>Choose your own data adventure</h2>
<!-- .tabset-fade .tabset-pills} -->
<p>This week we will work with two different data examples to demonstrate a couple different applications of GLMM to non-normal data. The binomial and Poisson distributions are commonly used to describe biological and ecological processes due to the nature of the data we collect. Therefore, one of the examples this week will use a Bernouli response (special case of the binomial where <code>N</code> = 1), and the other will use a count response to demonstrate the application of GLMMs in biology and ecology. Please realize that procedures outlined below are generally applicable within the broader context of GLMM, and they are easily generalized to include a wide variety of other sampling distributions not discussed in class.</p>
<p>For our assignments this week, you may choose to work with either one of these examples, and must only submit a write-up for one of them. You choose, although I encourage you to explore with both of them to investigate similarities and differences in how things work for the models.</p>
<div id="walleye-phenology" class="section level3">
<h3><span style="color:black"> Walleye phenology</span></h3>
<h2 id="multi">
<b> Walleye phenology </b>
</h2>
<p>It is that magical time of year again. Birds are returning from their winter vacations, and all of the critters are twitterpaited. The salamanders and frogs are making there way to breeding pools in the soaked leaf litter, and even the fish are warming up for the spawn. There’s only one problem: we don’t quite know when those fish are going to get into the streams so we can catch them, clip their fins, put some tags in them, and study their every move (…muwahaha…). While the timing of daffodil emergence is often a reliable indicator, it would be nice to have a simple regression we could use to predict the timing of the fish spawn and maximize field sampling efficiency.</p>
<p>For this first example, we will attempt to predict counts of walleye, <em>Sander vitreus</em>, in spawning streams of Otsego Lake based on historical counts and climate data.</p>
<h3 id="multi">
<b> Walleye data </b>
</h3>
<p>We begin by reading in the data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the walleye data</span>
  wae =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;classData-master/otsegoRunCounts.csv&#39;</span>, <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>Have a look at the first ten lines of the data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="kw">head</span>(wae, <span class="dv">10</span>)
        date          site Length..mm. Weight..gm.  Sex Stage Count
<span class="dv">1</span>  <span class="dv">4</span><span class="op">/</span><span class="dv">10</span><span class="op">/</span><span class="dv">2017</span>  Shadow Brook           <span class="dv">0</span>          <span class="ot">NA</span> Male  Ripe     <span class="dv">1</span>
<span class="dv">2</span>  <span class="dv">4</span><span class="op">/</span><span class="dv">12</span><span class="op">/</span><span class="dv">2017</span>  Hayden Creek           <span class="dv">0</span>          <span class="ot">NA</span> Male  Ripe     <span class="dv">1</span>
<span class="dv">3</span>  <span class="dv">4</span><span class="op">/</span><span class="dv">17</span><span class="op">/</span><span class="dv">2009</span> Cripple Creek         <span class="dv">340</span>          <span class="ot">NA</span> Male  Ripe     <span class="dv">1</span>
<span class="dv">4</span>  <span class="dv">4</span><span class="op">/</span><span class="dv">17</span><span class="op">/</span><span class="dv">2009</span> Cripple Creek         <span class="dv">353</span>          <span class="ot">NA</span> Male  Ripe     <span class="dv">1</span>
<span class="dv">5</span>   <span class="dv">4</span><span class="op">/</span><span class="dv">5</span><span class="op">/</span><span class="dv">2009</span>  Hayden Creek         <span class="dv">354</span>          <span class="ot">NA</span> Male  Ripe     <span class="dv">1</span>
<span class="dv">6</span>  <span class="dv">4</span><span class="op">/</span><span class="dv">20</span><span class="op">/</span><span class="dv">2009</span>  Shadow Brook         <span class="dv">360</span>          <span class="ot">NA</span> Male Spent     <span class="dv">1</span>
<span class="dv">7</span>  <span class="dv">4</span><span class="op">/</span><span class="dv">12</span><span class="op">/</span><span class="dv">2009</span>  Shadow Brook         <span class="dv">364</span>          <span class="ot">NA</span> Male  Ripe     <span class="dv">1</span>
<span class="dv">8</span>  <span class="dv">4</span><span class="op">/</span><span class="dv">16</span><span class="op">/</span><span class="dv">2009</span> Cripple Creek         <span class="dv">365</span>          <span class="ot">NA</span> Male  Ripe     <span class="dv">1</span>
<span class="dv">9</span>  <span class="dv">4</span><span class="op">/</span><span class="dv">18</span><span class="op">/</span><span class="dv">2009</span>  Shadow Brook         <span class="dv">366</span>          <span class="ot">NA</span> Male  Ripe     <span class="dv">1</span>
<span class="dv">10</span> <span class="dv">4</span><span class="op">/</span><span class="dv">16</span><span class="op">/</span><span class="dv">2009</span> Cripple Creek         <span class="dv">369</span>          <span class="ot">NA</span> Male  Ripe     <span class="dv">1</span></code></pre></div>
<p>And check out the data structure</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">str</span>(wae)
<span class="st">&#39;data.frame&#39;</span><span class="op">:</span><span class="st">   </span><span class="dv">1879</span> obs. of  <span class="dv">7</span> variables<span class="op">:</span>
<span class="st"> </span><span class="er">$</span><span class="st"> </span>date       <span class="op">:</span><span class="st"> </span>chr  <span class="st">&quot;4/10/2017&quot;</span> <span class="st">&quot;4/12/2017&quot;</span> <span class="st">&quot;4/17/2009&quot;</span> <span class="st">&quot;4/17/2009&quot;</span> ...
 <span class="op">$</span><span class="st"> </span>site       <span class="op">:</span><span class="st"> </span>chr  <span class="st">&quot;Shadow Brook&quot;</span> <span class="st">&quot;Hayden Creek&quot;</span> <span class="st">&quot;Cripple Creek&quot;</span> <span class="st">&quot;Cripple Creek&quot;</span> ...
 <span class="op">$</span><span class="st"> </span>Length..mm.<span class="op">:</span><span class="st"> </span>int  <span class="dv">0</span> <span class="dv">0</span> <span class="dv">340</span> <span class="dv">353</span> <span class="dv">354</span> <span class="dv">360</span> <span class="dv">364</span> <span class="dv">365</span> <span class="dv">366</span> <span class="dv">369</span> ...
 <span class="op">$</span><span class="st"> </span>Weight..gm.<span class="op">:</span><span class="st"> </span>num  <span class="ot">NA</span> <span class="ot">NA</span> <span class="ot">NA</span> <span class="ot">NA</span> <span class="ot">NA</span> <span class="ot">NA</span> <span class="ot">NA</span> <span class="ot">NA</span> <span class="ot">NA</span> <span class="ot">NA</span> ...
 <span class="op">$</span><span class="st"> </span>Sex        <span class="op">:</span><span class="st"> </span>chr  <span class="st">&quot;Male&quot;</span> <span class="st">&quot;Male&quot;</span> <span class="st">&quot;Male&quot;</span> <span class="st">&quot;Male&quot;</span> ...
 <span class="op">$</span><span class="st"> </span>Stage      <span class="op">:</span><span class="st"> </span>chr  <span class="st">&quot;Ripe&quot;</span> <span class="st">&quot;Ripe&quot;</span> <span class="st">&quot;Ripe&quot;</span> <span class="st">&quot;Ripe&quot;</span> ...
 <span class="op">$</span><span class="st"> </span>Count      <span class="op">:</span><span class="st"> </span>int  <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> ...</code></pre></div>
<p>These data are measurements of the length and mass of individual walleye at various reproductive stages that were captured in spawning tributaries of Otsego Lake during the 2009 and 2013 spawning season. o</p>
<p>We will use the data to predict number of walleye we expect to see each day in the spawning tribs during spring 2017 based on historical counts.</p>
<h3 id="multi">
<b> Climate Data </b>
</h3>
<p>For this example, we are interested in predicting the timing of the walleye run. Generally speaking, phenology of spawning events in fishes and many other animals is driven by circannual rhythms entrained by photoperiod. However, temperature often acts as a trigger for releasing behavior related to spawning…<strong>Translation</strong>: if we want to predict timing of the spawning run, we need to have data for photoperiod and temperature, too!</p>
<p>I collected some of this information ahead of time for you. Temperature, precipitation, and snow depth data were downloaded from the following, surely reliable, <a href="http://www.usclimatedata.com/climate/cooperstown/new-york/united-states/usny0326/2017/3">website</a>.</p>
<p>Read in the data an have a look at the structure</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the climate data</span>
  climate=<span class="kw">read.csv</span>(<span class="st">&#39;classData-master/tempdata.csv&#39;</span>, <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)

<span class="co"># Have a look at the data structure</span>
  <span class="kw">str</span>(climate)
  </code></pre></div>
<pre><code>&#39;data.frame&#39;:   693 obs. of  3 variables:
 $ date  : chr  &quot;1/1/2009&quot; &quot;1/2/2009&quot; &quot;1/3/2009&quot; &quot;1/4/2009&quot; ...
 $ high_f: num  19.9 17.1 28 28 33.1 32 35.1 34 30 21.9 ...
 $ low_f : num  0 3 12.9 12.9 10.9 12 12 27 12.9 0 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Have a look at the data structure</span>
  <span class="kw">str</span>(climate)
<span class="st">&#39;data.frame&#39;</span><span class="op">:</span><span class="st">   </span><span class="dv">693</span> obs. of  <span class="dv">3</span> variables<span class="op">:</span>
<span class="st"> </span><span class="er">$</span><span class="st"> </span>date  <span class="op">:</span><span class="st"> </span>chr  <span class="st">&quot;1/1/2009&quot;</span> <span class="st">&quot;1/2/2009&quot;</span> <span class="st">&quot;1/3/2009&quot;</span> <span class="st">&quot;1/4/2009&quot;</span> ...
 <span class="op">$</span><span class="st"> </span>high_f<span class="op">:</span><span class="st"> </span>num  <span class="fl">19.9</span> <span class="fl">17.1</span> <span class="dv">28</span> <span class="dv">28</span> <span class="fl">33.1</span> <span class="dv">32</span> <span class="fl">35.1</span> <span class="dv">34</span> <span class="dv">30</span> <span class="fl">21.9</span> ...
 <span class="op">$</span><span class="st"> </span>low_f <span class="op">:</span><span class="st"> </span>num  <span class="dv">0</span> <span class="dv">3</span> <span class="fl">12.9</span> <span class="fl">12.9</span> <span class="fl">10.9</span> <span class="dv">12</span> <span class="dv">12</span> <span class="dv">27</span> <span class="fl">12.9</span> <span class="dv">0</span> ...</code></pre></div>
<h3>
<b> Data management </b>
</h3>
<h4 id="multi">
<b> Walleye counts </b>
</h4>
<p>Okay, so now we have fish records by date and we have some climate data for those same dates and then some. Now, we need to smash all of those data together so we can use them.</p>
<p>Our first step will be to summarize the walleye counts by date. To do this, we will use the <code>plyr</code> package in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the package</span>
  <span class="kw">library</span>(plyr)</code></pre></div>
<p>Tally up total counts of walleye in each stream on each day.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a column of ones that we can sum</span>
weye =<span class="st"> </span><span class="kw">ddply</span>(wae, <span class="kw">c</span>(<span class="st">&#39;date&#39;</span>, <span class="st">&#39;site&#39;</span>), summarize, <span class="dt">counts =</span> <span class="kw">length</span>(Sex))</code></pre></div>
<h4>
<b> Climate data </b>
</h4>
<p>Next, we will get the climate data in order.</p>
<p>Because temperature fluctuates pretty widely in the spring, we often think of accumulated thermal units (ATU) or degree days as having more of an influence on the reproductive biology of many organisms rather than just absolute temperatures. You can think of degree days as the sum of all temperatures from some starting date until some ending date. In our case, we will add up the degree days from January 1 until date i in our dataframe to get degree days for each observation.</p>
<p>First, we will convert our temperatures to celcius like the rest of the world.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Convert from farenheit to celcius</span>
  climate<span class="op">$</span>high_c =<span class="st"> </span>(climate<span class="op">$</span>high_f<span class="op">-</span><span class="dv">32</span>)<span class="op">*</span><span class="dv">5</span><span class="op">/</span><span class="dv">9</span>
  climate<span class="op">$</span>low_c =<span class="st"> </span>(climate<span class="op">$</span>low_f<span class="op">-</span><span class="dv">32</span>)<span class="op">*</span><span class="dv">5</span><span class="op">/</span><span class="dv">9</span></code></pre></div>
<p>Next, we will calculate degree days (in <span class="math inline">\(^{\circ}\)</span>C) using both the high temp and the low temp. We will start by calculating the mean of highs and lows, and then add them up for the time period of interest. Ideally, we would be working with averages, but this will do for now.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate mean based on daily highs and lows</span>
  climate<span class="op">$</span>mean_c =<span class="st"> </span><span class="kw">apply</span>(climate[ , <span class="dv">4</span><span class="op">:</span><span class="dv">5</span>], <span class="dv">1</span>, mean)

<span class="co"># Exclude values less than zero from this calculation</span>
  climate<span class="op">$</span>ddPrep =<span class="st"> </span>climate<span class="op">$</span>mean_c
  
  climate<span class="op">$</span>ddPrep[climate<span class="op">$</span>ddPrep <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>] =<span class="st"> </span><span class="dv">0</span>

<span class="co"># Change date to a date object from factor</span>
  <span class="co"># Load lubridate package</span>
    <span class="kw">library</span>(lubridate)
  <span class="co"># Convert to date</span>
    climate<span class="op">$</span>date =<span class="st"> </span><span class="kw">as.Date</span>(<span class="kw">as.character</span>(climate<span class="op">$</span>date),
                           <span class="dt">format=</span><span class="st">&quot;%m/%d/%Y&quot;</span>)
  <span class="co"># Get ordinal date</span>
    climate<span class="op">$</span>day =<span class="st"> </span><span class="kw">yday</span>(climate<span class="op">$</span>date)
  <span class="co"># Get year</span>
    climate<span class="op">$</span>year =<span class="st"> </span><span class="kw">year</span>(climate<span class="op">$</span>date)
  <span class="co"># Sort climate data by date and year</span>
    climate =<span class="st"> </span>climate[<span class="kw">with</span>(climate, <span class="kw">order</span>(year, day)), ]    
    
<span class="co"># Add up the values to calculate degree</span>
<span class="co"># days for each year</span>
<span class="co"># Split the dataframe up into a list</span>
<span class="co"># with a df for each year</span>
    test =<span class="st"> </span><span class="kw">split</span>(climate<span class="op">$</span>ddPrep, climate<span class="op">$</span>year)
  <span class="co"># Replace NA values of temperature with</span>
  <span class="co"># arithmetic mean of </span>
  <span class="co"># preceding and following elements</span>
    <span class="kw">library</span>(zoo)
    test =<span class="st"> </span><span class="kw">mapply</span>(na.approx, test)
  <span class="co"># Calculate degree days for each year  </span>
    dd =<span class="st"> </span><span class="kw">mapply</span>(cumsum, test)
  <span class="co"># Unlist the result and add it to the climate data  </span>
    climate<span class="op">$</span>dd =<span class="st"> </span><span class="kw">unlist</span>(dd)</code></pre></div>
<h4>
<b> Data merge </b>
</h4>
<p>We can now add degree days to our fish data. What? Fish data? I forgot we had that!</p>
<p>To wrap up our climate analysis, we will quickly calculate day length at Otsego Lake based on lattitude for each day of our historical records using the <code>geosphere</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(geosphere)
climate<span class="op">$</span>daylight =<span class="st"> </span><span class="kw">daylength</span>(<span class="dt">lat =</span> <span class="fl">42.76</span>, <span class="dt">doy =</span> climate<span class="op">$</span>day)</code></pre></div>
<p>Our final job will be to add all of the climate data to our new dataframe containing walleye counts. This is relatively easy to do in R using the <code>merge()</code> function, like so:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># First, format the date column in the weye df</span>
  weye<span class="op">$</span>date =<span class="st"> </span><span class="kw">as.Date</span>(<span class="kw">as.character</span>(weye<span class="op">$</span>date), <span class="dt">format=</span><span class="st">&quot;%m/%d/%Y&quot;</span>)  

<span class="co"># Merge the two dataframes</span>
  eyes =<span class="st"> </span><span class="kw">merge</span>(weye, climate)

<span class="co"># Finally, we are going to get rid of Leatherstocking </span>
<span class="co"># for now because there are few data points there</span>
  eyes =<span class="st"> </span>eyes[eyes<span class="op">$</span>site<span class="op">!=</span><span class="st">&#39;Leatherstocking Creek&#39;</span>, ]
  
<span class="co"># Check to see how much data we have left</span>
  <span class="kw">nrow</span>(eyes)
[<span class="dv">1</span>] <span class="dv">84</span></code></pre></div>
<p>Wow, that’s rough! We went from several hundred lines of data to just a handful pretty quickly!!</p>
<h3>
<b> Modeling counts </b>
</h3>
<p>After our data management triathalon, we can finally model walleye counts as a function of some explanatory variables of interest. As has become our practice during the last several lessons, we will do this in both frequentist and Bayesian frameworks.</p>
<h4>
<b> REML estimation </b>
</h4>
<p>We start by estimating a model using REML. Let’s say for the sake of argument that we are simply interested in the lake-wide mean of our counts so that we know when students should, for example, be heading out to tributaries to look for walleyes in streams.</p>
<p>For now, we will model walleye count as a function of photoperiod, with a random effect of site on the intercepts. This model assumes that there is variability in counts of spawning individuals between sites, but that the relationship between photoperiod and count is the same across all sites. In this case, we will specify a quadratic relationship between counts and dates because we expect the number of fish to increase to some point in the run before it decreases. We are not interested</p>
<p>In the <code>lme4</code> package, the model might look something like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the package</span>
  <span class="kw">library</span>(lme4)

<span class="co"># Make the model</span>
  waeMod1 =<span class="st"> </span><span class="kw">glmer</span>(counts<span class="op">~</span>dd <span class="op">+</span><span class="st"> </span>(dd<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>site), <span class="dt">data=</span>eyes, <span class="dt">family=</span>poisson)
  
<span class="co"># Have a look-see at the results</span>
  <span class="kw">summary</span>(waeMod1)
Generalized linear mixed model fit by maximum <span class="kw">likelihood</span> (Laplace Approximation) [<span class="st">&#39;glmerMod&#39;</span>]
 Family<span class="op">:</span><span class="st"> </span><span class="kw">poisson</span>  ( log )
Formula<span class="op">:</span><span class="st"> </span>counts <span class="op">~</span><span class="st"> </span>dd <span class="op">+</span><span class="st"> </span>(dd<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>site)
   Data<span class="op">:</span><span class="st"> </span>eyes

     AIC      BIC   logLik deviance df.resid 
  <span class="fl">2001.5</span>   <span class="fl">2008.8</span>   <span class="op">-</span><span class="fl">997.7</span>   <span class="fl">1995.5</span>       <span class="dv">81</span> 

Scaled residuals<span class="op">:</span><span class="st"> </span>
<span class="st">   </span>Min     1Q Median     3Q    Max 
<span class="op">-</span><span class="fl">5.615</span> <span class="op">-</span><span class="fl">3.187</span> <span class="op">-</span><span class="fl">1.223</span>  <span class="fl">1.566</span> <span class="fl">15.840</span> 

Random effects<span class="op">:</span>
<span class="st"> </span>Groups Name        Variance Std.Dev.
 <span class="kw">site</span>   (Intercept) <span class="fl">0.1144</span>   <span class="fl">0.3382</span>  
Number of obs<span class="op">:</span><span class="st"> </span><span class="dv">84</span>, groups<span class="op">:</span><span class="st">  </span>site, <span class="dv">3</span>

Fixed effects<span class="op">:</span>
<span class="st">             </span>Estimate Std. Error z value <span class="kw">Pr</span>(<span class="op">&gt;</span><span class="er">|</span>z<span class="op">|</span>)    
(Intercept) <span class="fl">2.5179198</span>  <span class="fl">0.2098985</span>  <span class="fl">11.996</span>  <span class="op">&lt;</span><span class="st"> </span><span class="fl">2e-16</span> <span class="op">**</span><span class="er">*</span>
dd          <span class="fl">0.0028820</span>  <span class="fl">0.0004679</span>   <span class="fl">6.159</span> <span class="fl">7.31e-10</span> <span class="op">**</span><span class="er">*</span>
<span class="op">---</span>
Signif. codes<span class="op">:</span><span class="st">  </span><span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span>

Correlation of Fixed Effects<span class="op">:</span>
<span class="st">   </span>(Intr)
dd <span class="op">-</span><span class="fl">0.338</span>
convergence code<span class="op">:</span><span class="st"> </span><span class="dv">0</span>
Model is nearly unidentifiable<span class="op">:</span><span class="st"> </span>very large eigenvalue
 <span class="op">-</span><span class="st"> </span>Rescale variables?</code></pre></div>
<p>Crap! Our model failed to converge. It looks like this is probably because we have variables on really different scales, and because we have a lot of colinearity between them. So, let’s try standardizing our covariates to see what we can do about that:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Standardize photoperiod</span>
  eyes<span class="op">$</span>sdd =<span class="st"> </span><span class="kw">scale</span>(eyes<span class="op">$</span>dd) 

<span class="co"># Make the model</span>
  waeMod2 =<span class="st"> </span><span class="kw">glmer</span>(counts<span class="op">~</span>sdd <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(sdd<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>site),
                  <span class="dt">data=</span>eyes,
                  <span class="dt">family=</span><span class="kw">negative.binomial</span>(<span class="dt">theta=</span><span class="dv">1000</span>))
  
<span class="co"># Have a look-see at the results</span>
  <span class="kw">summary</span>(waeMod2)
Generalized linear mixed model fit by maximum <span class="kw">likelihood</span> (Laplace Approximation) [<span class="st">&#39;glmerMod&#39;</span>]
 Family<span class="op">:</span><span class="st"> </span>Negative <span class="kw">Binomial</span>(<span class="dv">1000</span>)  ( log )
Formula<span class="op">:</span><span class="st"> </span>counts <span class="op">~</span><span class="st"> </span>sdd <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(sdd<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>site)
   Data<span class="op">:</span><span class="st"> </span>eyes

     AIC      BIC   logLik deviance df.resid 
  <span class="fl">1680.3</span>   <span class="fl">1692.5</span>   <span class="op">-</span><span class="fl">835.2</span>   <span class="fl">1670.3</span>       <span class="dv">79</span> 

Scaled residuals<span class="op">:</span><span class="st"> </span>
<span class="st">    </span>Min      1Q  Median      3Q     Max 
<span class="op">-</span><span class="fl">5.8122</span> <span class="op">-</span><span class="fl">2.6153</span> <span class="op">-</span><span class="fl">0.8857</span>  <span class="fl">1.8710</span> <span class="fl">11.6470</span> 

Random effects<span class="op">:</span>
<span class="st"> </span>Groups Name        Variance Std.Dev.
 <span class="kw">site</span>   (Intercept) <span class="fl">0.07527</span>  <span class="fl">0.2743</span>  
Number of obs<span class="op">:</span><span class="st"> </span><span class="dv">84</span>, groups<span class="op">:</span><span class="st">  </span>site, <span class="dv">3</span>

Fixed effects<span class="op">:</span>
<span class="st">            </span>Estimate Std. Error z value <span class="kw">Pr</span>(<span class="op">&gt;</span><span class="er">|</span>z<span class="op">|</span>)    
(Intercept)  <span class="fl">3.26437</span>    <span class="fl">0.16230</span>   <span class="fl">20.11</span>   <span class="op">&lt;</span><span class="fl">2e-16</span> <span class="op">**</span><span class="er">*</span>
sdd          <span class="fl">0.34889</span>    <span class="fl">0.03256</span>   <span class="fl">10.71</span>   <span class="op">&lt;</span><span class="fl">2e-16</span> <span class="op">**</span><span class="er">*</span>
<span class="kw">I</span>(sdd<span class="op">^</span><span class="dv">2</span>)    <span class="op">-</span><span class="fl">0.43186</span>    <span class="fl">0.03043</span>  <span class="op">-</span><span class="fl">14.19</span>   <span class="op">&lt;</span><span class="fl">2e-16</span> <span class="op">**</span><span class="er">*</span>
<span class="op">---</span>
Signif. codes<span class="op">:</span><span class="st">  </span><span class="dv">0</span> <span class="st">&#39;***&#39;</span> <span class="fl">0.001</span> <span class="st">&#39;**&#39;</span> <span class="fl">0.01</span> <span class="st">&#39;*&#39;</span> <span class="fl">0.05</span> <span class="st">&#39;.&#39;</span> <span class="fl">0.1</span> <span class="st">&#39; &#39;</span> <span class="dv">1</span>

Correlation of Fixed Effects<span class="op">:</span>
<span class="st">         </span>(Intr) sdd   
sdd       <span class="fl">0.009</span>       
<span class="kw">I</span>(sdd<span class="op">^</span><span class="dv">2</span>) <span class="op">-</span><span class="fl">0.111</span> <span class="op">-</span><span class="fl">0.321</span></code></pre></div>
<p>Okay, looks like we are doing a lot better with this now.</p>
<p>As we look through these results, we can see that we have a significant effect of degree days on spawning behavior. What’s more is that our count of spawning fish appears to increase during the year to a point before it starts to decrease.</p>
<p>Now, if we want, we can make a graph to show these predictions. Here, we make predictions for all years, and then we plot those predictions for a single site (<code>Shadow Brook</code>).</p>
<p>You will need to install the <code>merTools</code> package for this one before you can run the code below (<code>install.packages(merTolls)</code>). You will have to allow it to build from source.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the merTools package</span>
  <span class="kw">library</span>(merTools)
  
<span class="co"># Make a new dataframe for prediction</span>
  sdd =<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="kw">min</span>(eyes<span class="op">$</span>sdd), <span class="dt">to =</span> <span class="kw">max</span>(eyes<span class="op">$</span>sdd), <span class="dt">by =</span> .<span class="dv">1</span>)
  site =<span class="st"> </span><span class="kw">sort</span>(<span class="kw">rep</span>(<span class="kw">unique</span>(eyes<span class="op">$</span>site), <span class="kw">length</span>(sdd)))
  sdd =<span class="st"> </span><span class="kw">rep</span>(sdd, <span class="kw">length</span>(<span class="kw">unique</span>(eyes<span class="op">$</span>site)))
  newdata =<span class="st"> </span><span class="kw">data.frame</span>(sdd)
  
<span class="co"># Simulate predictions from the relationship stored in the model fit using</span>
<span class="co"># our new data</span>
  PI &lt;-<span class="st"> </span><span class="kw">predictInterval</span>(<span class="dt">merMod =</span> waeMod2, <span class="dt">newdata =</span> newdata, 
                        <span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">n.sims =</span> <span class="dv">1000</span>,
                        <span class="dt">stat =</span> <span class="st">&quot;median&quot;</span>, <span class="dt">type=</span><span class="st">&quot;linear.prediction&quot;</span>,
                        <span class="dt">include.resid.var =</span> <span class="ot">TRUE</span>)
  PI =<span class="st"> </span><span class="kw">apply</span>(PI, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), exp)
  
<span class="co"># Plot the raw data but don&#39;t label the x-axis</span>
<span class="co"># because we will want to add unstandardized labels</span>
<span class="co"># even though our regression used standardized labels</span>
  <span class="kw">plot</span>(eyes<span class="op">$</span>sdd[eyes<span class="op">$</span>site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>],
       eyes<span class="op">$</span>counts[eyes<span class="op">$</span>site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>],
       <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">500</span>), <span class="dt">pch=</span><span class="dv">21</span>,
       <span class="dt">bg=</span><span class="kw">c</span>(<span class="st">&#39;gray87&#39;</span>, <span class="st">&#39;gray60&#39;</span>,<span class="st">&#39;gray40&#39;</span>, <span class="st">&#39;black&#39;</span>)[<span class="kw">as.factor</span>(eyes<span class="op">$</span>year)],
       <span class="dt">cex=</span><span class="fl">1.9</span>, <span class="dt">xlab=</span><span class="st">&#39;Degree days&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Count&#39;</span>,
       <span class="dt">xaxt=</span><span class="st">&#39;n&#39;</span>
       )

<span class="co"># Add lines to the plot</span>
  <span class="kw">lines</span>(newdata<span class="op">$</span>sdd[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>],
        PI[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>,<span class="dv">1</span>], <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;blue&#39;</span>) <span class="co"># Mean</span>
  <span class="kw">lines</span>(newdata<span class="op">$</span>sdd[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>],
        PI[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>,<span class="dv">2</span>], <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;red&#39;</span>) <span class="co"># Lower</span>
  <span class="kw">lines</span>(newdata<span class="op">$</span>sdd[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>],
        PI[site<span class="op">==</span><span class="st">&#39;Shadow Brook&#39;</span>,<span class="dv">3</span>], <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;red&#39;</span>) <span class="co"># Upper</span></code></pre></div>
<p><img src="hw11_glmm_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>We could also do this using our global parameter estimates and some new data. We see that our mean predictions aren’t terrible, but there is quite a bit of uncertainty here.</p>
<h4>
<b> Bayesian estimation </b>
</h4>
<p>We can fit the same model in the Bayesian framework, too. Here we specify it just as we have during the past couple of weeks.</p>
<p>Let’s make sure to standardize covariates first:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#eyes = eyes[eyes$year!=2019, ]</span>
eyes<span class="op">$</span>stemp =<span class="st"> </span><span class="kw">scale</span>(eyes<span class="op">$</span>mean_c)  <span class="co"># Temperature</span>
eyes<span class="op">$</span>stemp[<span class="kw">is.na</span>(eyes<span class="op">$</span>stemp)] &lt;-<span class="st"> </span><span class="kw">mean</span>(eyes<span class="op">$</span>stemp, <span class="dt">na.rm =</span> T)
eyes<span class="op">$</span>sdd =<span class="st"> </span><span class="kw">scale</span>(eyes<span class="op">$</span>dd)        <span class="co"># Degree days</span>
eyes<span class="op">$</span>sdaylight  =<span class="st"> </span><span class="kw">scale</span>(eyes<span class="op">$</span>dd) <span class="co"># Daylight/photoperiod</span>
eyes<span class="op">$</span>doy =<span class="st"> </span><span class="kw">yday</span>(eyes<span class="op">$</span>date)
eyes<span class="op">$</span>sdoy =<span class="st"> </span><span class="kw">scale</span>(eyes<span class="op">$</span>doy)</code></pre></div>
<p>Now write out a model with random intercepts to predict count as a function of some covariate of interest (we’ll start with degree day in the example that follows):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Write model</span>
modelstring=<span class="st">&quot;</span>
<span class="st">  model {</span>
<span class="st">  </span>
<span class="st">    # Likelihood</span>
<span class="st">    for(i in 1:n){</span>
<span class="st">      count[i] ~ dnegbin(p[i], r)     # The random variable</span>
<span class="st">      p[i] &lt;- r/(r+lambda[i])</span>
<span class="st">      log(lambda[i]) &lt;- mu[i]</span>
<span class="st">      mu[i] &lt;- alpha[site[i]] + beta*X[i] + beta2*(X[i]^2) # Expectation</span>
<span class="st">    }</span>
<span class="st">    </span>
<span class="st">    # Priors</span>
<span class="st">    for (i in 1:ngroups){      </span>
<span class="st">      alpha[i] ~ dnorm(mu.int, tau.int)   # Random intercepts</span>
<span class="st">    }</span>
<span class="st">    </span>
<span class="st">    mu.int ~ dnorm(0, 0.1)       # Mean hyperparameter for random intercepts</span>
<span class="st">    tau.int &lt;- 1 / (sigma.int * sigma.int)</span>
<span class="st">    sigma.int ~ dunif(0, 100)      # SD hyperparameter for random intercepts</span>
<span class="st">    </span>
<span class="st">    beta ~ dnorm(0, taub)          # Common slope</span>
<span class="st">    taub &lt;- 1 / ( sigmab * sigmab)    # Residual precision</span>
<span class="st">    sigmab ~ dunif(0, 100)          # Residual standard deviation</span>
<span class="st">    </span>
<span class="st">    beta2 ~ dnorm(0, taub2)          # Common slope</span>
<span class="st">    taub2 &lt;- 1 / ( sigmab2 * sigmab2)    # Residual precision</span>
<span class="st">    sigmab2 ~ dunif(0, 100)          # Residual standard deviation</span>
<span class="st">    </span>
<span class="st">    r ~ dgamma(0.001, 0.001)          # Site-specific overdispersion</span>

<span class="st">  }</span>
<span class="st">&quot;</span>

<span class="co"># Bundle data</span>
  wae.data &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">count=</span>eyes<span class="op">$</span>count,
                   <span class="dt">site =</span> <span class="kw">as.numeric</span>(<span class="kw">as.factor</span>(eyes<span class="op">$</span>site)), 
                   <span class="dt">X =</span> <span class="kw">as.vector</span>(eyes<span class="op">$</span>sdd), <span class="co"># replace covariates here</span>
                   <span class="dt">ngroups =</span> <span class="kw">length</span>(<span class="kw">unique</span>(eyes<span class="op">$</span>site)),
                   <span class="dt">n =</span> <span class="kw">nrow</span>(eyes)
                   )
  
<span class="co"># Inits function</span>
inits &lt;-<span class="st"> </span><span class="cf">function</span>(){
  <span class="kw">list</span>(
    <span class="dt">alpha =</span> <span class="kw">rnorm</span>(<span class="kw">length</span>(<span class="kw">unique</span>(eyes<span class="op">$</span>site)), <span class="dv">0</span>, <span class="dv">1</span>),
    <span class="dt">r =</span> <span class="kw">rgamma</span>(<span class="kw">length</span>(<span class="kw">unique</span>(eyes<span class="op">$</span>site)), <span class="fl">0.1</span>, <span class="fl">0.01</span>),
    <span class="dt">beta =</span> <span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),
    <span class="dt">beta2 =</span> <span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">10</span>),
    <span class="dt">mu.int =</span> <span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),
    <span class="dt">sigma.int =</span> <span class="kw">rlnorm</span>(<span class="dv">1</span>),
    <span class="dt">sigmab =</span> <span class="kw">rlnorm</span>(<span class="dv">1</span>),
    <span class="dt">sigmab2=</span><span class="kw">rlnorm</span>(<span class="dv">1</span>)
  )}

<span class="co"># Parameters to estimate</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;beta2&quot;</span>,<span class="st">&quot;mu.int&quot;</span>, <span class="st">&quot;sigma.int&quot;</span>, <span class="st">&quot;sigmab&quot;</span>,
                <span class="st">&quot;sigmab2&quot;</span>)

<span class="co"># MCMC settings</span>
ni &lt;-<span class="dv">5000</span>
nb &lt;-<span class="st"> </span><span class="dv">2500</span>
nt &lt;-<span class="st"> </span><span class="dv">10</span>
nc &lt;-<span class="st"> </span><span class="dv">3</span>

<span class="co"># Load the package</span>
  <span class="kw">library</span>(R2jags)

<span class="co"># Run the Gibbs sampler</span>
  out &lt;-<span class="kw">jags</span>(wae.data, <span class="dt">inits=</span><span class="ot">NULL</span>, parameters,
             <span class="dt">model.file =</span> <span class="kw">textConnection</span>(modelstring),
             <span class="dt">n.thin=</span>nt, <span class="dt">n.chains=</span>nc, <span class="dt">n.burnin=</span>nb, <span class="dt">n.iter=</span>ni,
             <span class="dt">progress.bar =</span> <span class="st">&#39;text&#39;</span>)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information<span class="op">:</span>
<span class="st">   </span>Observed stochastic nodes<span class="op">:</span><span class="st"> </span><span class="dv">84</span>
   Unobserved stochastic nodes<span class="op">:</span><span class="st"> </span><span class="dv">10</span>
   Total graph size<span class="op">:</span><span class="st"> </span><span class="dv">828</span>

Initializing model
  
<span class="co"># Print the results  </span>
  <span class="kw">print</span>(out, <span class="dt">digits=</span><span class="dv">3</span>)
Inference <span class="cf">for</span> Bugs model at <span class="st">&quot;5&quot;</span>, fit using jags,
 <span class="dv">3</span> chains, each with <span class="dv">5000</span> <span class="kw">iterations</span> (first <span class="dv">2500</span> discarded), n.thin =<span class="st"> </span><span class="dv">10</span>
 n.sims =<span class="st"> </span><span class="dv">750</span> iterations saved
          mu.vect sd.vect    <span class="fl">2.5</span><span class="op">%     25%</span><span class="st">     </span><span class="dv">50</span><span class="op">%     75%</span><span class="st">   </span><span class="fl">97.5</span>%  Rhat n.eff
alpha[<span class="dv">1</span>]    <span class="fl">2.897</span>   <span class="fl">0.291</span>   <span class="fl">2.339</span>   <span class="fl">2.697</span>   <span class="fl">2.891</span>   <span class="fl">3.085</span>   <span class="fl">3.484</span> <span class="fl">1.000</span>   <span class="dv">750</span>
alpha[<span class="dv">2</span>]    <span class="fl">3.270</span>   <span class="fl">0.186</span>   <span class="fl">2.933</span>   <span class="fl">3.142</span>   <span class="fl">3.268</span>   <span class="fl">3.386</span>   <span class="fl">3.660</span> <span class="fl">0.999</span>   <span class="dv">750</span>
alpha[<span class="dv">3</span>]    <span class="fl">3.586</span>   <span class="fl">0.173</span>   <span class="fl">3.247</span>   <span class="fl">3.467</span>   <span class="fl">3.586</span>   <span class="fl">3.703</span>   <span class="fl">3.933</span> <span class="fl">1.005</span>   <span class="dv">390</span>
beta        <span class="fl">0.353</span>   <span class="fl">0.118</span>   <span class="fl">0.118</span>   <span class="fl">0.273</span>   <span class="fl">0.355</span>   <span class="fl">0.436</span>   <span class="fl">0.572</span> <span class="fl">1.000</span>   <span class="dv">750</span>
beta2      <span class="op">-</span><span class="fl">0.406</span>   <span class="fl">0.091</span>  <span class="op">-</span><span class="fl">0.589</span>  <span class="op">-</span><span class="fl">0.468</span>  <span class="op">-</span><span class="fl">0.406</span>  <span class="op">-</span><span class="fl">0.350</span>  <span class="op">-</span><span class="fl">0.224</span> <span class="fl">0.999</span>   <span class="dv">750</span>
mu.int      <span class="fl">3.012</span>   <span class="fl">0.887</span>   <span class="fl">0.429</span>   <span class="fl">2.837</span>   <span class="fl">3.193</span>   <span class="fl">3.446</span>   <span class="fl">4.269</span> <span class="fl">1.020</span>   <span class="dv">700</span>
sigma.int   <span class="fl">1.212</span>   <span class="fl">1.484</span>   <span class="fl">0.081</span>   <span class="fl">0.380</span>   <span class="fl">0.683</span>   <span class="fl">1.422</span>   <span class="fl">5.661</span> <span class="fl">1.000</span>   <span class="dv">750</span>
sigmab     <span class="fl">18.535</span>  <span class="fl">25.175</span>   <span class="fl">0.264</span>   <span class="fl">1.550</span>   <span class="fl">5.996</span>  <span class="fl">25.948</span>  <span class="fl">88.604</span> <span class="fl">1.000</span>   <span class="dv">750</span>
sigmab2    <span class="fl">16.451</span>  <span class="fl">23.428</span>   <span class="fl">0.272</span>   <span class="fl">1.331</span>   <span class="fl">5.452</span>  <span class="fl">21.433</span>  <span class="fl">88.353</span> <span class="fl">1.001</span>   <span class="dv">750</span>
deviance  <span class="fl">671.275</span>   <span class="fl">3.511</span> <span class="fl">666.377</span> <span class="fl">668.708</span> <span class="fl">670.648</span> <span class="fl">673.253</span> <span class="fl">679.309</span> <span class="fl">1.000</span>   <span class="dv">750</span>

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction <span class="kw">factor</span> (at convergence, <span class="dt">Rhat=</span><span class="dv">1</span>).

DIC <span class="kw">info</span> (using the rule, <span class="dt">pD =</span> <span class="kw">var</span>(deviance)<span class="op">/</span><span class="dv">2</span>)
pD =<span class="st"> </span><span class="fl">6.2</span> and DIC =<span class="st"> </span><span class="fl">677.4</span>
DIC is an estimate of expected predictive <span class="kw">error</span> (lower deviance is better).</code></pre></div>
<p>We notice that all parameters converge. Note that if we run this without standardizing our degree day covariate, convergence is not quite as clean. This is likely because of correlations between <code>dd</code> and <code>dd2</code>.</p>
<p>One thing you might notice here is the shift in our upper 95% credible interval around the posterior prediction. This is pretty typical of phenology data, and is caused by the fact that we don’t really sample much once we stop catching fish. Something to consider when designing your own studies…</p>
<h3>
<b> Your mission </b>
</h3>
<p>If you choose this homework option, I would like you to do the following:</p>

<ol style="list-style-type: decimal">
<li>Re-run the code block above, replacing <code>sdd</code> in <code>wae.data</code> with each of the other standardized covariates from <code>eyes</code> (<code>stemp</code>, <code>sdaylight</code>, and <code>sdoy</code>). For each model, I want you to get the DIC and check convergence (do this one first).</li>
</ol>

<ol start="2" style="list-style-type: decimal">
<li>Then, using the best model DIC, please make predictions from the model coefficients. Below is an example using the degree day model above. You can use the predictions about walleye counts vs degree days to find out the approximate date of first spawn by looking up the date that corresponds to minimum degree day where predicted counts &gt; 0 in the climate data (or <code>temp</code>, <code>daylight</code>, <code>doy</code>).</li>
</ol>

<ol start="3" style="list-style-type: decimal">
<li>Submit a brief writeup describing methods and results.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a new sequence of standardized degree days  </span>
  sdd =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, .<span class="dv">1</span>)

<span class="co"># Make prediction from the model parameters</span>
  fit =<span class="st"> </span><span class="kw">exp</span>(
    <span class="kw">mean</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>mu.int)<span class="op">+</span>
<span class="st">    </span><span class="kw">mean</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta)<span class="op">*</span>sdd<span class="op">+</span>
<span class="st">    </span><span class="kw">mean</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta2)<span class="op">*</span>(sdd<span class="op">^</span><span class="dv">2</span>))

  lcis =<span class="st"> </span><span class="kw">exp</span>(
    <span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>mu.int, <span class="dt">probs=</span>.<span class="dv">025</span>)<span class="op">+</span>
<span class="st">    </span><span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta, <span class="dt">probs=</span>.<span class="dv">025</span>)<span class="op">*</span>sdd<span class="op">+</span>
<span class="st">    </span><span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta2, <span class="dt">probs=</span>.<span class="dv">025</span>)<span class="op">*</span>(sdd<span class="op">^</span><span class="dv">2</span>))
  
  ucis =<span class="st"> </span><span class="kw">exp</span>(
    <span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>mu.int, <span class="dt">probs=</span>.<span class="dv">975</span>)<span class="op">+</span>
<span class="st">    </span><span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta, <span class="dt">probs=</span>.<span class="dv">975</span>)<span class="op">*</span>sdd<span class="op">+</span>
<span class="st">    </span><span class="kw">quantile</span>(out<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list<span class="op">$</span>beta2, <span class="dt">probs=</span>.<span class="dv">975</span>)<span class="op">*</span>(sdd<span class="op">^</span><span class="dv">2</span>))
  
<span class="co"># Plot the predictions</span>
  <span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">1</span>,<span class="dv">1</span>))
  <span class="kw">plot</span>(eyes<span class="op">$</span>sdd, eyes<span class="op">$</span>counts,
       <span class="dt">pch=</span><span class="dv">21</span>, <span class="dt">bg=</span><span class="kw">c</span>(<span class="st">&#39;white&#39;</span>, <span class="st">&#39;gray&#39;</span>, <span class="st">&#39;black&#39;</span>)[<span class="kw">as.factor</span>(eyes<span class="op">$</span>site)], <span class="dt">cex=</span><span class="fl">1.2</span>,
       <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">max</span>(eyes<span class="op">$</span>counts)<span class="op">+</span><span class="dv">50</span>),
       <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="fl">2.9</span>, <span class="dv">3</span>),
       <span class="dt">xlab=</span><span class="st">&#39;Degree days (C)&#39;</span>, 
       <span class="dt">ylab=</span><span class="st">&#39;Count of spawners&#39;</span>,
       <span class="dt">xaxt=</span><span class="st">&#39;n&#39;</span>, <span class="dt">yaxt=</span><span class="st">&#39;n&#39;</span>)
  <span class="kw">lines</span>(sdd, fit, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&#39;black&#39;</span>)
  <span class="kw">lines</span>(sdd, lcis, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;gray40&#39;</span>)
  <span class="kw">lines</span>(sdd, ucis, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;gray40&#39;</span>)

<span class="co"># Add a new x-axis </span>
  <span class="kw">axis</span>(<span class="dt">side=</span><span class="dv">1</span>,
         <span class="dt">at=</span>(<span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">300</span>,<span class="dv">50</span>)<span class="op">-</span><span class="kw">mean</span>(eyes<span class="op">$</span>dd))<span class="op">/</span><span class="kw">sd</span>(eyes<span class="op">$</span>dd),
         <span class="dt">labels=</span> 
           <span class="co">#Get dd on original scale from a sequence</span>
           <span class="co"># of new standardized values</span>
           <span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">300</span>,<span class="dv">50</span>)
         )
  
<span class="co"># Add a rotated y-axis</span>
  <span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">las=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="hw11_glmm_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
<div id="plant-surveys" class="section level3">
<h3><span style="color:gray"><b> <strong>Plant surveys</strong> </b></span></h3>
<h2 id="multi">
<b> Big milfoil problems </b>
</h2>
<p>For this example, we will look at increases or decreases in Eurasian watermilfoil (<em>Myriophylum spicatum</em>) following herbicide treatment at different doses. We will use a Bernoulli response (1 or 0) to test effects of turbidity on successful achievement of plant control across 30 sites.</p>
<h3 id="multi">
<b> Data </b>
</h3>
<p>Start by reading in the data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the plant data</span>
  plants =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;classData-master/plants2.csv&quot;</span>)</code></pre></div>
<p>This is a pretty straightforward data set compared to the walleye phenology set (hopefully that is not what led you here). Here, we have samples of Eurasian watermilfoil control from each of 30 experimental waterbodies treated with an herbicide at 5 different conductivities. Those data have been condensed to indicate whether the species increased or decreased at each site following herbicide application. Here, we will investigate the influence of conductivity (an index for turbidity where greater values indicate more turbid water) on this response, while accounting for random variation between sites.</p>
<h3 id="multi">
<b> Estimation with REML </b>
</h3>
<p>To start with, we will fit the model using REML. Here, we need to remember to specify a site-specific random effect on the intercept and we need to give R the <code>family</code> for our link function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit the model and store it to an object</span>
  plantMod1=<span class="kw">glmer</span>(success<span class="op">~</span>conductivity<span class="op">+</span>(<span class="dv">1</span><span class="op">|</span>site),
                  <span class="dt">data=</span>plants, <span class="dt">family=</span>binomial)</code></pre></div>
<p>Crud! The first thing we get smacked with is a warning about predictor (explanatory) variables being on very different scales. This is because the variable we are using (conductivity) varies across a huge range. That causes numerical problems during estimation with the algorithm being used.</p>
<p>Let’s scale and center (standardize) the conductivity variable</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Scale and center the variable</span>
  plants<span class="op">$</span>scond &lt;-<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">scale</span>(plants<span class="op">$</span>conductivity))

<span class="co"># Fit the model and store it to an object</span>
  plantMod1=<span class="kw">glmer</span>(success<span class="op">~</span>scond<span class="op">+</span>(<span class="dv">1</span><span class="op">|</span>site),
                  <span class="dt">data=</span>plants, <span class="dt">family=</span>binomial)</code></pre></div>
<p>After a quick look at the results, we see that turbidity has a significant, negative effect on the probability of successful control following this herbicide application.</p>
<p>We could make a graph of these results as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Get the fixed-effects coefficients from the model</span>
  f.coefs &lt;-<span class="st"> </span><span class="kw">summary</span>(plantMod1)<span class="op">$</span>coefficients

<span class="co"># Make a function to invert the logit</span>
  invlogit=<span class="cf">function</span>(x){<span class="kw">exp</span>(x)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(x))}

<span class="co"># Now we can make predictions with a sequence over </span>
<span class="co"># the range of observed values using y = mx + b</span>
  newCond =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="fl">0.10</span>)
  preds =<span class="st"> </span>f.coefs[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>f.coefs[<span class="dv">2</span>,<span class="dv">1</span>]<span class="op">*</span>newCond
  
<span class="co"># Get upper and lower 95% CI for predictions, too!</span>
  lwr =<span class="st"> </span>(f.coefs[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">-</span><span class="fl">1.96</span><span class="op">*</span>f.coefs[<span class="dv">1</span>,<span class="dv">2</span>]) <span class="op">+</span><span class="st"> </span>(f.coefs[<span class="dv">2</span>,<span class="dv">1</span>]<span class="op">-</span><span class="fl">1.96</span><span class="op">*</span>f.coefs[<span class="dv">2</span>,<span class="dv">2</span>])<span class="op">*</span>newCond
  upr =<span class="st"> </span>(f.coefs[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">+</span><span class="fl">1.96</span><span class="op">*</span>f.coefs[<span class="dv">1</span>,<span class="dv">2</span>]) <span class="op">+</span><span class="st"> </span>(f.coefs[<span class="dv">2</span>,<span class="dv">1</span>]<span class="op">+</span><span class="fl">1.96</span><span class="op">*</span>f.coefs[<span class="dv">2</span>,<span class="dv">2</span>])<span class="op">*</span>newCond
  
<span class="co"># Make a quick plot, inverting the logit function for </span>
<span class="co"># predictions on the fly</span>
  <span class="kw">plot</span>(newCond, <span class="kw">invlogit</span>(preds), <span class="dt">type=</span><span class="st">&#39;l&#39;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;white&#39;</span>,
       <span class="dt">xlab =</span> <span class="st">&#39;Standardized conductivity&#39;</span>,
       <span class="dt">ylab =</span> <span class="st">&#39;Probability of successful control&#39;</span>,
       <span class="dt">yaxt =</span> <span class="st">&#39;n&#39;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)
       )
  <span class="kw">axis</span>(<span class="dt">side=</span><span class="dv">2</span>, <span class="dt">las=</span><span class="dv">2</span>)
<span class="co"># Add lower and upper prediction of success by conductivity</span>
<span class="co"># also inverting logit on the fly</span>
  <span class="kw">polygon</span>(<span class="dt">x =</span> <span class="kw">c</span>(newCond, <span class="kw">rev</span>(newCond)), <span class="dt">y =</span> <span class="kw">c</span>(<span class="kw">invlogit</span>(lwr), <span class="kw">rev</span>(<span class="kw">invlogit</span>(upr))),
          <span class="dt">col =</span> <span class="kw">rgb</span>(<span class="fl">0.8</span>, <span class="fl">0.8</span>, <span class="fl">0.8</span>, <span class="fl">0.5</span>), <span class="dt">border =</span> <span class="ot">NA</span>
          )
  <span class="kw">lines</span>(newCond, <span class="kw">invlogit</span>(preds), <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&#39;black&#39;</span>)</code></pre></div>
<p><img src="hw11_glmm_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>We can see that most of the uncertainty in this relationship occurs at higher <code>conductivity</code>, and the rest of the pattern is much what we would expect based on the value of <code>beta</code> from our model.</p>
<p>If we wanted to make predictions for one or more of the sites, we could do so using the <code>merTools</code> package as demonstrated in the walleye phenology example (check it out for the homework!).</p>
<h3 id="multi">
<b> Bayesian estimation </b>
</h3>
<p>Now, we will estimate a model with random slopes using Bayesian methods.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modelstring=<span class="st">&quot;</span>
<span class="st">      model{</span>

<span class="st">        # Priors</span>
<span class="st">          for(i in 1:ngroups){</span>
<span class="st">            alpha[i] ~ dnorm(mu.int, tau.int) # Random intercepts</span>
<span class="st">          }</span>

<span class="st">          mu.int ~ dnorm(0, 0.001)            # Mean hyperparameter for ran. intercepts</span>
<span class="st">          tau.int &lt;- 1/(sigma.int*sigma.int)  # Precision for random intercepts</span>
<span class="st">          sigma.int ~ dunif(0, 100)           # SD hyperparameter for ran. intercepts</span>

<span class="st">          beta ~ dnorm(0, 0.001)              # Common slope for beta</span>

<span class="st">        # Likelihood</span>
<span class="st">          for(i in 1:N){</span>
<span class="st">            y[i] ~ dbern(mu[i])</span>
<span class="st">            logit(mu[i]) &lt;- alpha[site[i]] + beta*X[i]</span>
<span class="st">          }</span>
<span class="st">        }</span>
<span class="st">&quot;</span></code></pre></div>
<blockquote>
<p>Make the data</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Package the data in a list for JAGS</span>
    jags.data &lt;-<span class="st"> </span><span class="kw">list</span>(
      <span class="dt">y =</span> plants<span class="op">$</span>success,
      <span class="dt">site =</span> plants<span class="op">$</span>site,
      <span class="dt">X =</span> plants<span class="op">$</span>scond,
      <span class="dt">ngroups =</span> <span class="kw">length</span>(<span class="kw">unique</span>(plants<span class="op">$</span>site)),
      <span class="dt">N =</span> <span class="kw">nrow</span>(plants)
    )</code></pre></div>
<blockquote>
<p>Define parameters for monitoring</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Specify the parameters we want to monitor</span>
    parameters =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;mu.int&quot;</span>, <span class="st">&quot;sigma.int&quot;</span>)</code></pre></div>
<blockquote>
<p>Specify initial values</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a function to declare some initial values.</span>
    inits =<span class="st"> </span><span class="cf">function</span>(){
      <span class="kw">list</span>(
        <span class="dt">alpha =</span> <span class="kw">rnorm</span>(<span class="kw">length</span>(<span class="kw">unique</span>(plants<span class="op">$</span>site)), <span class="dv">0</span>, <span class="dv">2</span>),
        <span class="dt">beta =</span> <span class="kw">rnorm</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>),
        <span class="dt">mu.int =</span> <span class="kw">rnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>),
        <span class="dt">sigma.int =</span> <span class="kw">rlnorm</span>(<span class="dv">1</span>)
      )
    }</code></pre></div>
<blockquote>
<p>Define MCMC settings for Gibbs sampler</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># MCMC settings</span>
  ni &lt;-<span class="st"> </span><span class="dv">15000</span>
  nt &lt;-<span class="st"> </span><span class="dv">5</span>
  nb &lt;-<span class="st"> </span><span class="dv">5000</span>
  nc &lt;-<span class="st"> </span><span class="dv">3</span></code></pre></div>
<blockquote>
<p>Run the model</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the R2jags package</span>
  <span class="kw">library</span>(R2jags)

<span class="co"># Call JAGS from R and run the model</span>
   plant_glmm &lt;-<span class="st"> </span><span class="kw">jags</span>(jags.data, inits, parameters,
     <span class="dt">model.file =</span> <span class="kw">textConnection</span>(modelstring),
     <span class="dt">n.chains =</span> nc, <span class="dt">n.thin =</span> nt, <span class="dt">n.iter =</span> ni,
     <span class="dt">n.burnin =</span> nb)</code></pre></div>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 180
   Unobserved stochastic nodes: 33
   Total graph size: 950

Initializing model</code></pre>
<blockquote>
<p>Look at the results</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Print the model</span>
  <span class="kw">print</span>(plant_glmm, <span class="dt">digits=</span><span class="dv">3</span>)
Inference <span class="cf">for</span> Bugs model at <span class="st">&quot;6&quot;</span>, fit using jags,
 <span class="dv">3</span> chains, each with <span class="dv">15000</span> <span class="kw">iterations</span> (first <span class="dv">5000</span> discarded), n.thin =<span class="st"> </span><span class="dv">5</span>
 n.sims =<span class="st"> </span><span class="dv">6000</span> iterations saved
          mu.vect sd.vect    <span class="fl">2.5</span><span class="op">%     25%</span><span class="st">     </span><span class="dv">50</span><span class="op">%     75%</span><span class="st">   </span><span class="fl">97.5</span>%  Rhat n.eff
alpha[<span class="dv">1</span>]    <span class="fl">1.361</span>   <span class="fl">0.644</span>   <span class="fl">0.328</span>   <span class="fl">0.938</span>   <span class="fl">1.269</span>   <span class="fl">1.692</span>   <span class="fl">2.915</span> <span class="fl">1.001</span>  <span class="dv">3200</span>
alpha[<span class="dv">2</span>]    <span class="fl">1.657</span>   <span class="fl">0.815</span>   <span class="fl">0.539</span>   <span class="fl">1.086</span>   <span class="fl">1.464</span>   <span class="fl">2.083</span>   <span class="fl">3.654</span> <span class="fl">1.002</span>  <span class="dv">2400</span>
alpha[<span class="dv">3</span>]    <span class="fl">1.360</span>   <span class="fl">0.652</span>   <span class="fl">0.332</span>   <span class="fl">0.930</span>   <span class="fl">1.254</span>   <span class="fl">1.684</span>   <span class="fl">2.934</span> <span class="fl">1.002</span>  <span class="dv">2500</span>
alpha[<span class="dv">4</span>]    <span class="fl">0.789</span>   <span class="fl">0.598</span>  <span class="op">-</span><span class="fl">0.498</span>   <span class="fl">0.459</span>   <span class="fl">0.839</span>   <span class="fl">1.157</span>   <span class="fl">1.901</span> <span class="fl">1.002</span>  <span class="dv">2200</span>
alpha[<span class="dv">5</span>]    <span class="fl">1.075</span>   <span class="fl">0.580</span>  <span class="op">-</span><span class="fl">0.045</span>   <span class="fl">0.722</span>   <span class="fl">1.050</span>   <span class="fl">1.400</span>   <span class="fl">2.325</span> <span class="fl">1.001</span>  <span class="dv">6000</span>
alpha[<span class="dv">6</span>]    <span class="fl">1.080</span>   <span class="fl">0.585</span>  <span class="op">-</span><span class="fl">0.062</span>   <span class="fl">0.726</span>   <span class="fl">1.058</span>   <span class="fl">1.398</span>   <span class="fl">2.376</span> <span class="fl">1.001</span>  <span class="dv">3300</span>
alpha[<span class="dv">7</span>]    <span class="fl">1.372</span>   <span class="fl">0.656</span>   <span class="fl">0.325</span>   <span class="fl">0.939</span>   <span class="fl">1.269</span>   <span class="fl">1.711</span>   <span class="fl">2.910</span> <span class="fl">1.002</span>  <span class="dv">2400</span>
alpha[<span class="dv">8</span>]    <span class="fl">1.367</span>   <span class="fl">0.669</span>   <span class="fl">0.286</span>   <span class="fl">0.930</span>   <span class="fl">1.257</span>   <span class="fl">1.698</span>   <span class="fl">2.983</span> <span class="fl">1.001</span>  <span class="dv">6000</span>
alpha[<span class="dv">9</span>]    <span class="fl">1.374</span>   <span class="fl">0.667</span>   <span class="fl">0.323</span>   <span class="fl">0.938</span>   <span class="fl">1.266</span>   <span class="fl">1.701</span>   <span class="fl">3.012</span> <span class="fl">1.002</span>  <span class="dv">3100</span>
alpha[<span class="dv">10</span>]   <span class="fl">1.068</span>   <span class="fl">0.572</span>  <span class="op">-</span><span class="fl">0.078</span>   <span class="fl">0.723</span>   <span class="fl">1.056</span>   <span class="fl">1.389</span>   <span class="fl">2.295</span> <span class="fl">1.001</span>  <span class="dv">2900</span>
alpha[<span class="dv">11</span>]   <span class="fl">0.799</span>   <span class="fl">0.591</span>  <span class="op">-</span><span class="fl">0.530</span>   <span class="fl">0.475</span>   <span class="fl">0.853</span>   <span class="fl">1.177</span>   <span class="fl">1.861</span> <span class="fl">1.004</span>   <span class="dv">670</span>
alpha[<span class="dv">12</span>]   <span class="fl">0.793</span>   <span class="fl">0.590</span>  <span class="op">-</span><span class="fl">0.566</span>   <span class="fl">0.469</span>   <span class="fl">0.838</span>   <span class="fl">1.159</span>   <span class="fl">1.855</span> <span class="fl">1.001</span>  <span class="dv">5900</span>
alpha[<span class="dv">13</span>]   <span class="fl">1.371</span>   <span class="fl">0.670</span>   <span class="fl">0.308</span>   <span class="fl">0.937</span>   <span class="fl">1.264</span>   <span class="fl">1.709</span>   <span class="fl">2.963</span> <span class="fl">1.001</span>  <span class="dv">3900</span>
alpha[<span class="dv">14</span>]   <span class="fl">0.797</span>   <span class="fl">0.582</span>  <span class="op">-</span><span class="fl">0.513</span>   <span class="fl">0.484</span>   <span class="fl">0.852</span>   <span class="fl">1.155</span>   <span class="fl">1.874</span> <span class="fl">1.002</span>  <span class="dv">1900</span>
alpha[<span class="dv">15</span>]   <span class="fl">1.074</span>   <span class="fl">0.568</span>  <span class="op">-</span><span class="fl">0.040</span>   <span class="fl">0.726</span>   <span class="fl">1.045</span>   <span class="fl">1.397</span>   <span class="fl">2.323</span> <span class="fl">1.002</span>  <span class="dv">2600</span>
alpha[<span class="dv">16</span>]   <span class="fl">0.794</span>   <span class="fl">0.594</span>  <span class="op">-</span><span class="fl">0.531</span>   <span class="fl">0.457</span>   <span class="fl">0.854</span>   <span class="fl">1.171</span>   <span class="fl">1.881</span> <span class="fl">1.002</span>  <span class="dv">1400</span>
alpha[<span class="dv">17</span>]   <span class="fl">1.075</span>   <span class="fl">0.578</span>  <span class="op">-</span><span class="fl">0.044</span>   <span class="fl">0.737</span>   <span class="fl">1.046</span>   <span class="fl">1.392</span>   <span class="fl">2.338</span> <span class="fl">1.001</span>  <span class="dv">6000</span>
alpha[<span class="dv">18</span>]   <span class="fl">1.070</span>   <span class="fl">0.581</span>  <span class="op">-</span><span class="fl">0.033</span>   <span class="fl">0.721</span>   <span class="fl">1.042</span>   <span class="fl">1.384</span>   <span class="fl">2.358</span> <span class="fl">1.001</span>  <span class="dv">3500</span>
alpha[<span class="dv">19</span>]   <span class="fl">0.788</span>   <span class="fl">0.589</span>  <span class="op">-</span><span class="fl">0.527</span>   <span class="fl">0.469</span>   <span class="fl">0.835</span>   <span class="fl">1.153</span>   <span class="fl">1.886</span> <span class="fl">1.001</span>  <span class="dv">3200</span>
alpha[<span class="dv">20</span>]   <span class="fl">0.790</span>   <span class="fl">0.578</span>  <span class="op">-</span><span class="fl">0.522</span>   <span class="fl">0.466</span>   <span class="fl">0.838</span>   <span class="fl">1.164</span>   <span class="fl">1.830</span> <span class="fl">1.001</span>  <span class="dv">3700</span>
alpha[<span class="dv">21</span>]   <span class="fl">0.517</span>   <span class="fl">0.664</span>  <span class="op">-</span><span class="fl">1.014</span>   <span class="fl">0.137</span>   <span class="fl">0.615</span>   <span class="fl">0.987</span>   <span class="fl">1.566</span> <span class="fl">1.002</span>  <span class="dv">2700</span>
alpha[<span class="dv">22</span>]   <span class="fl">1.354</span>   <span class="fl">0.650</span>   <span class="fl">0.299</span>   <span class="fl">0.927</span>   <span class="fl">1.253</span>   <span class="fl">1.682</span>   <span class="fl">2.942</span> <span class="fl">1.001</span>  <span class="dv">4200</span>
alpha[<span class="dv">23</span>]   <span class="fl">1.072</span>   <span class="fl">0.572</span>  <span class="op">-</span><span class="fl">0.042</span>   <span class="fl">0.740</span>   <span class="fl">1.049</span>   <span class="fl">1.388</span>   <span class="fl">2.371</span> <span class="fl">1.001</span>  <span class="dv">6000</span>
alpha[<span class="dv">24</span>]   <span class="fl">1.080</span>   <span class="fl">0.579</span>  <span class="op">-</span><span class="fl">0.057</span>   <span class="fl">0.733</span>   <span class="fl">1.060</span>   <span class="fl">1.397</span>   <span class="fl">2.314</span> <span class="fl">1.002</span>  <span class="dv">2100</span>
alpha[<span class="dv">25</span>]   <span class="fl">0.782</span>   <span class="fl">0.589</span>  <span class="op">-</span><span class="fl">0.538</span>   <span class="fl">0.464</span>   <span class="fl">0.842</span>   <span class="fl">1.159</span>   <span class="fl">1.869</span> <span class="fl">1.001</span>  <span class="dv">3000</span>
alpha[<span class="dv">26</span>]   <span class="fl">0.517</span>   <span class="fl">0.676</span>  <span class="op">-</span><span class="fl">1.068</span>   <span class="fl">0.141</span>   <span class="fl">0.637</span>   <span class="fl">0.990</span>   <span class="fl">1.544</span> <span class="fl">1.002</span>  <span class="dv">2600</span>
alpha[<span class="dv">27</span>]   <span class="fl">1.085</span>   <span class="fl">0.579</span>  <span class="op">-</span><span class="fl">0.059</span>   <span class="fl">0.737</span>   <span class="fl">1.058</span>   <span class="fl">1.414</span>   <span class="fl">2.376</span> <span class="fl">1.001</span>  <span class="dv">5500</span>
alpha[<span class="dv">28</span>]   <span class="fl">0.795</span>   <span class="fl">0.583</span>  <span class="op">-</span><span class="fl">0.465</span>   <span class="fl">0.474</span>   <span class="fl">0.838</span>   <span class="fl">1.167</span>   <span class="fl">1.840</span> <span class="fl">1.002</span>  <span class="dv">1800</span>
alpha[<span class="dv">29</span>]   <span class="fl">1.378</span>   <span class="fl">0.654</span>   <span class="fl">0.342</span>   <span class="fl">0.951</span>   <span class="fl">1.266</span>   <span class="fl">1.715</span>   <span class="fl">2.990</span> <span class="fl">1.002</span>  <span class="dv">2300</span>
alpha[<span class="dv">30</span>]   <span class="fl">0.784</span>   <span class="fl">0.587</span>  <span class="op">-</span><span class="fl">0.556</span>   <span class="fl">0.450</span>   <span class="fl">0.839</span>   <span class="fl">1.161</span>   <span class="fl">1.836</span> <span class="fl">1.003</span>   <span class="dv">960</span>
beta       <span class="op">-</span><span class="fl">1.800</span>   <span class="fl">0.286</span>  <span class="op">-</span><span class="fl">2.398</span>  <span class="op">-</span><span class="fl">1.985</span>  <span class="op">-</span><span class="fl">1.786</span>  <span class="op">-</span><span class="fl">1.598</span>  <span class="op">-</span><span class="fl">1.283</span> <span class="fl">1.001</span>  <span class="dv">6000</span>
mu.int      <span class="fl">1.042</span>   <span class="fl">0.267</span>   <span class="fl">0.556</span>   <span class="fl">0.863</span>   <span class="fl">1.030</span>   <span class="fl">1.214</span>   <span class="fl">1.588</span> <span class="fl">1.001</span>  <span class="dv">2800</span>
sigma.int   <span class="fl">0.587</span>   <span class="fl">0.347</span>   <span class="fl">0.055</span>   <span class="fl">0.316</span>   <span class="fl">0.552</span>   <span class="fl">0.822</span>   <span class="fl">1.355</span> <span class="fl">1.022</span>   <span class="dv">200</span>
deviance  <span class="fl">160.978</span>   <span class="fl">6.463</span> <span class="fl">147.431</span> <span class="fl">156.544</span> <span class="fl">161.574</span> <span class="fl">165.831</span> <span class="fl">172.250</span> <span class="fl">1.003</span>   <span class="dv">840</span>

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction <span class="kw">factor</span> (at convergence, <span class="dt">Rhat=</span><span class="dv">1</span>).

DIC <span class="kw">info</span> (using the rule, <span class="dt">pD =</span> <span class="kw">var</span>(deviance)<span class="op">/</span><span class="dv">2</span>)
pD =<span class="st"> </span><span class="fl">20.8</span> and DIC =<span class="st"> </span><span class="fl">181.8</span>
DIC is an estimate of expected predictive <span class="kw">error</span> (lower deviance is better).</code></pre></div>
<p>This output can be a bit daunting because of the <code>alpha</code> overload. Here, we have a unique <code>alpha</code> for each of our initial 30 sites. We have a single <code>beta</code> describing the change in probability of <code>success</code> as a function of <code>conductivity</code>.</p>
<p>If we just want the overall change in probability of success as related to conductivity, then will want to work with our global mean, <code>mu.int</code> for now. For this homework option, I will ask you to pick one of the sites to make predictions using one of the <code>alpha</code> parameters instead of <code>mu.int</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Get the posteriors</span>
posts =<span class="st"> </span>plant_glmm<span class="op">$</span>BUGSoutput<span class="op">$</span>sims.list

<span class="co"># Have a look at them</span>
<span class="kw">names</span>(posts)
[<span class="dv">1</span>] <span class="st">&quot;alpha&quot;</span>     <span class="st">&quot;beta&quot;</span>      <span class="st">&quot;deviance&quot;</span>  <span class="st">&quot;mu.int&quot;</span>    <span class="st">&quot;sigma.int&quot;</span></code></pre></div>
<p>Get the regression coefficients:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Intercept estimates</span>
mu.int &lt;-<span class="st"> </span>posts<span class="op">$</span>mu.int 

<span class="co"># Slope estimates</span>
beta &lt;-<span class="st"> </span>posts<span class="op">$</span>beta </code></pre></div>
<p>Now that we have our coefficient estimates, we can make predictions using our good old friend <span class="math inline">\(y = mx + b\)</span>, or <code>pred = mu.int + beta * scond</code>. We have to step up our coding game a little here to make one prediction for each pair of parameter estimates stored in our posteriors.</p>
<p>We start by making a new sequence of our <code>X</code> variable (<code>conductivity</code>)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make up some new values of our</span>
<span class="co"># standardized covariate (conductivity)</span>
newcond =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, .<span class="dv">5</span>)</code></pre></div>
<p>Now, we will make an empty matrix with the same number of rows as our MCMC samples in <code>alpha</code> and <code>mu.int</code> and a number of columns corresponding to the number of elements in <code>newcond</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make an empty matrix to hold predictions</span>
preds =<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span><span class="kw">length</span>(mu.int), <span class="dt">ncol=</span><span class="kw">length</span>(newcond))</code></pre></div>
<p>Here comes the tricky part. We are going to loop over the rows and columns in the matrix, pulling new values of <code>alpha</code> and <code>mu.int</code> as well as new values of <code>newcond</code> in a nested, sequential way. Note that <code>alpha</code> and <code>mu.int</code> are indexed by <code>i</code> and <code>newcond</code> is indexed by a <code>t</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(preds)){
  <span class="cf">for</span>(t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(preds)){
    preds[i,t] &lt;-<span class="st"> </span>mu.int[i] <span class="op">+</span><span class="st"> </span>beta[i]<span class="op">*</span>newcond[t]
  }
}</code></pre></div>
<p>Now, let’s calculate some summary statistics from the joint posterior prediction. First, we will get the mean and and 95% CRI for probability of <code>success</code> for each new observation of <code>conductivity</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred.mean &lt;-<span class="st"> </span><span class="kw">invlogit</span>(<span class="kw">apply</span>(preds, <span class="dv">2</span>, mean))
pred.lwr &lt;-<span class="st"> </span><span class="kw">invlogit</span>(<span class="kw">apply</span>(preds, <span class="dv">2</span>, quantile, <span class="fl">0.025</span>))
pred.upr &lt;-<span class="st"> </span><span class="kw">invlogit</span>(<span class="kw">apply</span>(preds, <span class="dv">2</span>, quantile, <span class="fl">0.975</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make a quick plot, inverting the logit function for </span>
<span class="co"># predictions on the fly</span>
  <span class="kw">plot</span>(newcond, pred.mean, <span class="dt">type=</span><span class="st">&#39;l&#39;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;white&#39;</span>,
       <span class="dt">xlab =</span> <span class="st">&#39;Standardized conductivity&#39;</span>,
       <span class="dt">ylab =</span> <span class="st">&#39;Probability of successful control&#39;</span>,
       <span class="dt">yaxt =</span> <span class="st">&#39;n&#39;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)
       )
  <span class="kw">axis</span>(<span class="dt">side=</span><span class="dv">2</span>, <span class="dt">las=</span><span class="dv">2</span>)
<span class="co"># Add lower and upper prediction of success by conductivity</span>
<span class="co"># also inverting logit on the fly</span>
  <span class="kw">polygon</span>(<span class="dt">x =</span> <span class="kw">c</span>(newcond, <span class="kw">rev</span>(newcond)), <span class="dt">y =</span> <span class="kw">c</span>(pred.lwr, <span class="kw">rev</span>(pred.upr)),
          <span class="dt">col =</span> <span class="kw">rgb</span>(<span class="fl">0.8</span>, <span class="fl">0.8</span>, <span class="fl">0.8</span>, <span class="fl">0.5</span>), <span class="dt">border =</span> <span class="ot">NA</span>
          )
  <span class="kw">lines</span>(newcond, pred.mean, <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&#39;black&#39;</span>)</code></pre></div>
<p><img src="hw11_glmm_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>Notice here that the variance around our predictions at high values of standardized <code>conductivity</code> is much better estimated than in our REML fit above.</p>
<h3 id="multi">
<b> Your mission </b>
</h3>
<p>For this option, I want you to do the following:</p>

<ol style="list-style-type: decimal">
<li>Using either REML or Bayesian estimation, first run the model out to convergence. Make sure diagnostics idicate that estimates have converged and effective sample size (ESS, or <code>n.eff</code>) is sufficiently large if using Bayesian.</li>
</ol>

<ol start="2" style="list-style-type: decimal">
<li>Make predictions for at least one individual site using one set of <code>alpha</code> estimates from the model. If using REML, you can see an example of how to do this in the walleye phenology homework option.</li>
</ol>

<ol start="3" style="list-style-type: decimal">
<li>Submit a brief writeup describing methods and results.</li>
</ol>
<p><br></p>
</div>
</div>

<!DOCTYPE html>

<br>

<hr>

<p style="color:gray; text-align:center">This work is licensed under a <a href="https://creativecommons.org/licenses/by/4.0/legalcode">Creative Commons Attribution 4.0 International License</a>. Data are provided for educational purposes only unless otherwise noted.</p>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
