<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>03_probabilityDistributions.utf8</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<!DOCTYPE html>
<head>
<!-- Favicon for various operating systems -->
<link rel="apple-touch-icon" sizes="180x180" href="./favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="./favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="./favicon/favicon-16x16.png">
<!-- <link rel="manifest" href="./favicon/site.webmanifest"> -->
<link rel="mask-icon" href="./favicon/safari-pinned-tab.svg" color="#603cba">
<link rel="shortcut icon" href="./favicon/favicon.ico">
<meta name="msapplication-TileColor" content="#603cba">
<meta name="msapplication-config" content="./favicon/browserconfig.xml">
<meta name="theme-color" content="#382121">
</head>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="..\..\styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">BIOL 217</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="content.html">Course content</a>
</li>
<li>
  <a href="software.html">Software needs</a>
</li>
<li>
  <a href="resources.html">Additional Resources</a>
</li>
<li>
  <a href="contact.html">Contact</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/danStich">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="working-with-probability-distributions" class="section level1">
<h1>Working with probability distributions</h1>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-2-1.png" width="480" style="display: block; margin: auto auto auto 0;" /></p>
<h2 id="multi">
Introduction
</h2>
<p>This week we are going to talk about <strong>probability</strong> and <strong>probability distributions</strong> as a backdrop for the models that we will be working with during the next several weeks. Probability theory is central to statistical techniques, so it will be important for you to have a pretty firm understanding of this to grab hold of big ideas later on. If you are successful in understanding these concepts, you will have a working body of knowledge that is comparable, or better developed than many leading professionals in our fields.</p>
<p>When we talk about probability distributions, we are talking about the probability that a <strong>random variable</strong> takes on some <strong>value</strong>. In most cases, there is a higher probability that a variable will take on certain values than others. That probability may be governed by any number of processes and thus may assume a number of different <strong>shapes</strong> with respect to the <strong>likelihood</strong> of any given value of our random variable. The differences in the shapes, and the mathematical <strong>parameters</strong> that we use to describe those shapes are called “probability distributions”.</p>
<p>There was a time when biologists were largely restricted to using models that relied heavily on assumptions of normality in the error structure of random variables because of how computationally intensive other methods were. This often led to the use of strictly <strong>parametric</strong> tools like ANOVA and t-tests, or the use of strictly <strong>non-parametric</strong> tools like frequency analyses and rank- order methods. While these can still be useful techniques in our toolboxes, that time has passed, and now we have access to a wide range of tools that allow us to extend simple parametric and non-parametric tools to explicitly incorporate mechanisms that allow us to relax or change distributional assumptions. We will discuss these throughout the course, but we need to look at the underlying distributions that govern our decisions about which of these tools to use. So, this week we’ll look at specific distributions that correspond to methods that are commonly applied.</p>
<p>We are going to use this tutorial for our discussions about probability and probability distributions throughout the week. Next week, we will use this new information to talk about how we calculate <strong>distributional statistics</strong> from samples and how those can be used for statistical inference before we begin talking about statistical analyses for the remainder of the course. Hopefully the order of things is starting to make some sense now!</p>
<div id="probability-distributions-in-r" class="section level2">
<h2>Probability distributions in R</h2>
<p>R has a number of built-in distribution types, and there are random-number generators associated with most or all of these that will allow us to take random samples from a distribution. This is useful for data simulation, but is also helpful for us to learn about probability distributions and how their parameters affect the <strong>shape</strong>, <strong>spread</strong>, <strong>scale</strong>, <strong>location</strong>, etc. of those distributions. We will briefly discuss concepts like <strong>skew</strong> because of how they can help us think about the assumptions that we are making (or breaking!) in the models that we use.</p>
<p>For this class, we will focus on one major family of distributions and then zero in on a few distributions within this family that you are guaranteed to encounter in analyses throughout your career.</p>
<div id="exponential-family-of-distributions" class="section level3">
<h3>Exponential family of distributions</h3>
<p>Most or all of the distributions we will need for this class come from the <strong>exponential family</strong> of distributions.</p>
<p>The exponential family is very flexible. It includes most of the probability distributions with which you are familiar, and many more. Just ask this <em>very</em> reliable <a href="https://en.wikipedia.org/wiki/Exponential_family">Wikipedia entry</a>. Let’s face it, you were going there anyway, I just cut out the Google step.</p>
<p>Take a look at the table at the bottom of this Wikipedia page just to get an idea of how many distributions are included within the exponential! Holy cow! We’re not going to look at all of these in this class- I just want you to be aware that this is a HUGE family of specific distributions.</p>
<blockquote>
<p>Distributions that we’ll focus on this week:</p>
</blockquote>
<ol style="list-style-type: decimal">
<li>Continuous <br> Normal (Gaussian) <br> Lognormal <br> Beta <br> Uniform <br> <br></li>
<li>Discrete distributions Bernouli <br> Binomial <br> Multinomial <br> Poisson <br> Negative binomial <br></li>
</ol>
</div>
<div id="continuous-probability-distributions" class="section level3">
<h3>Continuous probability distributions</h3>
<blockquote>
<p>The normal distribution</p>
</blockquote>
<p>This is one distribution with which most of you have at least some nodding acquaintance.</p>
<p>The <strong>normal distribution</strong> is defined by two parameters:</p>
<ol style="list-style-type: decimal">
<li><p>The mean (<span class="math inline">\(\mu\)</span>)</p></li>
<li><p>The variance (<span class="math inline">\(\sigma^2\)</span>)</p></li>
</ol>
<p>Let’s take a look at what the normal distribution looks like. We’ll start with the standard normal (or <em>z</em>) distribution. The standard normal is a normal distribution with a mean of zero and a variance of 1.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Plot a density curve as for 10k</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co"># samples from a normal distribution</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co"># as a thick, black line</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="kw">plot</span>(<span class="kw">density</span>(</span>
<span id="cb1-5"><a href="#cb1-5"></a>  <span class="kw">rnorm</span>(<span class="dt">n=</span><span class="fl">1e4</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)),</span>
<span id="cb1-6"><a href="#cb1-6"></a>  <span class="dt">main=</span><span class="st">&#39;&#39;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;black&#39;</span>,</span>
<span id="cb1-7"><a href="#cb1-7"></a>  <span class="dt">xlab=</span><span class="kw">expression</span>(theta), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We can change the parameters of the standard normal to increase or decrease the degree of <strong>kurtosis</strong> or peakedness in our distribution. The blue line in the plot below shows a distribution with lower kurtosis than the z distribution (this one is called a <strong>t-distribution</strong>). The red line shows a distribution with greater kurtosis than the z distribution.</p>
<p>For line drawings like these, we can just add them to the existing plot to keep the same x and y scales and axes by using the <code>lines</code> function:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Add thick, blue line to the</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="co"># plot for mu=0, sigma=2</span></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="kw">lines</span>(<span class="kw">density</span>(</span>
<span id="cb2-4"><a href="#cb2-4"></a>  <span class="kw">rnorm</span>(<span class="dt">n=</span><span class="fl">1e4</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">2</span>)),</span>
<span id="cb2-5"><a href="#cb2-5"></a>  <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb2-6"><a href="#cb2-6"></a></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co"># Add thick, red line to the</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="co"># plot for mu=0, sigma=0.5</span></span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="kw">lines</span>(<span class="kw">density</span>(</span>
<span id="cb2-10"><a href="#cb2-10"></a>  <span class="kw">rnorm</span>(<span class="dt">n=</span><span class="fl">1e4</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span>.<span class="dv">5</span>)),</span>
<span id="cb2-11"><a href="#cb2-11"></a>  <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&#39;red&#39;</span>)  </span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>We can add a legend to clarify:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">legend</span>(<span class="dt">x=</span><span class="dv">1</span>,    <span class="co"># x-coordinate for legend</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>       <span class="dt">y=</span>.<span class="dv">9</span>,   <span class="co"># Y-coordinate for legend</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>       <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&#39;mu=0, sd=1&#39;</span>, <span class="st">&#39;mu=0, sd=2&#39;</span>, <span class="st">&#39;mu=0, sd=.5&#39;</span>), <span class="co"># Names</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>       <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&#39;black&#39;</span>, <span class="st">&#39;blue&#39;</span>, <span class="st">&#39;red&#39;</span>), <span class="co"># Colors</span></span>
<span id="cb3-5"><a href="#cb3-5"></a>       <span class="dt">lty=</span><span class="dv">1</span>,  <span class="co"># Line type for legend symbols</span></span>
<span id="cb3-6"><a href="#cb3-6"></a>       <span class="dt">lwd=</span><span class="dv">2</span>,  <span class="co"># Line width for legend symbols</span></span>
<span id="cb3-7"><a href="#cb3-7"></a>       <span class="dt">bg=</span><span class="st">&#39;n&#39;</span>, <span class="co"># Legend fill: none</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>       <span class="dt">bty=</span><span class="st">&#39;n&#39;</span> <span class="co"># Box type for legend: none</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>) <span class="co"># Close call to legend</span></span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<blockquote>
<p>The lognormal distribution</p>
</blockquote>
<p>The <strong>lognormal distribution</strong> is a probability distribution that assumes our random variable is normally distributed on the <strong>log scale</strong>. This assumption allows us to incorporate <strong>skew</strong> into the normal distribution and change the location and spread of the normal distribution by transforming the parameters (<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>) onto the log scale. This is one of the more common data transformations that you will run into, e.g.: “We log-transformed the data to achieve normality…”</p>
<p>Let’s take a look at how changes to the mean change the location of this distribution:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Plot the density fucntion for a lognormal</span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="co"># distribution that has a mean of zero and</span></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="co"># a standard deviation of 1.</span></span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="kw">plot</span>(<span class="kw">density</span>(</span>
<span id="cb4-5"><a href="#cb4-5"></a>  <span class="kw">rlnorm</span>(<span class="dt">n=</span><span class="fl">1e4</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>)),</span>
<span id="cb4-6"><a href="#cb4-6"></a>  <span class="dt">main=</span><span class="st">&#39;&#39;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;black&#39;</span>, </span>
<span id="cb4-7"><a href="#cb4-7"></a>  <span class="dt">xlab=</span><span class="kw">expression</span>(theta), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb4-8"><a href="#cb4-8"></a></span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="co"># Now, we can change the parameters to change the location and spread</span></span>
<span id="cb4-10"><a href="#cb4-10"></a><span class="kw">lines</span>(<span class="kw">density</span>(</span>
<span id="cb4-11"><a href="#cb4-11"></a>  <span class="kw">rlnorm</span>(<span class="dt">n=</span><span class="fl">1e4</span>, <span class="dt">mean=</span><span class="dv">1</span>, <span class="dt">sd=</span><span class="dv">1</span>)),</span>
<span id="cb4-12"><a href="#cb4-12"></a>  <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&#39;blue&#39;</span>) </span>
<span id="cb4-13"><a href="#cb4-13"></a></span>
<span id="cb4-14"><a href="#cb4-14"></a><span class="kw">lines</span>(<span class="kw">density</span>(</span>
<span id="cb4-15"><a href="#cb4-15"></a>  <span class="kw">rlnorm</span>(<span class="dt">n=</span><span class="fl">1e4</span>, <span class="dt">mean=</span><span class="dv">2</span>, <span class="dt">sd=</span><span class="dv">1</span>)),</span>
<span id="cb4-16"><a href="#cb4-16"></a>  <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&#39;red&#39;</span>)  </span>
<span id="cb4-17"><a href="#cb4-17"></a></span>
<span id="cb4-18"><a href="#cb4-18"></a><span class="co"># Add a legend to the plot</span></span>
<span id="cb4-19"><a href="#cb4-19"></a><span class="kw">legend</span>(<span class="dt">x=</span><span class="dv">20</span>, <span class="dt">y=</span>.<span class="dv">9</span>,</span>
<span id="cb4-20"><a href="#cb4-20"></a>       <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&#39;mu=0, sd=1&#39;</span>, <span class="st">&#39;mu=1, sd=1&#39;</span>, <span class="st">&#39;mu=2, sd=1&#39;</span>), </span>
<span id="cb4-21"><a href="#cb4-21"></a>       <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&#39;black&#39;</span>, <span class="st">&#39;blue&#39;</span>, <span class="st">&#39;red&#39;</span>),</span>
<span id="cb4-22"><a href="#cb4-22"></a>       <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">bg=</span><span class="st">&#39;n&#39;</span>, <span class="dt">bty=</span><span class="st">&#39;n&#39;</span>)</span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<blockquote>
<p>The beta distribution</p>
</blockquote>
<p>The <strong>beta distribution</strong> is a probability distribution that is constrained to the interval (0, 1). But, it is incredibly flexible in its parameterization, and as a result is very useful for stochastic simulation of variables on the probability scale, such as survival.</p>
<p>The parameters of the beta distribution are <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, or commonly <code>a</code> and <code>b</code> or <code>shape 1</code> and <code>shape 2</code>. Within this distribution, <span class="math inline">\(\alpha\)</span> pushes the distribution to the right (toward 1), and <span class="math inline">\(\beta\)</span> pushes the distribution to the left (toward 0). The relative magnitude of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> determine the location, shape, and spread of the probability distribution for our random variable. When <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are equal, and greater than 1, the beta distribution is a t-distribution within the interval (0, 1).</p>
<p>Let’s take a look:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># Within the rbeta function in R,</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="co"># &#39;a&#39; is called &#39;shape1&#39; and &#39;b&#39;</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="co"># is called &#39;shape2&#39;</span></span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="kw">plot</span>(<span class="kw">density</span>(<span class="kw">rbeta</span>(<span class="dt">n=</span><span class="fl">1e4</span>, <span class="dt">shape1=</span><span class="dv">50</span>, <span class="dt">shape2=</span><span class="dv">50</span>)),</span>
<span id="cb5-5"><a href="#cb5-5"></a>     <span class="dt">main=</span><span class="st">&#39;&#39;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;black&#39;</span>,</span>
<span id="cb5-6"><a href="#cb5-6"></a>     <span class="dt">xlab=</span><span class="kw">expression</span>(theta),</span>
<span id="cb5-7"><a href="#cb5-7"></a>     <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">50</span>), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb5-8"><a href="#cb5-8"></a></span>
<span id="cb5-9"><a href="#cb5-9"></a><span class="co"># Now, we can change the parameters</span></span>
<span id="cb5-10"><a href="#cb5-10"></a><span class="co"># to change the location and spread</span></span>
<span id="cb5-11"><a href="#cb5-11"></a><span class="kw">lines</span>(<span class="kw">density</span>(<span class="kw">rbeta</span>(<span class="dt">n=</span><span class="fl">1e4</span>, <span class="dt">shape1=</span><span class="dv">50</span>, <span class="dt">shape2=</span><span class="dv">100</span>)), <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&#39;blue&#39;</span>)      </span>
<span id="cb5-12"><a href="#cb5-12"></a><span class="kw">lines</span>(<span class="kw">density</span>(<span class="kw">rbeta</span>(<span class="dt">n=</span><span class="fl">1e4</span>, <span class="dt">shape1=</span><span class="dv">500</span>, <span class="dt">shape2=</span><span class="dv">250</span>)), <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&#39;red&#39;</span>)  </span>
<span id="cb5-13"><a href="#cb5-13"></a></span>
<span id="cb5-14"><a href="#cb5-14"></a><span class="co"># Add a legend to the plot</span></span>
<span id="cb5-15"><a href="#cb5-15"></a><span class="kw">legend</span>(<span class="dt">x=</span>.<span class="dv">65</span>, <span class="dt">y=</span><span class="dv">50</span>,</span>
<span id="cb5-16"><a href="#cb5-16"></a>       <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&#39;a=50, b=50&#39;</span>, <span class="st">&#39;a=50, b=100&#39;</span>, <span class="st">&#39;a=500, b=250&#39;</span>), </span>
<span id="cb5-17"><a href="#cb5-17"></a>       <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&#39;black&#39;</span>, <span class="st">&#39;blue&#39;</span>, <span class="st">&#39;red&#39;</span>),</span>
<span id="cb5-18"><a href="#cb5-18"></a>       <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">bg=</span><span class="st">&#39;n&#39;</span>, <span class="dt">bty=</span><span class="st">&#39;n&#39;</span>)      </span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="discrete-probability-distributions" class="section level3">
<h3>Discrete probability distributions</h3>
<p><strong>Discrete</strong> probability distributions are useful for situations in which our random variable of interest can only take specific values within the interval of interest. For example, this might include age, counts, pass/fail, or any number of conceivable categories. As a result, these require a slightly different treatment of probability as a discrete, rather than continuous phenomenon.</p>
<blockquote>
<p>The Bernoulli distribution</p>
</blockquote>
<p>The <strong>Bernoulli distribution</strong> is a special case of the binomial distribution with a single trial (see below for clarification). Bernoulli outcomes are those for which the random variable can take on one of two values: a one or a zero. This distribution is useful for visualizing processes such as coin flips, yes/no responses, live/dead endpoints, and a number of other very interesting phenomena. The Bernoulli distribution has a single parameter: the probability of success, but is also governed by sample size: n.</p>
<p>We can simulate data from a Bernoulli distribution in one of two ways in R</p>
<p>The “old-school” way of doing this was to draw from a binomial with a single <strong>trial</strong>. Here we randomly draw a single sample from a binomial with a single trial, and a probability of success of 50%. This can be likened to flipping a fair coin.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">rbinom</span>(<span class="dt">n=</span><span class="dv">1</span>, <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">prob=</span>.<span class="dv">5</span>)</span>
<span id="cb6-2"><a href="#cb6-2"></a>[<span class="dv">1</span>] <span class="dv">0</span></span></code></pre></div>
<p>But now, there is a function in the <code>Rlab</code> package that simplifies this for the specific case of a Bernoulli.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># First, install the necessary package</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="co"># Uncomment to install</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="co"># install.packages(&#39;Rlab&#39;) </span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="kw">library</span>(Rlab)</span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="co"># Now we can take a random</span></span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="co"># sample from a Bernoulli</span></span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="co"># Flip the coin once</span></span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="kw">rbern</span>(<span class="dt">n=</span><span class="dv">1</span>, <span class="dt">prob=</span>.<span class="dv">5</span>)</span>
<span id="cb7-11"><a href="#cb7-11"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb7-12"><a href="#cb7-12"></a></span>
<span id="cb7-13"><a href="#cb7-13"></a><span class="co"># Flip the coin 10 times</span></span>
<span id="cb7-14"><a href="#cb7-14"></a><span class="kw">rbern</span>(<span class="dt">n=</span><span class="dv">10</span>, <span class="dt">prob=</span>.<span class="dv">5</span>)</span>
<span id="cb7-15"><a href="#cb7-15"></a> [<span class="dv">1</span>] <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">1</span> <span class="dv">0</span></span></code></pre></div>
<blockquote>
<p>The binomial distribution</p>
</blockquote>
<p>The <strong>binomial distribution</strong> is pretty similar to the Bernoulli distribution except that it also includes a parameter called <span class="math inline">\(N\)</span> (<code>size</code> in R) which corresponds to a number of trials. In most cases in biology, it will suffice to use the Bernoulli, but for modeling we will want to understand the binomial for things like random stratified designs and nested models that rely on the use of binomial distribution</p>
<p>To sample data from a binomial distribution, we can use <code>rbinom</code>. In this example we tell R that we want 10 samples (<code>n</code>) from a binomial distribution that has 10 trials (<code>size</code>) and a probability of success (<code>prob</code>) of 0.5. This is like having 10 people flip the coin 10 times instead of just one person flipping the coin 100 times.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># Take a random draw of 10 samples</span></span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="co"># from a binomial distribution with 10 trials</span></span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="co"># and probability of success equal to 0.50</span></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="kw">rbinom</span>(<span class="dt">n=</span><span class="dv">10</span>, <span class="dt">size=</span><span class="dv">10</span>, <span class="dt">prob=</span><span class="fl">0.5</span>)</span>
<span id="cb8-5"><a href="#cb8-5"></a> [<span class="dv">1</span>] <span class="dv">5</span> <span class="dv">5</span> <span class="dv">5</span> <span class="dv">4</span> <span class="dv">4</span> <span class="dv">7</span> <span class="dv">4</span> <span class="dv">8</span> <span class="dv">6</span> <span class="dv">6</span></span></code></pre></div>
<blockquote>
<p>The multinomial distribution</p>
</blockquote>
<p>The <strong>multinomial distribution</strong> is a further generalization of the Binomial and Bernoulli distributions. Here, there are one or more possible categorical outcomes, and the probability of each one occuring is specified individually <strong>but all of them must sum to one</strong>. The categories are, in this case, assumed to be a <strong>mutually exclusive</strong> and <strong>exhaustive</strong> set of possible outcomes.</p>
<p>We can use the multinomial distribution to randomly sample from categories (imagine our response variable is a categorical variable, like the names of the students in this class). To do this:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># First, we make a vector of names:</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>name &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;Alex&#39;</span>, <span class="st">&#39;Eleanor&#39;</span>, <span class="st">&#39;Kathleen&#39;</span>, <span class="st">&#39;Madylin&#39;</span>)</span>
<span id="cb9-3"><a href="#cb9-3"></a></span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="co"># Then, we assign a uniform probability of</span></span>
<span id="cb9-5"><a href="#cb9-5"></a><span class="co"># drawing any given name if they can all</span></span>
<span id="cb9-6"><a href="#cb9-6"></a><span class="co"># be drawn with equal frequency:</span></span>
<span id="cb9-7"><a href="#cb9-7"></a>probs &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dt">x=</span><span class="dv">1</span><span class="op">/</span><span class="kw">length</span>(name), <span class="dt">times=</span><span class="kw">length</span>(name))      </span>
<span id="cb9-8"><a href="#cb9-8"></a>probs      </span>
<span id="cb9-9"><a href="#cb9-9"></a>[<span class="dv">1</span>] <span class="fl">0.25</span> <span class="fl">0.25</span> <span class="fl">0.25</span> <span class="fl">0.25</span></span></code></pre></div>
<p>Now, we can sample from a multinomial distribution using our objects. Here we are taking 5 samples from the distribution, each time we sample there is only one trial, and we are sampling the 4 probabilities above.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">rmultinom</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">prob=</span>probs)</span>
<span id="cb10-2"><a href="#cb10-2"></a>     [,<span class="dv">1</span>] [,<span class="dv">2</span>] [,<span class="dv">3</span>] [,<span class="dv">4</span>] [,<span class="dv">5</span>]</span>
<span id="cb10-3"><a href="#cb10-3"></a>[<span class="dv">1</span>,]    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">1</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>[<span class="dv">2</span>,]    <span class="dv">1</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>[<span class="dv">3</span>,]    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">1</span>    <span class="dv">0</span>    <span class="dv">0</span></span>
<span id="cb10-6"><a href="#cb10-6"></a>[<span class="dv">4</span>,]    <span class="dv">0</span>    <span class="dv">1</span>    <span class="dv">0</span>    <span class="dv">1</span>    <span class="dv">0</span></span></code></pre></div>
<p><strong>WHOA</strong> a matrix??!!! HOLY CRAP, WHAT DOES IT ALL MEAN?</p>
<p>Take a step back, breathe, and think about this. The rows in this matrix are you and your classmates. If we took one random sample from the multinomial distribution, it would look like this:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="co"># Take a single sample from</span></span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="co"># the list of student names    </span></span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="kw">rmultinom</span>(<span class="dt">n=</span><span class="dv">1</span>, <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">prob=</span>probs)</span>
<span id="cb11-4"><a href="#cb11-4"></a>     [,<span class="dv">1</span>]</span>
<span id="cb11-5"><a href="#cb11-5"></a>[<span class="dv">1</span>,]    <span class="dv">0</span></span>
<span id="cb11-6"><a href="#cb11-6"></a>[<span class="dv">2</span>,]    <span class="dv">0</span></span>
<span id="cb11-7"><a href="#cb11-7"></a>[<span class="dv">3</span>,]    <span class="dv">0</span></span>
<span id="cb11-8"><a href="#cb11-8"></a>[<span class="dv">4</span>,]    <span class="dv">1</span></span></code></pre></div>
<p>Here, we pulled a single sample from the distribution, and probability of sampling a given individual was 0.25 (1/4). If it makes it easier, we can put your names next to it:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a><span class="kw">cbind</span>(name, <span class="kw">rmultinom</span>(<span class="dt">n=</span><span class="dv">1</span>, <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">prob=</span>probs))</span>
<span id="cb12-2"><a href="#cb12-2"></a>     name          </span>
<span id="cb12-3"><a href="#cb12-3"></a>[<span class="dv">1</span>,] <span class="st">&quot;Alex&quot;</span>     <span class="st">&quot;1&quot;</span></span>
<span id="cb12-4"><a href="#cb12-4"></a>[<span class="dv">2</span>,] <span class="st">&quot;Eleanor&quot;</span>  <span class="st">&quot;0&quot;</span></span>
<span id="cb12-5"><a href="#cb12-5"></a>[<span class="dv">3</span>,] <span class="st">&quot;Kathleen&quot;</span> <span class="st">&quot;0&quot;</span></span>
<span id="cb12-6"><a href="#cb12-6"></a>[<span class="dv">4</span>,] <span class="st">&quot;Madylin&quot;</span>  <span class="st">&quot;0&quot;</span></span></code></pre></div>
<p>Now, if I was calling on you randomly in class, after 10 questions, the spread of people who have participated in class might look like this:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="kw">cbind</span>(name, <span class="kw">rmultinom</span>(<span class="dt">n=</span><span class="dv">10</span>, <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">prob=</span>probs))</span>
<span id="cb13-2"><a href="#cb13-2"></a>     name                                              </span>
<span id="cb13-3"><a href="#cb13-3"></a>[<span class="dv">1</span>,] <span class="st">&quot;Alex&quot;</span>     <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;1&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;1&quot;</span> <span class="st">&quot;1&quot;</span> <span class="st">&quot;0&quot;</span></span>
<span id="cb13-4"><a href="#cb13-4"></a>[<span class="dv">2</span>,] <span class="st">&quot;Eleanor&quot;</span>  <span class="st">&quot;1&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;1&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;1&quot;</span> <span class="st">&quot;1&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;1&quot;</span></span>
<span id="cb13-5"><a href="#cb13-5"></a>[<span class="dv">3</span>,] <span class="st">&quot;Kathleen&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;1&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span></span>
<span id="cb13-6"><a href="#cb13-6"></a>[<span class="dv">4</span>,] <span class="st">&quot;Madylin&quot;</span>  <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;1&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span> <span class="st">&quot;0&quot;</span></span></code></pre></div>
<p>Taking this one step further, we could just draw a name and stop looking at these ugly (no but really they are <strong>awesome</strong>!) matrices:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a>name[<span class="kw">which</span>(<span class="kw">rmultinom</span>(<span class="dt">n=</span><span class="dv">1</span>, <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">prob=</span>probs)<span class="op">&gt;</span><span class="dv">0</span>)]</span>
<span id="cb14-2"><a href="#cb14-2"></a>[<span class="dv">1</span>] <span class="st">&quot;Alex&quot;</span></span></code></pre></div>
<p>And now we have a way to randomly select an individual based on a multinomial distribution!</p>
<blockquote>
<p>The Poisson distribution</p>
</blockquote>
<p>The <strong>Poisson distribution</strong> is used for counts or other integer data. This distribution is widely used (and just as widely misused!) for its ability to account for a large number of biological and ecological processes in the models that we will discuss this semester. The Poisson distribution has a single parameter, <span class="math inline">\(\lambda\)</span>, which is both the mean and the variance of the distribution. So, despite its utility, the distribution is relatively inflexible with respect to shape and spread. <strong>Fun fact</strong>: this distribution was originally worked out by a French mathematician to predict the number of soldiers who were accidentally killed from being kicked by horses.</p>
<p>Take a look at how the distribution changes when you change <span class="math inline">\(\lambda\)</span>, and you will get an idea of how this one works.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="kw">hist</span>(<span class="kw">rpois</span>(<span class="dt">n=</span><span class="fl">1e4</span>, <span class="dt">lambda=</span><span class="dv">100</span>), <span class="dt">main=</span><span class="st">&#39;&#39;</span>)</span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<blockquote>
<p>The negative binomial distribution</p>
</blockquote>
<p>Okay, this one can be a little difficult to wrap your head around but it’s an important one for us to know about. So, we will spend a little extra time setting this one up to try and be clear. Often, folks start out thinking that they’re going to use a Poisson distribution and they end up collecting with data that do not conform to the relative inflexibility of that single-parameter distribution. For the purpose of this class, we are not going to dive into the mechanics of the <strong>negative binomial distribution</strong>, but we do need to know what it looks like and why we might need it.</p>
<p>One useful way to conceptualize the negative binomial is to ask “how long does it take for some event to occur?” For example, we might ask how long it takes a fish to start migrating, how long it takes a sea turtle to recover in a rehabilitation center, how long it will take for a terminal patient to expire, or how frequently we see the expression of a gene of interest. These kinds of questions are asked in aptly named “time-to-event” models that rely on the variance structure of the negative binomial. In the context of these kinds of questions, the negative binomial is a discrete probability distribution (and not a continuous distribution) because the “time” component of the distribution is actually a series of independent Bernoulli trials (holy crap, I know!). For example: if we want to know how many days it will take for a turtle to recover, what we are really doing is asking on each day until recovery, “Is today the day?”. Then, we flip a coin and find out. So, each day in this example is a Bernoulli trial. Another way to think about this is the number of failures occurring in a sequence before a target number of sucesses is achieved.</p>
<p>For the classical parameterization:</p>
<p>We will start with looking at how many failures are observed before one success in a sequence of Bernoulli trials.</p>
<p>With probability of succes equal to 0.95, it doesn’t take long and most of the probability mass is on zero, with a couple of stragglers further out.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a><span class="kw">hist</span>(<span class="kw">rnbinom</span>(<span class="fl">1e4</span>, <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">prob=</span>.<span class="dv">95</span>))</span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>If we decrease probability of success in each trial to 0.25, we see more failures on average before we reach success. Most of the time, it still takes less than 5 trials to reach a success, but some times it takes much longer.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a><span class="kw">hist</span>(<span class="kw">rnbinom</span>(<span class="fl">1e4</span>, <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">prob=</span>.<span class="dv">25</span>))</span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>And, if we increase the number of successes that we use for our criterion, or target, then it spreads the distribution out even further.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a><span class="kw">hist</span>(<span class="kw">rnbinom</span>(<span class="fl">1e4</span>, <span class="dt">size=</span><span class="dv">10</span>, <span class="dt">prob=</span>.<span class="dv">25</span>))        </span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Now, because of it’s properties, the negative binomial is also useful for number of other applications. Specifically, it has been widely used to represent Poisson-like processes in which the mean and variance are not equal (e.g., <strong>overdispersion</strong>). This has seen a lot of application in the field of ecology, especially for overdispersed count data.</p>
<p>Here, we draw 10,000 random samples from a distribution with a mean of 10 and an overdispersion parameter of 1. The overdispersion parameter is called ‘size’ because this is an alternative parameterization that is just making use of the relationships between existing parameters of the negative binomial. It’s easy to grasp how the mean changes the location of the distribution.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a><span class="kw">hist</span>(<span class="kw">rnbinom</span>(<span class="fl">1e4</span>, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">size=</span><span class="dv">1</span>))</span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>But, note how the overdispersion parameter changes things if you run the following code:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a><span class="kw">hist</span>(<span class="kw">rnbinom</span>(<span class="fl">1e4</span>, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">size=</span>.<span class="dv">1</span>))      </span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a><span class="kw">hist</span>(<span class="kw">rnbinom</span>(<span class="fl">1e4</span>, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">size=</span><span class="dv">10</span>))</span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-24-2.png" width="672" /></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a><span class="kw">hist</span>(<span class="kw">rnbinom</span>(<span class="fl">1e4</span>, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">size=</span><span class="dv">100</span>))      </span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-24-3.png" width="672" /></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="kw">hist</span>(<span class="kw">rnbinom</span>(<span class="fl">1e4</span>, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">size=</span><span class="dv">1000</span>))  </span></code></pre></div>
<p><img src="03_probabilityDistributions_files/figure-html/unnamed-chunk-24-4.png" width="672" /></p>
<p>A more intuitive way to work with the negative binomial in R is by using the <code>MASS</code> package. In this parameterization, we use the mean and the dispersion parameter explicitly so it makes more sense:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1"></a><span class="co"># MASS comes pre-installed as part of base software</span></span>
<span id="cb24-2"><a href="#cb24-2"></a><span class="kw">library</span>(MASS)</span>
<span id="cb24-3"><a href="#cb24-3"></a><span class="kw">hist</span>(<span class="kw">rnegbin</span>(<span class="fl">1e4</span>, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta =</span> <span class="fl">.1</span>))  </span>
<span id="cb24-4"><a href="#cb24-4"></a><span class="kw">hist</span>(<span class="kw">rnegbin</span>(<span class="fl">1e4</span>, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta =</span> <span class="dv">10</span>))       </span>
<span id="cb24-5"><a href="#cb24-5"></a><span class="kw">hist</span>(<span class="kw">rnegbin</span>(<span class="fl">1e4</span>, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta =</span> <span class="dv">100</span>))       </span>
<span id="cb24-6"><a href="#cb24-6"></a><span class="kw">hist</span>(<span class="kw">rnegbin</span>(<span class="fl">1e4</span>, <span class="dt">mu=</span><span class="dv">10</span>, <span class="dt">theta =</span> <span class="dv">1000</span>)) </span></code></pre></div>
<p><strong>NOTE</strong> that the results are pretty much identical.</p>
</div>
</div>
<div id="calculating-sample-statistics-and-distributional-parameters-in-r" class="section level2">
<h2>Calculating sample statistics and distributional parameters in R</h2>
<p>In this section, we will learn how to derive the parameters of the <strong>normal distribution</strong> using a few different methods in R. We will use this opportunity to re-introduce the parameters as <strong>moments</strong> of the distribution so we can talk about what we mean by <strong>confidence intervals</strong>. We also will introduce a couple of different methods for calculating moments of a distribution. Specifically, we will look at how to derive…</p>
<div id="moments-about-the-mean" class="section level3">
<h3>Moments about the mean</h3>
<p>Sounds fancy, huh?</p>
<ol style="list-style-type: decimal">
<li>Zeroth moment
<ul>
<li>This is the sum of the total probability of the distribution 1.00, always</li>
</ul></li>
<li>First moment
<ul>
<li>The mean</li>
<li>We will look at a few ways to calculate this</li>
</ul></li>
<li>Second moment
<ul>
<li>The variance</li>
<li>As with the mean, we will examine a couple of options for calculating</li>
</ul></li>
<li>Third moment
<ul>
<li>Skew</li>
<li>We won’t calculate for this class, but we have discussed, and this parameter contributes to the location/spread of the distribution (how far left or right the peak is)</li>
</ul></li>
<li>Fourth moment
<ul>
<li>Kurtosis</li>
<li>Similarly, we won’t cover the calculation, but this is another moment that we have discussed with respect to departure from a z distribution in the normal</li>
</ul></li>
</ol>
</div>
<div id="estimating-parameters-of-the-normal-distribution-from-a-sample" class="section level3">
<h3>Estimating parameters of the normal distribution from a sample</h3>
<p>The tools demonstrated below can be used for most of the probability distributions that have been implemented in R, and we could go on and on forever about them. But, for the sake of our collective sanity we will walk through the tools available using the normal distribution alone, <em>although I encourage you to explore others as applicable to the work that you are doing!</em></p>
<blockquote>
<p>Method of moments estimator</p>
</blockquote>
<p>See if you can rearrange this in a way that makes sense with how you know to calculate a <strong>mean</strong> and a <strong>variance</strong>!</p>
<p>First, we’ll estimate it by making our own function:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># Make up a vector of data to test this on</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>test_norm =<span class="st"> </span><span class="kw">rnorm</span>(<span class="fl">1e3</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb25-3"><a href="#cb25-3"></a>  </span>
<span id="cb25-4"><a href="#cb25-4"></a><span class="co"># Write the function</span></span>
<span id="cb25-5"><a href="#cb25-5"></a><span class="co"># First, define a function by name</span></span>
<span id="cb25-6"><a href="#cb25-6"></a>norm.mom =<span class="st"> </span><span class="cf">function</span>(x){      </span>
<span id="cb25-7"><a href="#cb25-7"></a>  <span class="co"># Calculate mean</span></span>
<span id="cb25-8"><a href="#cb25-8"></a>  x_bar =<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="kw">length</span>(x)) <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(x) </span>
<span id="cb25-9"><a href="#cb25-9"></a>  <span class="co"># Calculate variance</span></span>
<span id="cb25-10"><a href="#cb25-10"></a>  sigma2 =<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="kw">length</span>(x)) <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>((x<span class="op">-</span>x_bar)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb25-11"><a href="#cb25-11"></a>  <span class="co"># Return the calculations</span></span>
<span id="cb25-12"><a href="#cb25-12"></a>  <span class="kw">return</span>(<span class="kw">c</span>(x_bar, sigma2))                  </span>
<span id="cb25-13"><a href="#cb25-13"></a>}</span>
<span id="cb25-14"><a href="#cb25-14"></a><span class="co"># Test the function</span></span>
<span id="cb25-15"><a href="#cb25-15"></a><span class="kw">norm.mom</span>(test_norm)</span>
<span id="cb25-16"><a href="#cb25-16"></a>[<span class="dv">1</span>] <span class="fl">-0.02141993</span>  <span class="fl">1.04956963</span></span></code></pre></div>
<p>Because this one is so common, R has built-in estimators that rely on the exact solution provided by the formulas for the first two moments of the normal distribution:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a><span class="kw">mean</span>(test_norm)</span>
<span id="cb26-2"><a href="#cb26-2"></a>[<span class="dv">1</span>] <span class="fl">-0.02141993</span></span>
<span id="cb26-3"><a href="#cb26-3"></a><span class="kw">var</span>(test_norm)</span>
<span id="cb26-4"><a href="#cb26-4"></a>[<span class="dv">1</span>] <span class="fl">1.05062</span></span></code></pre></div>
<p>How do these compare to the answers returned by our function?</p>
<blockquote>
<p>Maximum likelihood estimator</p>
</blockquote>
<p>R also has built-in <strong>maximum likelihood</strong> estimators that provide an exact solution to the first two moments of the normal distribution.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a><span class="kw">library</span>(MASS)</span>
<span id="cb27-2"><a href="#cb27-2"></a><span class="kw">fitdistr</span>(test_norm, <span class="st">&#39;normal&#39;</span>)</span>
<span id="cb27-3"><a href="#cb27-3"></a>      mean           sd     </span>
<span id="cb27-4"><a href="#cb27-4"></a>  <span class="fl">-0.02141993</span>    <span class="fl">1.02448506</span> </span>
<span id="cb27-5"><a href="#cb27-5"></a> ( <span class="fl">0.03239706</span>) ( <span class="fl">0.02290818</span>)</span></code></pre></div>
<p>Only one problem here: R doesn’t report the second moment! It reports the square root of the second moment: the <strong>standard deviation</strong>!</p>
<p>Finally, let’s write our own function and maximize the likelihood with the <code>optim()</code> function in R.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># Define the function</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>normal.lik =<span class="st"> </span><span class="cf">function</span>(theta, y){</span>
<span id="cb28-3"><a href="#cb28-3"></a>  <span class="co"># The starting value for</span></span>
<span id="cb28-4"><a href="#cb28-4"></a>  <span class="co"># mu that we provide</span></span>
<span id="cb28-5"><a href="#cb28-5"></a>  mu =<span class="st"> </span>theta[<span class="dv">1</span>]</span>
<span id="cb28-6"><a href="#cb28-6"></a>  <span class="co"># The starting value for</span></span>
<span id="cb28-7"><a href="#cb28-7"></a>  <span class="co"># sigma2 that we provide</span></span>
<span id="cb28-8"><a href="#cb28-8"></a>  sigma2 =<span class="st"> </span>theta[<span class="dv">2</span>]</span>
<span id="cb28-9"><a href="#cb28-9"></a>  <span class="co"># Number of observations in the data</span></span>
<span id="cb28-10"><a href="#cb28-10"></a>  n =<span class="st"> </span><span class="kw">nrow</span>(y)</span>
<span id="cb28-11"><a href="#cb28-11"></a>  <span class="co"># Compute the log likelihood of the</span></span>
<span id="cb28-12"><a href="#cb28-12"></a>  <span class="co"># data (y) using the likelihood</span></span>
<span id="cb28-13"><a href="#cb28-13"></a>  <span class="co"># function for the normal distribution</span></span>
<span id="cb28-14"><a href="#cb28-14"></a>  <span class="co"># given the starting values for our</span></span>
<span id="cb28-15"><a href="#cb28-15"></a>  <span class="co"># parameters (contained in the vector &#39;theta&#39;)</span></span>
<span id="cb28-16"><a href="#cb28-16"></a>  logl =<span class="st"> </span><span class="fl">-.5</span><span class="op">*</span>n<span class="op">*</span><span class="kw">log</span>(<span class="dv">2</span><span class="op">*</span>pi) <span class="fl">-.5</span><span class="op">*</span>n<span class="op">*</span><span class="kw">log</span>(sigma2)<span class="op">-</span>(<span class="dv">1</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>sigma2))<span class="op">*</span><span class="kw">sum</span>((y<span class="op">-</span>mu)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb28-17"><a href="#cb28-17"></a>  <span class="kw">return</span>(<span class="op">-</span>logl)</span>
<span id="cb28-18"><a href="#cb28-18"></a>}</span></code></pre></div>
<p>Now, we use the <code>optim</code> function to maximize the likelihood of the data (technically by minimizing the -log likehood) given different values of our parameters (<code>mu</code> and <code>sigma2</code>).</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a><span class="kw">optim</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), normal.lik, <span class="dt">y=</span><span class="kw">data.frame</span>(test_norm))</span>
<span id="cb29-2"><a href="#cb29-2"></a><span class="op">$</span>par</span>
<span id="cb29-3"><a href="#cb29-3"></a>[<span class="dv">1</span>] <span class="fl">-0.02135358</span>  <span class="fl">1.04946323</span></span>
<span id="cb29-4"><a href="#cb29-4"></a></span>
<span id="cb29-5"><a href="#cb29-5"></a><span class="op">$</span>value</span>
<span id="cb29-6"><a href="#cb29-6"></a>[<span class="dv">1</span>] <span class="fl">1443.129</span></span>
<span id="cb29-7"><a href="#cb29-7"></a></span>
<span id="cb29-8"><a href="#cb29-8"></a><span class="op">$</span>counts</span>
<span id="cb29-9"><a href="#cb29-9"></a><span class="cf">function</span> gradient </span>
<span id="cb29-10"><a href="#cb29-10"></a>      <span class="dv">39</span>       <span class="ot">NA</span> </span>
<span id="cb29-11"><a href="#cb29-11"></a></span>
<span id="cb29-12"><a href="#cb29-12"></a><span class="op">$</span>convergence</span>
<span id="cb29-13"><a href="#cb29-13"></a>[<span class="dv">1</span>] <span class="dv">0</span></span>
<span id="cb29-14"><a href="#cb29-14"></a></span>
<span id="cb29-15"><a href="#cb29-15"></a><span class="op">$</span>message</span>
<span id="cb29-16"><a href="#cb29-16"></a><span class="ot">NULL</span></span></code></pre></div>
<p>We can also make this into an object and call the parts by name:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1"></a><span class="co"># Make it into an object</span></span>
<span id="cb30-2"><a href="#cb30-2"></a>est =<span class="st"> </span><span class="kw">optim</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb30-3"><a href="#cb30-3"></a>            normal.lik,</span>
<span id="cb30-4"><a href="#cb30-4"></a>            <span class="dt">y=</span><span class="kw">data.frame</span>(test_norm)</span>
<span id="cb30-5"><a href="#cb30-5"></a>            ) </span>
<span id="cb30-6"><a href="#cb30-6"></a></span>
<span id="cb30-7"><a href="#cb30-7"></a><span class="co"># Look at the structure </span></span>
<span id="cb30-8"><a href="#cb30-8"></a><span class="co"># I&#39;ll be damned, it&#39;s a list!</span></span>
<span id="cb30-9"><a href="#cb30-9"></a><span class="co"># Hey, we learned about those!</span></span>
<span id="cb30-10"><a href="#cb30-10"></a><span class="kw">str</span>(est)   </span>
<span id="cb30-11"><a href="#cb30-11"></a>List of <span class="dv">5</span></span>
<span id="cb30-12"><a href="#cb30-12"></a> <span class="op">$</span><span class="st"> </span>par        <span class="op">:</span><span class="st"> </span>num [<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="fl">-0.0214</span> <span class="fl">1.0495</span></span>
<span id="cb30-13"><a href="#cb30-13"></a> <span class="op">$</span><span class="st"> </span>value      <span class="op">:</span><span class="st"> </span>num <span class="dv">1443</span></span>
<span id="cb30-14"><a href="#cb30-14"></a> <span class="op">$</span><span class="st"> </span>counts     <span class="op">:</span><span class="st"> </span>Named int [<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="dv">39</span> <span class="ot">NA</span></span>
<span id="cb30-15"><a href="#cb30-15"></a>  ..<span class="op">-</span><span class="st"> </span><span class="kw">attr</span>(<span class="op">*</span>, <span class="st">&quot;names&quot;</span>)=<span class="st"> </span>chr [<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="st">&quot;function&quot;</span> <span class="st">&quot;gradient&quot;</span></span>
<span id="cb30-16"><a href="#cb30-16"></a> <span class="op">$</span><span class="st"> </span>convergence<span class="op">:</span><span class="st"> </span>int <span class="dv">0</span></span>
<span id="cb30-17"><a href="#cb30-17"></a> <span class="op">$</span><span class="st"> </span>message    <span class="op">:</span><span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb30-18"><a href="#cb30-18"></a></span>
<span id="cb30-19"><a href="#cb30-19"></a><span class="co"># Here are the estimates    </span></span>
<span id="cb30-20"><a href="#cb30-20"></a>est<span class="op">$</span>par </span>
<span id="cb30-21"><a href="#cb30-21"></a>[<span class="dv">1</span>] <span class="fl">-0.02135358</span>  <span class="fl">1.04946323</span></span>
<span id="cb30-22"><a href="#cb30-22"></a>  </span>
<span id="cb30-23"><a href="#cb30-23"></a><span class="co"># The mean  </span></span>
<span id="cb30-24"><a href="#cb30-24"></a>est<span class="op">$</span>par[<span class="dv">1</span>]</span>
<span id="cb30-25"><a href="#cb30-25"></a>[<span class="dv">1</span>] <span class="fl">-0.02135358</span></span>
<span id="cb30-26"><a href="#cb30-26"></a></span>
<span id="cb30-27"><a href="#cb30-27"></a><span class="co"># The variance  </span></span>
<span id="cb30-28"><a href="#cb30-28"></a>est<span class="op">$</span>par[<span class="dv">2</span>] </span>
<span id="cb30-29"><a href="#cb30-29"></a>[<span class="dv">1</span>] <span class="fl">1.049463</span></span></code></pre></div>
<p>That’s better: an exact solution!</p>
<p>Just in case you’d like to know exactly what <code>optim</code> is doing, you can find out like this:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1"></a>?optim</span></code></pre></div>
<blockquote>
<p>Quantiles and other descriptive statistics</p>
</blockquote>
<p>There are a number of other ways we might like to describe this this (or any) sampling distribution. Here are a few examples that we will work with this semester.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1"></a><span class="co"># Here is the median, or 50th percentile</span></span>
<span id="cb32-2"><a href="#cb32-2"></a><span class="kw">median</span>(test_norm) </span>
<span id="cb32-3"><a href="#cb32-3"></a>[<span class="dv">1</span>] <span class="fl">-0.01478225</span></span>
<span id="cb32-4"><a href="#cb32-4"></a></span>
<span id="cb32-5"><a href="#cb32-5"></a><span class="co"># The 95% confidence limits</span></span>
<span id="cb32-6"><a href="#cb32-6"></a><span class="kw">quantile</span>(test_norm, <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>)) </span>
<span id="cb32-7"><a href="#cb32-7"></a>     <span class="fl">2.5</span><span class="op">%     97.5%</span><span class="st"> </span></span>
<span id="cb32-8"><a href="#cb32-8"></a><span class="fl">-1.951779</span>  <span class="fl">1.993428</span> </span>
<span id="cb32-9"><a href="#cb32-9"></a></span>
<span id="cb32-10"><a href="#cb32-10"></a><span class="co"># Inner quartile range</span></span>
<span id="cb32-11"><a href="#cb32-11"></a><span class="kw">quantile</span>(test_norm, <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.75</span>))    </span>
<span id="cb32-12"><a href="#cb32-12"></a>       <span class="dv">25</span><span class="op">%        75%</span><span class="st"> </span></span>
<span id="cb32-13"><a href="#cb32-13"></a><span class="fl">-0.7221435</span>  <span class="fl">0.6139927</span> </span>
<span id="cb32-14"><a href="#cb32-14"></a></span>
<span id="cb32-15"><a href="#cb32-15"></a><span class="co"># Range of sample</span></span>
<span id="cb32-16"><a href="#cb32-16"></a><span class="kw">range</span>(test_norm)                             </span>
<span id="cb32-17"><a href="#cb32-17"></a>[<span class="dv">1</span>] <span class="fl">-3.297170</span>  <span class="fl">3.287247</span></span></code></pre></div>
</div>
</div>
</div>

<!DOCTYPE html>

<br>

<hr>

<p style="color:gray; text-align:center">This work is licensed under a <a href="https://creativecommons.org/licenses/by/4.0/legalcode">Creative Commons Attribution 4.0 International License</a>. Data are provided for educational purposes only unless otherwise noted.</p>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
