<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>12_cart.utf8.md</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<!DOCTYPE html>
<head>
<!-- Favicon for various operating systems -->
<link rel="apple-touch-icon" sizes="180x180" href="./favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="./favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="./favicon/favicon-16x16.png">
<!-- <link rel="manifest" href="./favicon/site.webmanifest"> -->
<link rel="mask-icon" href="./favicon/safari-pinned-tab.svg" color="#603cba">
<link rel="shortcut icon" href="./favicon/favicon.ico">
<meta name="msapplication-TileColor" content="#603cba">
<meta name="msapplication-config" content="./favicon/browserconfig.xml">
<meta name="theme-color" content="#382121">
</head>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="..\..\styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">BIOL 217</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Teaching
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../../teaching.html">Teaching home</a>
    </li>
    <li>
      <a href="../../classes/BIOL217/index.html">BIOL 217</a>
    </li>
    <li>
      <a href="../../classes/BIOL678/index.html">BIOL 678</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../research.html">Research</a>
</li>
<li>
  <a href="../../studentProjects.html">Current Students</a>
</li>
<li>
  <a href="../../publications.html">Publications</a>
</li>
<li>
  <a href="../../cv.html">CV</a>
</li>
<li>
  <a href="../../contact.html">Contact</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/danStich">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<h1 id="multi">
Classification and regression trees (CART)
</h1>
<p><img src="../../images/water.jpg" alt=""></p>
<h2 id="multi">
Introduction
</h2>
<p>This week we will explore machine learning techniques for understanding biological and ecological data sets. We are moving on to a set of techniques known broadly as decision trees. Within this class of models, we will focus our discussion on a group of predictive tools known as “classification and regression trees” or <strong>CART</strong>. CART relies on ‘recursive partitioning’ to identify patterns in the variance of response variables with respect to explanatory variables of interest. If the response is categorical, then we use <strong>classification trees</strong>. If it is numeric, then we call them <strong>regression trees</strong>. Relatively recent work has led to the development of tools that also handle multiple responses: multivariate decision trees.</p>
<p>In a way, CART can be thought of as a tool that is complementary to some of the tools that we have already talked about this semester. We can look at differences between groups and distributions like many tools we discussed, but now we are flipping the process on its head. Instead of looking for differences in a response between a priori groups that we have defined as experimental treatments or presumably different biological populations, we will be using computer algorithms to search for unknown statistical populations within the structure of our response of interest with respect to our explanatory variables. Sometimes these are populations that we assume exist ahead of time, but very often they are populations that would be hidden from detection through the use of other quantitative tools.</p>
<div id="the-basics-of-cart-go-something-like-this" class="section level4">
<h4>The <strong>basics of CART</strong> go something like this:</h4>
<p>We partition the response into the two most homogenous groups possible based on our explanatory variables (predictors). If categorical, this means splitting into two categories. In the case of a binomial predictor, we end up with two groups- each containg only a single category. In the case of a multinomial predictor with k categories, we still end up with two groups, but each side of the partition might contain anywhere from 1 to K-1 groups. If the predictor is numeric, then we use a rank-order to determine at which rank the distributions of two groups are most homogeneous. (This is the same concept that we used when we looked at non-parametric alternatives to t-tests and ANOVA back in the first couple weeks of the semester.) This initial split is found by maximizing homogeneity within groups in the partition based on all all possible splits for each of the explanatory variables.</p>
<p>Once we have made the first split, we continue to repeat the process over and over again until the tree becomes sufficiently large that we have over-fit the model. This process is called ‘growing’ the tree. We can then use some form of k-fold cross validation to ‘prune’ the tree back based on the predictive performance of the model.</p>
<p>For those looking for a little more (but not too much) depth and a big-picture overview of some of the math, you can find a nice worked example with some easy-to-understand diagrams <a href="http://stats.stackexchange.com/questions/44382/mathematics-behind-classification-and-regression-trees">in this thread from Stack Overflow</a>.</p>
</div>
<div id="classification-trees" class="section level2">
<h2>Classification trees</h2>
<p>We will work with the <code>iris</code> data for this example. The response in the <code>iris</code> data is a categorical variable with no particular order, <code>Species</code>. Because of this, the class of decision trees that we will be working with for the data is classification trees. In this case, our categorical variable has three levels (<code>setosa</code>, <code>versicolor</code>, and <code>virginica</code>), so we know that the initial split will include one branch that contains only one species and one branch that includes two species. The rest of our tree will be grown based on this initial structure, regardless of the variable that is used for the initial split.</p>
<p>First, let’s load the library and the data set that we will need to use for this example. We’ll start with the <code>rpart</code> package, but there are actually a few different packages that will do CART for us. Last, we set a seed for the random number generators in R so we all get the same results.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1">  <span class="kw">library</span>(rpart)</a>
<a class="sourceLine" id="cb1-2" title="2"></a>
<a class="sourceLine" id="cb1-3" title="3"><span class="co"># Load the iris data that we&#39;ve been working with</span></a>
<a class="sourceLine" id="cb1-4" title="4">  <span class="kw">data</span>(iris)</a>
<a class="sourceLine" id="cb1-5" title="5"></a>
<a class="sourceLine" id="cb1-6" title="6"><span class="co"># Set the random number seed so that the results</span></a>
<a class="sourceLine" id="cb1-7" title="7"><span class="co"># are the same each time we run the example (if we</span></a>
<a class="sourceLine" id="cb1-8" title="8"><span class="co"># didn&#39;t set this the results might differ a bit each time</span></a>
<a class="sourceLine" id="cb1-9" title="9"><span class="co"># because the subsampling process below is stochastic)</span></a>
<a class="sourceLine" id="cb1-10" title="10">  <span class="kw">set.seed</span>(<span class="dv">2568</span>)</a></code></pre></div>
<p>Next, we will split our data into <strong>training data</strong> that we use to fit the model, and <strong>test data</strong> we use to validate the model. To do this, we will randomly select rows from our dataframe and assign them to the training data. All unsampled rows will be assigned to the test data set.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="co"># Define a variable to subsample rows of the</span></a>
<a class="sourceLine" id="cb2-2" title="2"><span class="co"># iris dataframe</span></a>
<a class="sourceLine" id="cb2-3" title="3">  n =<span class="st"> </span><span class="kw">nrow</span>(iris)</a>
<a class="sourceLine" id="cb2-4" title="4"></a>
<a class="sourceLine" id="cb2-5" title="5"><span class="co"># Define a random subsample of the original data.</span></a>
<a class="sourceLine" id="cb2-6" title="6"><span class="co"># We will use these data as a training data set,</span></a>
<a class="sourceLine" id="cb2-7" title="7"><span class="co"># that we will then use to fit the model. The object</span></a>
<a class="sourceLine" id="cb2-8" title="8"><span class="co"># `train` is just a random sample of row numbers from</span></a>
<a class="sourceLine" id="cb2-9" title="9"><span class="co"># the total number of rows ini the iris data.</span></a>
<a class="sourceLine" id="cb2-10" title="10"><span class="co"># Here, we take half the data</span></a>
<a class="sourceLine" id="cb2-11" title="11">  train =<span class="st"> </span><span class="kw">sort</span>(<span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span>n, <span class="kw">floor</span>(n<span class="op">/</span><span class="dv">2</span>)))</a>
<a class="sourceLine" id="cb2-12" title="12"></a>
<a class="sourceLine" id="cb2-13" title="13"><span class="co"># We can define separate data frames for the training</span></a>
<a class="sourceLine" id="cb2-14" title="14"><span class="co"># data and the test data using the indices contained</span></a>
<a class="sourceLine" id="cb2-15" title="15"><span class="co"># in `train`.</span></a>
<a class="sourceLine" id="cb2-16" title="16">  </a>
<a class="sourceLine" id="cb2-17" title="17"><span class="co"># Training data</span></a>
<a class="sourceLine" id="cb2-18" title="18">  iris.train =<span class="st"> </span>iris[train, ]</a>
<a class="sourceLine" id="cb2-19" title="19">  </a>
<a class="sourceLine" id="cb2-20" title="20"><span class="co"># Test data</span></a>
<a class="sourceLine" id="cb2-21" title="21">  iris.test =<span class="st"> </span>iris[<span class="op">-</span>train, ]</a></code></pre></div>
<p>Then, we can fit the classification tree to the training data.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1"><span class="co"># Fit the tree</span></a>
<a class="sourceLine" id="cb3-2" title="2">  iris.ct =<span class="st"> </span><span class="kw">rpart</span>(Species <span class="op">~</span><span class="st"> </span>. ,       <span class="co"># Formula: &#39;.&#39; means entire dataframe</span></a>
<a class="sourceLine" id="cb3-3" title="3">                  <span class="dt">data =</span> iris,        <span class="co"># Using iris data</span></a>
<a class="sourceLine" id="cb3-4" title="4">                  <span class="dt">subset =</span> train      <span class="co"># More specifically, the training data</span></a>
<a class="sourceLine" id="cb3-5" title="5">                  )</a></code></pre></div>
<p>We can print a summary of the tree to examine where the splits occurred and how these locations were chosen by the algorithm.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1"><span class="co"># Print the summary</span></a>
<a class="sourceLine" id="cb4-2" title="2">  <span class="kw">summary</span>(iris.ct)</a>
<a class="sourceLine" id="cb4-3" title="3">Call<span class="op">:</span></a>
<a class="sourceLine" id="cb4-4" title="4"><span class="kw">rpart</span>(<span class="dt">formula =</span> Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris, <span class="dt">subset =</span> train)</a>
<a class="sourceLine" id="cb4-5" title="5">  n=<span class="st"> </span><span class="dv">75</span> </a>
<a class="sourceLine" id="cb4-6" title="6"></a>
<a class="sourceLine" id="cb4-7" title="7">         CP nsplit  rel error     xerror       xstd</a>
<a class="sourceLine" id="cb4-8" title="8"><span class="dv">1</span> <span class="fl">0.5217391</span>      <span class="dv">0</span> <span class="fl">1.00000000</span> <span class="fl">1.00000000</span> <span class="fl">0.09168313</span></a>
<a class="sourceLine" id="cb4-9" title="9"><span class="dv">2</span> <span class="fl">0.4565217</span>      <span class="dv">1</span> <span class="fl">0.47826087</span> <span class="fl">0.54347826</span> <span class="fl">0.08874963</span></a>
<a class="sourceLine" id="cb4-10" title="10"><span class="dv">3</span> <span class="fl">0.0100000</span>      <span class="dv">2</span> <span class="fl">0.02173913</span> <span class="fl">0.04347826</span> <span class="fl">0.03033109</span></a>
<a class="sourceLine" id="cb4-11" title="11"></a>
<a class="sourceLine" id="cb4-12" title="12">Variable importance</a>
<a class="sourceLine" id="cb4-13" title="13">Petal.Length  Petal.Width Sepal.Length  Sepal.Width </a>
<a class="sourceLine" id="cb4-14" title="14">          <span class="dv">33</span>           <span class="dv">31</span>           <span class="dv">21</span>           <span class="dv">14</span> </a>
<a class="sourceLine" id="cb4-15" title="15"></a>
<a class="sourceLine" id="cb4-16" title="16">Node number <span class="dv">1</span><span class="op">:</span><span class="st"> </span><span class="dv">75</span> observations,    complexity param=<span class="fl">0.5217391</span></a>
<a class="sourceLine" id="cb4-17" title="17">  predicted class=setosa      expected loss=<span class="fl">0.6133333</span>  <span class="kw">P</span>(node) =<span class="dv">1</span></a>
<a class="sourceLine" id="cb4-18" title="18">    class counts<span class="op">:</span><span class="st">    </span><span class="dv">29</span>    <span class="dv">22</span>    <span class="dv">24</span></a>
<a class="sourceLine" id="cb4-19" title="19">   probabilities<span class="op">:</span><span class="st"> </span><span class="fl">0.387</span> <span class="fl">0.293</span> <span class="fl">0.320</span> </a>
<a class="sourceLine" id="cb4-20" title="20">  left son=<span class="dv">2</span> (<span class="dv">29</span> obs) right son=<span class="dv">3</span> (<span class="dv">46</span> obs)</a>
<a class="sourceLine" id="cb4-21" title="21">  Primary splits<span class="op">:</span></a>
<a class="sourceLine" id="cb4-22" title="22"><span class="st">      </span>Petal.Length <span class="op">&lt;</span><span class="st"> </span><span class="fl">2.6</span>  to the left,  improve=<span class="fl">26.69681</span>, (<span class="dv">0</span> missing)</a>
<a class="sourceLine" id="cb4-23" title="23">      Petal.Width  <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.8</span>  to the left,  improve=<span class="fl">26.69681</span>, (<span class="dv">0</span> missing)</a>
<a class="sourceLine" id="cb4-24" title="24">      Sepal.Length <span class="op">&lt;</span><span class="st"> </span><span class="fl">5.45</span> to the left,  improve=<span class="fl">18.52740</span>, (<span class="dv">0</span> missing)</a>
<a class="sourceLine" id="cb4-25" title="25">      Sepal.Width  <span class="op">&lt;</span><span class="st"> </span><span class="fl">3.35</span> to the right, improve=<span class="fl">10.62932</span>, (<span class="dv">0</span> missing)</a>
<a class="sourceLine" id="cb4-26" title="26">  Surrogate splits<span class="op">:</span></a>
<a class="sourceLine" id="cb4-27" title="27"><span class="st">      </span>Petal.Width  <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.8</span>  to the left,  agree=<span class="fl">1.000</span>, adj=<span class="fl">1.000</span>, (<span class="dv">0</span> split)</a>
<a class="sourceLine" id="cb4-28" title="28">      Sepal.Length <span class="op">&lt;</span><span class="st"> </span><span class="fl">5.45</span> to the left,  agree=<span class="fl">0.920</span>, adj=<span class="fl">0.793</span>, (<span class="dv">0</span> split)</a>
<a class="sourceLine" id="cb4-29" title="29">      Sepal.Width  <span class="op">&lt;</span><span class="st"> </span><span class="fl">3.35</span> to the right, agree=<span class="fl">0.827</span>, adj=<span class="fl">0.552</span>, (<span class="dv">0</span> split)</a>
<a class="sourceLine" id="cb4-30" title="30"></a>
<a class="sourceLine" id="cb4-31" title="31">Node number <span class="dv">2</span><span class="op">:</span><span class="st"> </span><span class="dv">29</span> observations</a>
<a class="sourceLine" id="cb4-32" title="32">  predicted class=setosa      expected loss=<span class="dv">0</span>  <span class="kw">P</span>(node) =<span class="fl">0.3866667</span></a>
<a class="sourceLine" id="cb4-33" title="33">    class counts<span class="op">:</span><span class="st">    </span><span class="dv">29</span>     <span class="dv">0</span>     <span class="dv">0</span></a>
<a class="sourceLine" id="cb4-34" title="34">   probabilities<span class="op">:</span><span class="st"> </span><span class="fl">1.000</span> <span class="fl">0.000</span> <span class="fl">0.000</span> </a>
<a class="sourceLine" id="cb4-35" title="35"></a>
<a class="sourceLine" id="cb4-36" title="36">Node number <span class="dv">3</span><span class="op">:</span><span class="st"> </span><span class="dv">46</span> observations,    complexity param=<span class="fl">0.4565217</span></a>
<a class="sourceLine" id="cb4-37" title="37">  predicted class=virginica   expected loss=<span class="fl">0.4782609</span>  <span class="kw">P</span>(node) =<span class="fl">0.6133333</span></a>
<a class="sourceLine" id="cb4-38" title="38">    class counts<span class="op">:</span><span class="st">     </span><span class="dv">0</span>    <span class="dv">22</span>    <span class="dv">24</span></a>
<a class="sourceLine" id="cb4-39" title="39">   probabilities<span class="op">:</span><span class="st"> </span><span class="fl">0.000</span> <span class="fl">0.478</span> <span class="fl">0.522</span> </a>
<a class="sourceLine" id="cb4-40" title="40">  left son=<span class="dv">6</span> (<span class="dv">23</span> obs) right son=<span class="dv">7</span> (<span class="dv">23</span> obs)</a>
<a class="sourceLine" id="cb4-41" title="41">  Primary splits<span class="op">:</span></a>
<a class="sourceLine" id="cb4-42" title="42"><span class="st">      </span>Petal.Length <span class="op">&lt;</span><span class="st"> </span><span class="fl">4.75</span> to the left,  improve=<span class="fl">21.04348</span>, (<span class="dv">0</span> missing)</a>
<a class="sourceLine" id="cb4-43" title="43">      Petal.Width  <span class="op">&lt;</span><span class="st"> </span><span class="fl">1.65</span> to the left,  improve=<span class="fl">19.28986</span>, (<span class="dv">0</span> missing)</a>
<a class="sourceLine" id="cb4-44" title="44">      Sepal.Length <span class="op">&lt;</span><span class="st"> </span><span class="fl">6.65</span> to the left,  improve=<span class="st"> </span><span class="fl">4.52795</span>, (<span class="dv">0</span> missing)</a>
<a class="sourceLine" id="cb4-45" title="45">      Sepal.Width  <span class="op">&lt;</span><span class="st"> </span><span class="fl">2.95</span> to the left,  improve=<span class="st"> </span><span class="fl">1.53176</span>, (<span class="dv">0</span> missing)</a>
<a class="sourceLine" id="cb4-46" title="46">  Surrogate splits<span class="op">:</span></a>
<a class="sourceLine" id="cb4-47" title="47"><span class="st">      </span>Petal.Width  <span class="op">&lt;</span><span class="st"> </span><span class="fl">1.75</span> to the left,  agree=<span class="fl">0.957</span>, adj=<span class="fl">0.913</span>, (<span class="dv">0</span> split)</a>
<a class="sourceLine" id="cb4-48" title="48">      Sepal.Length <span class="op">&lt;</span><span class="st"> </span><span class="fl">6.35</span> to the left,  agree=<span class="fl">0.739</span>, adj=<span class="fl">0.478</span>, (<span class="dv">0</span> split)</a>
<a class="sourceLine" id="cb4-49" title="49">      Sepal.Width  <span class="op">&lt;</span><span class="st"> </span><span class="fl">2.95</span> to the left,  agree=<span class="fl">0.652</span>, adj=<span class="fl">0.304</span>, (<span class="dv">0</span> split)</a>
<a class="sourceLine" id="cb4-50" title="50"></a>
<a class="sourceLine" id="cb4-51" title="51">Node number <span class="dv">6</span><span class="op">:</span><span class="st"> </span><span class="dv">23</span> observations</a>
<a class="sourceLine" id="cb4-52" title="52">  predicted class=versicolor  expected loss=<span class="fl">0.04347826</span>  <span class="kw">P</span>(node) =<span class="fl">0.3066667</span></a>
<a class="sourceLine" id="cb4-53" title="53">    class counts<span class="op">:</span><span class="st">     </span><span class="dv">0</span>    <span class="dv">22</span>     <span class="dv">1</span></a>
<a class="sourceLine" id="cb4-54" title="54">   probabilities<span class="op">:</span><span class="st"> </span><span class="fl">0.000</span> <span class="fl">0.957</span> <span class="fl">0.043</span> </a>
<a class="sourceLine" id="cb4-55" title="55"></a>
<a class="sourceLine" id="cb4-56" title="56">Node number <span class="dv">7</span><span class="op">:</span><span class="st"> </span><span class="dv">23</span> observations</a>
<a class="sourceLine" id="cb4-57" title="57">  predicted class=virginica   expected loss=<span class="dv">0</span>  <span class="kw">P</span>(node) =<span class="fl">0.3066667</span></a>
<a class="sourceLine" id="cb4-58" title="58">    class counts<span class="op">:</span><span class="st">     </span><span class="dv">0</span>     <span class="dv">0</span>    <span class="dv">23</span></a>
<a class="sourceLine" id="cb4-59" title="59">   probabilities<span class="op">:</span><span class="st"> </span><span class="fl">0.000</span> <span class="fl">0.000</span> <span class="fl">1.000</span> </a></code></pre></div>
<p>Finally, we can make some very rudimentary plots in base graphics for the tree and this can greatly facilitate the interpretation of these trees. We will also add some text to the plot to make it a little easier to understand.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1"><span class="co"># Make the plot</span></a>
<a class="sourceLine" id="cb5-2" title="2">  <span class="kw">plot</span>(iris.ct, <span class="dt">minbranch=</span> <span class="dv">10</span>, <span class="dt">compress=</span><span class="ot">TRUE</span>, <span class="dt">margin=</span>.<span class="dv">15</span>, <span class="dt">nspace=</span><span class="dv">5</span>)</a>
<a class="sourceLine" id="cb5-3" title="3"></a>
<a class="sourceLine" id="cb5-4" title="4"><span class="co"># Adding text to the plot makes the tree understandable</span></a>
<a class="sourceLine" id="cb5-5" title="5">  <span class="kw">text</span>(iris.ct, <span class="dt">use.n =</span> <span class="ot">TRUE</span>, <span class="dt">all =</span> <span class="ot">FALSE</span>, <span class="dt">fancy =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>While this graphical representation is easier to understand than the summary output of the tree, it is not much nicer to look at than the tabular output. So, let’s see if we can do something about that!</p>
</div>
<div id="tree-visualization" class="section level1">
<h1>Tree visualization</h1>
<p>Let’s load a new package for making some nicer trees that we might actually want to use in a talk, on a poster, or even in a paper. One trade off that we need to consider when making decisions about information and data visualization is what we gain and loose with various representations of our trees. For example, the plots above are a mess and we almost certainly wouldn’t want to use them for data presentation in a paper, a talk, or poster. However, they do contain a lot of useful information that we are likely going to lose with nicer looking tools.</p>
<p>We will rely on the aptly named <code>rpart.plot</code> package to start looking at our trees. Specifically, we are going to use the <code>prp</code> function for a nicer looking tree.</p>
<p>You’ll notice right away that we lose the neat-o group membership numbers that we got out of the ugly plots. On the other hand, this is a lot nicer to look at! Plus, it is a lot clearer to see which side the split for each variable represents.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1"><span class="co"># Library load</span></a>
<a class="sourceLine" id="cb6-2" title="2">  <span class="kw">library</span>(rpart.plot)</a>
<a class="sourceLine" id="cb6-3" title="3"></a>
<a class="sourceLine" id="cb6-4" title="4"><span class="co"># Plot the rpart object. Here, we add an </span></a>
<a class="sourceLine" id="cb6-5" title="5"><span class="co"># argument to make the variable names shorter</span></a>
<a class="sourceLine" id="cb6-6" title="6"><span class="co"># so we can fit more in a single pane</span></a>
<a class="sourceLine" id="cb6-7" title="7">  <span class="kw">prp</span>(iris.ct, <span class="dt">varlen =</span> <span class="dv">3</span>)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>But, wouldn’t it be nice if we could get a <em>little</em> more information out of this nicer layout? <strong>Glad you ask</strong>!</p>
<p>One simple way to do it is to pass values to the <code>extra</code> argument in the <code>prp</code> function. With all of the options available in this plotting utility, it is hard to imagine one named <code>extra</code>, but let’s take a look at how a few of the possible values for <code>extra</code> change the plot (see <code>?prp</code> for a detailed list of possible display options.)</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1">  <span class="co"># We can get counts in each category for each split</span></a>
<a class="sourceLine" id="cb7-2" title="2">    <span class="kw">prp</span>(iris.ct, <span class="dt">varlen =</span> <span class="dv">3</span>, <span class="dt">extra=</span><span class="dv">1</span>)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1">  <span class="co"># Classification rate (this one is only </span></a>
<a class="sourceLine" id="cb8-2" title="2">  <span class="co"># for classification trees, not to be</span></a>
<a class="sourceLine" id="cb8-3" title="3">  <span class="co"># used for regression trees)</span></a>
<a class="sourceLine" id="cb8-4" title="4">    <span class="kw">prp</span>(iris.ct, <span class="dt">varlen =</span> <span class="dv">3</span>, <span class="dt">extra=</span><span class="dv">2</span>)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-8-2.png" width="672" /></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" title="1">  <span class="co"># Misclassification rates (also for classification trees only)</span></a>
<a class="sourceLine" id="cb9-2" title="2">    <span class="kw">prp</span>(iris.ct, <span class="dt">varlen =</span> <span class="dv">3</span>, <span class="dt">extra=</span><span class="dv">3</span>)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-8-3.png" width="672" /></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1">  <span class="co"># Probability of membership in a node by class...</span></a>
<a class="sourceLine" id="cb10-2" title="2">    <span class="kw">prp</span>(iris.ct, <span class="dt">varlen =</span> <span class="dv">3</span>, <span class="dt">extra=</span><span class="dv">4</span>)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-8-4.png" width="672" /></p>
<blockquote>
<p>Here is a <em>really</em> nice way of visualizing these trees, though.</p>
</blockquote>
<p><strong>Note</strong>: You may have let the package install a <code>.dll</code> file for <code>gtk+</code> in order to get the <code>RColorBrewer</code> package to work. <code>Gtk+</code> is the cross-platform <code>GIMP tool kit</code> for building graphical user interfaces (GUIs). This will not be required as part of the assignment this week because you will probably not be able to install this on the school PCs, but I want you to there is more to life (and machine learning) than ugly graphs. Now you have the code.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" title="1"><span class="co"># Install and load the packages</span></a>
<a class="sourceLine" id="cb11-2" title="2">  <span class="kw">library</span>(rattle) <span class="co"># We&#39;ll use this one to make some more functional plots</span></a>
<a class="sourceLine" id="cb11-3" title="3">  <span class="kw">library</span>(RColorBrewer) <span class="co"># We&#39;ll use this one for colors</span></a>
<a class="sourceLine" id="cb11-4" title="4"></a>
<a class="sourceLine" id="cb11-5" title="5"><span class="co"># Make the plot</span></a>
<a class="sourceLine" id="cb11-6" title="6">  <span class="co">#prp(iris.ct)</span></a>
<a class="sourceLine" id="cb11-7" title="7">  </a>
<a class="sourceLine" id="cb11-8" title="8"><span class="co"># Now, make it fancy</span></a>
<a class="sourceLine" id="cb11-9" title="9">  <span class="kw">fancyRpartPlot</span>(iris.ct, <span class="dt">main=</span><span class="st">&#39;&#39;</span>, <span class="dt">sub=</span><span class="st">&#39;&#39;</span>)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Wicked awesome.</p>
</div>
<div id="pruning-the-tree" class="section level1">
<h1>Pruning the tree</h1>
<p>Now that we have looked at how to fit a tree and how to visualize a tree, we really should take a look at how to make sure the tree is not garbage. We can do this a few different ways. We have some tools available to us that we can use to determine the number of splits we should keep, what the predictive power of the resultant trees are, and we can even explore some statistical stopping rules that can eliminate the need for pruning, at least in theory.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" title="1"><span class="co"># Let&#39;s start by fitting a tree to the data that we assume is overfit from the</span></a>
<a class="sourceLine" id="cb12-2" title="2"><span class="co"># get-go</span></a>
<a class="sourceLine" id="cb12-3" title="3">  <span class="kw">set.seed</span>(<span class="dv">5</span>)</a>
<a class="sourceLine" id="cb12-4" title="4">  iris.ot =<span class="st"> </span><span class="kw">rpart</span>(</a>
<a class="sourceLine" id="cb12-5" title="5">                  Species <span class="op">~</span><span class="st"> </span>. ,</a>
<a class="sourceLine" id="cb12-6" title="6">                  <span class="dt">data =</span> iris,</a>
<a class="sourceLine" id="cb12-7" title="7">                  <span class="dt">method =</span> <span class="st">&#39;class&#39;</span>,</a>
<a class="sourceLine" id="cb12-8" title="8">                  <span class="dt">parms =</span> <span class="kw">list</span>(<span class="dt">split =</span> <span class="st">&#39;information&#39;</span>),</a>
<a class="sourceLine" id="cb12-9" title="9">                  <span class="dt">cp=</span><span class="fl">0.000001</span>,</a>
<a class="sourceLine" id="cb12-10" title="10">                  <span class="dt">minsplit =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb12-11" title="11">                  <span class="dt">minbucket =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb12-12" title="12"></a>
<a class="sourceLine" id="cb12-13" title="13"><span class="co"># Take a quick look at the plot</span></a>
<a class="sourceLine" id="cb12-14" title="14">  <span class="kw">prp</span>(iris.ot)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1">  <span class="kw">fancyRpartPlot</span>(iris.ot, <span class="dt">main=</span><span class="st">&#39;&#39;</span>, <span class="dt">sub=</span><span class="st">&#39;&#39;</span>)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-10-2.png" width="672" /></p>
<p>Now we need to pick the tree size that minimizes misclassification rate (prediction error). To do this, we are basically going to look at changes in three things:</p>
<ol style="list-style-type: decimal">
<li>Training error (error in predicting training data): <code>relerror</code></li>
<li>Crossvalidation error (predictive error in x-validation): <code>xerror</code></li>
<li>Complexity parameter: <code>cp</code>
<ul>
<li>This one tells us how much information gain we get for additional splits. In general, we are looking for the cp at which cross validation error is minimized so we can use that to decide how far back we want to prune our trees.</li>
</ul></li>
</ol>
<p>First, let’s look at how the cross-validation results change with respect to the size of our tree. This initial plot shows us how the relative error and the complexity parameter (cp) change with an increasing number of splits.</p>
<p>In this plot, it is clear that by the third split we have minimized the xerror and decreases in information loss are minimized through the addition of more splits, but let’s keep moving along.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" title="1">  <span class="kw">plotcp</span>(iris.ot)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Another, perhaps more familiar, way to look at this is to plot changes in the predictive R-squared value for the tree with respect to subsequent splits. Again, it is clear that by the time we get two splits out from the root that we have essentially explained as much variance as we are going to squeeze out of this tree.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" title="1">  <span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb15-2" title="2">  <span class="kw">rsq.rpart</span>(iris.ot)</a>
<a class="sourceLine" id="cb15-3" title="3"></a>
<a class="sourceLine" id="cb15-4" title="4">Classification tree<span class="op">:</span></a>
<a class="sourceLine" id="cb15-5" title="5"><span class="kw">rpart</span>(<span class="dt">formula =</span> Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris, <span class="dt">method =</span> <span class="st">&quot;class&quot;</span>, <span class="dt">parms =</span> <span class="kw">list</span>(<span class="dt">split =</span> <span class="st">&quot;information&quot;</span>), </a>
<a class="sourceLine" id="cb15-6" title="6">    <span class="dt">cp =</span> <span class="fl">1e-06</span>, <span class="dt">minsplit =</span> <span class="dv">1</span>, <span class="dt">minbucket =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb15-7" title="7"></a>
<a class="sourceLine" id="cb15-8" title="8">Variables actually used <span class="cf">in</span> tree construction<span class="op">:</span></a>
<a class="sourceLine" id="cb15-9" title="9">[<span class="dv">1</span>] Petal.Length Petal.Width  Sepal.Length</a>
<a class="sourceLine" id="cb15-10" title="10"></a>
<a class="sourceLine" id="cb15-11" title="11">Root node error<span class="op">:</span><span class="st"> </span><span class="dv">100</span><span class="op">/</span><span class="dv">150</span> =<span class="st"> </span><span class="fl">0.66667</span></a>
<a class="sourceLine" id="cb15-12" title="12"></a>
<a class="sourceLine" id="cb15-13" title="13">n=<span class="st"> </span><span class="dv">150</span> </a>
<a class="sourceLine" id="cb15-14" title="14"></a>
<a class="sourceLine" id="cb15-15" title="15">       CP nsplit rel error xerror     xstd</a>
<a class="sourceLine" id="cb15-16" title="16"><span class="dv">1</span> <span class="fl">5.0e-01</span>      <span class="dv">0</span>      <span class="fl">1.00</span>   <span class="fl">1.18</span> <span class="fl">0.050173</span></a>
<a class="sourceLine" id="cb15-17" title="17"><span class="dv">2</span> <span class="fl">4.4e-01</span>      <span class="dv">1</span>      <span class="fl">0.50</span>   <span class="fl">0.67</span> <span class="fl">0.060888</span></a>
<a class="sourceLine" id="cb15-18" title="18"><span class="dv">3</span> <span class="fl">2.0e-02</span>      <span class="dv">2</span>      <span class="fl">0.06</span>   <span class="fl">0.09</span> <span class="fl">0.029086</span></a>
<a class="sourceLine" id="cb15-19" title="19"><span class="dv">4</span> <span class="fl">1.0e-02</span>      <span class="dv">3</span>      <span class="fl">0.04</span>   <span class="fl">0.08</span> <span class="fl">0.027520</span></a>
<a class="sourceLine" id="cb15-20" title="20"><span class="dv">5</span> <span class="fl">5.0e-03</span>      <span class="dv">6</span>      <span class="fl">0.01</span>   <span class="fl">0.08</span> <span class="fl">0.027520</span></a>
<a class="sourceLine" id="cb15-21" title="21"><span class="dv">6</span> <span class="fl">1.0e-06</span>      <span class="dv">8</span>      <span class="fl">0.00</span>   <span class="fl">0.09</span> <span class="fl">0.029086</span></a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>We can also print the results of the model fit to take a look at the numbers behind all of these graphs.</p>
<p>Some simple calculations are helpful for this:</p>
<ul>
<li>Prediction error rate in training data = <code>Root node error</code> * <code>rel error</code> * 100</li>
<li>Prediction error rate in cross-validation = <code>Root node error</code> * <code>xerror</code> * 100</li>
</ul>
<p>We want the cp value (with a simpler tree) that minimizes the <code>xerror</code>. The key here is that we want the first model to minimize <code>xerror</code>.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" title="1">  <span class="kw">printcp</span>(iris.ot)</a>
<a class="sourceLine" id="cb16-2" title="2"></a>
<a class="sourceLine" id="cb16-3" title="3">Classification tree<span class="op">:</span></a>
<a class="sourceLine" id="cb16-4" title="4"><span class="kw">rpart</span>(<span class="dt">formula =</span> Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris, <span class="dt">method =</span> <span class="st">&quot;class&quot;</span>, <span class="dt">parms =</span> <span class="kw">list</span>(<span class="dt">split =</span> <span class="st">&quot;information&quot;</span>), </a>
<a class="sourceLine" id="cb16-5" title="5">    <span class="dt">cp =</span> <span class="fl">1e-06</span>, <span class="dt">minsplit =</span> <span class="dv">1</span>, <span class="dt">minbucket =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb16-6" title="6"></a>
<a class="sourceLine" id="cb16-7" title="7">Variables actually used <span class="cf">in</span> tree construction<span class="op">:</span></a>
<a class="sourceLine" id="cb16-8" title="8">[<span class="dv">1</span>] Petal.Length Petal.Width  Sepal.Length</a>
<a class="sourceLine" id="cb16-9" title="9"></a>
<a class="sourceLine" id="cb16-10" title="10">Root node error<span class="op">:</span><span class="st"> </span><span class="dv">100</span><span class="op">/</span><span class="dv">150</span> =<span class="st"> </span><span class="fl">0.66667</span></a>
<a class="sourceLine" id="cb16-11" title="11"></a>
<a class="sourceLine" id="cb16-12" title="12">n=<span class="st"> </span><span class="dv">150</span> </a>
<a class="sourceLine" id="cb16-13" title="13"></a>
<a class="sourceLine" id="cb16-14" title="14">       CP nsplit rel error xerror     xstd</a>
<a class="sourceLine" id="cb16-15" title="15"><span class="dv">1</span> <span class="fl">5.0e-01</span>      <span class="dv">0</span>      <span class="fl">1.00</span>   <span class="fl">1.18</span> <span class="fl">0.050173</span></a>
<a class="sourceLine" id="cb16-16" title="16"><span class="dv">2</span> <span class="fl">4.4e-01</span>      <span class="dv">1</span>      <span class="fl">0.50</span>   <span class="fl">0.67</span> <span class="fl">0.060888</span></a>
<a class="sourceLine" id="cb16-17" title="17"><span class="dv">3</span> <span class="fl">2.0e-02</span>      <span class="dv">2</span>      <span class="fl">0.06</span>   <span class="fl">0.09</span> <span class="fl">0.029086</span></a>
<a class="sourceLine" id="cb16-18" title="18"><span class="dv">4</span> <span class="fl">1.0e-02</span>      <span class="dv">3</span>      <span class="fl">0.04</span>   <span class="fl">0.08</span> <span class="fl">0.027520</span></a>
<a class="sourceLine" id="cb16-19" title="19"><span class="dv">5</span> <span class="fl">5.0e-03</span>      <span class="dv">6</span>      <span class="fl">0.01</span>   <span class="fl">0.08</span> <span class="fl">0.027520</span></a>
<a class="sourceLine" id="cb16-20" title="20"><span class="dv">6</span> <span class="fl">1.0e-06</span>      <span class="dv">8</span>      <span class="fl">0.00</span>   <span class="fl">0.09</span> <span class="fl">0.029086</span></a></code></pre></div>
<p>Now we can get the cp for tree that is the first to reach the minimum xerror (with the fewest number of splits):</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" title="1">bestcp =<span class="st"> </span>iris.ot<span class="op">$</span>cptable[<span class="kw">which.min</span>(iris.ot<span class="op">$</span>cptable[,<span class="st">&quot;xerror&quot;</span>]),<span class="st">&quot;CP&quot;</span>]</a>
<a class="sourceLine" id="cb17-2" title="2">bestcp</a>
<a class="sourceLine" id="cb17-3" title="3">[<span class="dv">1</span>] <span class="fl">0.01</span></a></code></pre></div>
<p>We can use the information we have to calculate the misclassification rate for our optimal tree based on the equation on line 221. Here, we can see that our best tree will have a misclassification rate of 0.035. IN OTHER WORDS, we have effectively explained 96.5% of the variance in our data with this regression tree. Aw snap!</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" title="1">  <span class="fl">5e-3</span><span class="op">*</span>.<span class="dv">07</span><span class="op">*</span><span class="dv">100</span></a>
<a class="sourceLine" id="cb18-2" title="2">[<span class="dv">1</span>] <span class="fl">0.035</span></a></code></pre></div>
<p>Now we can use that cp to prune our tree by re-fitting our model with a new cp argument, changing nothing else, to see where the splits are and how they can be interpretted.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" title="1">iris.pt =<span class="st"> </span><span class="kw">rpart</span>(Species <span class="op">~</span><span class="st"> </span>. ,</a>
<a class="sourceLine" id="cb19-2" title="2">                <span class="dt">data =</span> iris,</a>
<a class="sourceLine" id="cb19-3" title="3">                <span class="dt">method =</span> <span class="st">&#39;class&#39;</span>,</a>
<a class="sourceLine" id="cb19-4" title="4">                <span class="dt">parms =</span> <span class="kw">list</span>(<span class="dt">split =</span> <span class="st">&#39;information&#39;</span>),</a>
<a class="sourceLine" id="cb19-5" title="5">                <span class="dt">cp=</span><span class="fl">0.01</span></a>
<a class="sourceLine" id="cb19-6" title="6">                )</a></code></pre></div>
<p>We see that our plot is reduced compared to the original overfitted plot, and it actually is identical to the original, although this is not always the case.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" title="1">  <span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb20-2" title="2">  <span class="kw">prp</span>(iris.pt)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1">  <span class="kw">fancyRpartPlot</span>(iris.pt, <span class="dt">main=</span><span class="st">&#39;&#39;</span>, <span class="dt">sub=</span><span class="st">&#39;&#39;</span>)</a></code></pre></div>
<p><img src="12_cart_files/figure-html/unnamed-chunk-17-2.png" width="672" /></p>
<p>That should get you started fitting and pruning CART models. Although the examples that we used above are for classification trees, you should understand that these concepts work the same way for regression trees, although the interpretation varies slightly. In fact, it is more straightforward because we are just counting the number of records in each node instead of the number of records within each group in each node.</p>
<p><br></p>
</div>

<!DOCTYPE html>

<br>

<hr>

<p style="color:gray; text-align:center">This work is licensed under a <a href="https://creativecommons.org/licenses/by/4.0/legalcode">Creative Commons Attribution 4.0 International License</a>. Data are provided for educational purposes only unless otherwise noted.</p>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
